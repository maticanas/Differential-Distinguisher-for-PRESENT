{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NXVzTjGSQpAx",
    "outputId": "31cbc208-81e9-4251-95e5-a53c46575581"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 80-bit Key Vectors:\n",
      "Success 0x5579c1387b228445\n",
      "Success 0xe72c46c0f5945049\n",
      "Success 0xa112ffc72f68417b\n",
      "Success 0x3333dcd3213210d2\n",
      "0x5579c1387b228445\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "https://github.com/inmcm/present_cipher/tree/master/python\n",
    "\"\"\"\n",
    "# coding: utf-8\n",
    "from __future__ import print_function\n",
    "\n",
    "s_box = (0xC, 0x5, 0x6, 0xB, 0x9, 0x0, 0xA, 0xD, 0x3, 0xE, 0xF, 0x8, 0x4, 0x7, 0x1, 0x2)\n",
    "\n",
    "inv_s_box = (0x5, 0xE, 0xF, 0x8, 0xC, 0x1, 0x2, 0xD, 0xB, 0x4, 0x6, 0x3, 0x0, 0x7, 0x9, 0xA)\n",
    "\n",
    "p_layer_order = [0, 16, 32, 48, 1, 17, 33, 49, 2, 18, 34, 50, 3, 19, 35, 51, 4, 20, 36, 52, 5, 21, 37, 53, 6, 22, 38,\n",
    "                 54, 7, 23, 39, 55, 8, 24, 40, 56, 9, 25, 41, 57, 10, 26, 42, 58, 11, 27, 43, 59, 12, 28, 44, 60, 13,\n",
    "                 29, 45, 61, 14, 30, 46, 62, 15, 31, 47, 63]\n",
    "\n",
    "block_size = 64\n",
    "\n",
    "ROUND_LIMIT = 32\n",
    "\n",
    "\n",
    "def round_function(state, key):\n",
    "    new_state = state ^ key\n",
    "    state_nibs = []\n",
    "    for x in range(0, block_size, 4):\n",
    "        nib = (new_state >> x) & 0xF\n",
    "        sb_nib = s_box[nib]\n",
    "        state_nibs.append(sb_nib)\n",
    "    # print(state_nibs)\n",
    "\n",
    "    state_bits = []\n",
    "    for y in state_nibs:\n",
    "        nib_bits = [1 if t == '1'else 0 for t in format(y, '04b')[::-1]]\n",
    "        state_bits += nib_bits\n",
    "    # print(state_bits)\n",
    "    # print(len(state_bits))\n",
    "\n",
    "    state_p_layer = [0 for _ in range(64)]\n",
    "    for p_index, std_bits in enumerate(state_bits):\n",
    "        state_p_layer[p_layer_order[p_index]] = std_bits\n",
    "\n",
    "    # print(len(state_p_layer), state_p_layer)\n",
    "\n",
    "    round_output = 0\n",
    "    for index, ind_bit in enumerate(state_p_layer):\n",
    "        round_output += (ind_bit << index)\n",
    "\n",
    "    # print(format(round_output, '#016X'))\n",
    "\n",
    "    # print('')\n",
    "    return round_output\n",
    "\n",
    "\n",
    "def key_function_80(key, round_count):\n",
    "    # print('Start: ', hex(key))\n",
    "    # print('')\n",
    "\n",
    "    r = [1 if t == '1'else 0 for t in format(key, '080b')[::-1]]\n",
    "\n",
    "    # print('k bits:', r)\n",
    "    # print('')\n",
    "\n",
    "    h = r[-61:] + r[:-61]\n",
    "\n",
    "    # print('s bits:', h)\n",
    "    # print('')\n",
    "\n",
    "    round_key_int = 0\n",
    "    # print('init round int:', hex(round_key_int))\n",
    "    for index, ind_bit in enumerate(h):\n",
    "        round_key_int += (ind_bit << index)\n",
    "        # print('round:',index, '-', hex(round_key_int))\n",
    "\n",
    "    # print('round_key_int', hex(round_key_int))\n",
    "    # print('')\n",
    "\n",
    "    upper_nibble = round_key_int >> 76\n",
    "\n",
    "    # print('upper_nibble:', upper_nibble)\n",
    "\n",
    "    upper_nibble = s_box[upper_nibble]\n",
    "\n",
    "    # print('upper_nibble sboxed', hex(upper_nibble))\n",
    "\n",
    "    xor_portion = ((round_key_int >> 15) & 0x1F) ^ round_count\n",
    "    # print('Count:', round_count)\n",
    "    # print('XOR Value:', xor_portion)\n",
    "\n",
    "    # print('Before:', hex(round_key_int))\n",
    "    round_key_int = (round_key_int & 0x0FFFFFFFFFFFFFF07FFF) + (upper_nibble << 76) + (xor_portion << 15)\n",
    "    # print('After: ', hex(round_key_int))\n",
    "\n",
    "    return round_key_int\n",
    "\n",
    "\n",
    "\n",
    "test_vectors_80 = {1:(0x00000000000000000000, 0x0000000000000000, 0x5579C1387B228445),\n",
    "                2:(0xFFFFFFFFFFFFFFFFFFFF, 0x0000000000000000, 0xE72C46C0F5945049),\n",
    "                3:(0x00000000000000000000, 0xFFFFFFFFFFFFFFFF, 0xA112FFC72F68417B),\n",
    "                4:(0xFFFFFFFFFFFFFFFFFFFF, 0xFFFFFFFFFFFFFFFF, 0x3333DCD3213210D2)}\n",
    "\n",
    "print('Testing 80-bit Key Vectors:')\n",
    "\n",
    "\n",
    "\n",
    "for test_case in test_vectors_80:\n",
    "\n",
    "    key_schedule = []\n",
    "    current_round_key = test_vectors_80[test_case][0]\n",
    "    round_state = test_vectors_80[test_case][1]\n",
    "\n",
    "    # Key schedule\n",
    "    for rnd_cnt in range(ROUND_LIMIT):\n",
    "        # print(format(round_key, '020X'))\n",
    "        # print(format(round_key >> 16, '016X'))\n",
    "        key_schedule.append(current_round_key >> 16)\n",
    "        current_round_key = key_function_80(current_round_key, rnd_cnt + 1)\n",
    "\n",
    "    for rnd in range(ROUND_LIMIT - 1):\n",
    "        # print('Round:', rnd)\n",
    "        # print('State:', format(round_state, '016X'))\n",
    "        # print('R_Key:', format(key_schedule[rnd], '016X'))\n",
    "        round_state = round_function(round_state, key_schedule[rnd])\n",
    "\n",
    "    round_state ^= key_schedule[ROUND_LIMIT-1]\n",
    "\n",
    "    if round_state == test_vectors_80[test_case][2]:\n",
    "        print('Success', hex(round_state))\n",
    "    else:\n",
    "        print('Failure', hex(round_state))\n",
    "        \n",
    "def PRESENT(P, K, ROUND):\n",
    "    key_schedule = []\n",
    "    current_round_key = K\n",
    "    round_state = P\n",
    "    \n",
    "    if(ROUND==0):\n",
    "        return P\n",
    "\n",
    "    for rnd_cnt in range(ROUND):\n",
    "        key_schedule.append(current_round_key >> 16)\n",
    "        current_round_key = key_function_80(current_round_key, rnd_cnt + 1)\n",
    "\n",
    "    for rnd in range(ROUND - 1):\n",
    "        round_state = round_function(round_state, key_schedule[rnd])\n",
    "\n",
    "    round_state ^= key_schedule[ROUND-1]\n",
    "    \n",
    "    return round_state\n",
    "\n",
    "C = PRESENT(0x0, 0x0, ROUND=32)\n",
    "print(hex(C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AwZVgDHVQpAz"
   },
   "outputs": [],
   "source": [
    "Wang_diff = [0x7000000000007000, 0x0700000000000700, 0x0070000000000070, 0x0007000000000007]\n",
    "BLOCK_SIZE = 64\n",
    "\n",
    "ROUND_global = 6\n",
    "sample_num = 10000\n",
    "test_sample_num = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xJrNRizYQpA0"
   },
   "outputs": [],
   "source": [
    "def gen(sample_num, ROUND):\n",
    "    P_set = []\n",
    "    K_set = []\n",
    "    for i in range(sample_num):\n",
    "        P_set.append(random.randrange(0,2**64))\n",
    "        #print(\"%x\" % P_set[i])\n",
    "        K_set.append(random.randrange(0,2**80))\n",
    "        #print(\"%x\" % K_set[i])\n",
    "\n",
    "    C_diff_set = []\n",
    "    C_diff_label = []\n",
    "    for i in range(sample_num):\n",
    "        P = P_set[i]\n",
    "        K = K_set[i]\n",
    "        C = PRESENT(P, K, ROUND)\n",
    "        for j in range(4):\n",
    "            Cj = PRESENT(P^Wang_diff[j], K, ROUND)\n",
    "            C_diff = C^Cj\n",
    "            #print(C_diff)\n",
    "            C_diff_set.append(C_diff)\n",
    "            temp = [0, 0, 0, 0]\n",
    "            temp[j] = 1\n",
    "            C_diff_label.append(temp)\n",
    "\n",
    "    tr_X = []\n",
    "    for C_diff in C_diff_set:\n",
    "        A = []\n",
    "        for j in range(BLOCK_SIZE):\n",
    "            A.append((C_diff>>j)&1)\n",
    "        tr_X.append(A)\n",
    "        #print(A)\n",
    "    tr_X = np.array(tr_X)\n",
    "\n",
    "    tr_X = []\n",
    "    for C_diff in C_diff_set:\n",
    "        A = []\n",
    "        for j in range(BLOCK_SIZE):\n",
    "            A.append((C_diff>>j)&1)\n",
    "        tr_X.append(A)\n",
    "        #print(A)\n",
    "    tr_X = np.array(tr_X)\n",
    "    tr_t = np.array(C_diff_label)\n",
    "\n",
    "    ind = np.arange(len(tr_X))\n",
    "    np.random.shuffle(ind)\n",
    "    tr_X = tr_X[ind]\n",
    "    tr_t = tr_t[ind]\n",
    "    \n",
    "    return tr_X, tr_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_gen():\n",
    "    SAMPLE_NUM_RANGE = [10000, 50000, 100000]\n",
    "    ROUND_RANGE = [3, 4, 5, 6, 7, 8]\n",
    "    for sn in SAMPLE_NUM_RANGE:\n",
    "        for rn in ROUND_RANGE:\n",
    "            tr_X, tr_t = gen(sn, rn)\n",
    "            np.save(\"ROUND %d SAMPLE %d Dataset\" % (rn, sn), tr_X)\n",
    "            np.save(\"ROUND %d SAMPLE %d Label\" % (rn, sn), tr_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Wk0Lr4ReQpA1"
   },
   "outputs": [],
   "source": [
    "def test_sample_gen():\n",
    "    TEST_SMAPLE_NUM = 10000\n",
    "    for rn in ROUND_RANGE:\n",
    "        te_X, te_t = gen(TEST_SMAPLE_NUM, rn)\n",
    "        np.save(\"ROUND %d TEST_SAMPLE Dataset\" % (rn), te_X)\n",
    "        np.save(\"ROUND %d TEST_SAMPLE Label\" % (rn), te_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "O9XPTV7FQpA1"
   },
   "outputs": [],
   "source": [
    "def load_sample(SAMPLE_NUM, ROUND_NUM):\n",
    "    tr_X = np.load(\"ROUND %d SAMPLE %d Dataset.npy\" % (ROUND_NUM, SAMPLE_NUM))\n",
    "    tr_t = np.load(\"ROUND %d SAMPLE %d Label.npy\" % (ROUND_NUM, SAMPLE_NUM))\n",
    "    return tr_X, tr_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_sample(ROUND_NUM):\n",
    "    te_X = np.load(\"ROUND %d TEST_SAMPLE Dataset.npy\" % (ROUND_NUM))\n",
    "    te_t = np.load(\"ROUND %d TEST_SAMPLE Label.npy\" % (ROUND_NUM))\n",
    "    return te_X, te_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "RfujwI1AQpA1"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, layer1=128, layer2=1028, layer3=None, reg=None, learning_rate=0.001, loss='categorical_crossentropy'):\n",
    "        self.layers = self._build_layers(layer1, layer2, layer3, reg)\n",
    "        self.model = tf.keras.Sequential(self.layers) \n",
    "        self.model.compile(optimizer=tf.keras.optimizers.Adam(lr=learning_rate), loss=loss, metrics=['accuracy'])\n",
    "\n",
    "    def _build_layers(self, layer1, layer2, layer3, reg):\n",
    "        if layer3==None:\n",
    "            layers = [\n",
    "                tf.keras.layers.Flatten(input_shape=(64,)),\n",
    "                tf.keras.layers.Dense(layer1, activation='relu', kernel_regularizer=reg),\n",
    "                tf.keras.layers.Dense(layer2, activation='relu', kernel_regularizer=reg),\n",
    "                #tf.keras.layers.Dense(layer3, activation='relu', kernel_regularizer=reg),\n",
    "                tf.keras.layers.Dense(4, activation='softmax')\n",
    "            ]\n",
    "        else:\n",
    "            layers = [\n",
    "                tf.keras.layers.Flatten(input_shape=(64,)),\n",
    "                tf.keras.layers.Dense(layer1, activation='relu', kernel_regularizer=reg),\n",
    "                tf.keras.layers.Dense(layer2, activation='relu', kernel_regularizer=reg),\n",
    "                tf.keras.layers.Dense(layer3, activation='relu', kernel_regularizer=reg),\n",
    "                tf.keras.layers.Dense(4, activation='softmax')\n",
    "            ]\n",
    "        return layers\n",
    "\n",
    "    #그냥 cross entropy를 그대로 정의함\n",
    "    def _my_loss(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.int32) #float32 => int32로 casting #None, 1\n",
    "        y_true = tf.squeeze(tf.one_hot(y_true, depth=10, dtype=tf.float32), 1) # one_hot encoding #None, 1, 10 #quezze => 1을 없애줌 => None, 10\n",
    "        y_pred = tf.nn.softmax(y_pred, 1) # 한 축에 대해 softmax를 적용해라 #1 => 열을 의미 #즉, 한 행에 있는 값을 다 더하면 1이 되도록 만들어줌\n",
    "\n",
    "        #cross entropy 그대로 적용\n",
    "        #-sum t*log y 한 후에 평균 냄\n",
    "        return -tf.reduce_mean(tf.reduce_sum(\n",
    "                tf.multiply(y_true, tf.math.log(y_pred)), 1))\n",
    "\n",
    "    def _my_accuracy(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.int32)\n",
    "        y_true = tf.squeeze(tf.one_hot(y_true, depth=10, dtype=tf.float32), 1)\n",
    "        #argmax를 그대로 이용\n",
    "        return tf.reduce_mean(\n",
    "            tf.cast(\n",
    "                tf.equal(tf.argmax(y_true, 1), tf.argmax(y_pred, 1)), tf.float32))\n",
    "\n",
    "    def fit(self, x, t, epochs, batch_size=None, validation_split=0.0, verbose=1, shuffle=False, workers=2):\n",
    "        return self.model.fit(x, t, epochs=epochs, batch_size=batch_size, validation_split=validation_split, verbose=verbose, shuffle=shuffle, workers=workers)\n",
    "    \n",
    "    def evaluate(self, x=None, y=None, verbose=1):\n",
    "        return self.model.evaluate(x=x, y=y, verbose=verbose)\n",
    "    \n",
    "    def summary(self):\n",
    "        self.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mhQTZ7KwQpA2",
    "outputId": "85b3d255-445f-463d-ba53-122475dfd771"
   },
   "outputs": [],
   "source": [
    "#Config\n",
    "ROUND = 5\n",
    "SAMPLE_NUM = 10000\n",
    "#test_sample_num = 10000\n",
    "ITERATION = 1\n",
    "\n",
    "#Fix\n",
    "batch_size = 200\n",
    "epoch_size = 25\n",
    "validation_split = 0.3\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproduce():\n",
    "    tr_X, tr_t = load_sample(SAMPLE_NUM=10000, ROUND_NUM=ROUND)\n",
    "    te_X, te_t = load_test_sample(ROUND_NUM=5)\n",
    "    model = MLP(128, 1024, loss='mse')\n",
    "    results = model.fit(tr_X, tr_t, epochs=epoch_size, batch_size=batch_size, validation_split = validation_split, shuffle=False, verbose=1)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.1784 - accuracy: 0.3521 - val_loss: 0.1758 - val_accuracy: 0.3728\n",
      "Epoch 2/25\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.1715 - accuracy: 0.4018 - val_loss: 0.1740 - val_accuracy: 0.3799\n",
      "Epoch 3/25\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.1672 - accuracy: 0.4288 - val_loss: 0.1731 - val_accuracy: 0.3859\n",
      "Epoch 4/25\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.1631 - accuracy: 0.4556 - val_loss: 0.1729 - val_accuracy: 0.3898\n",
      "Epoch 5/25\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.1588 - accuracy: 0.4810 - val_loss: 0.1735 - val_accuracy: 0.3907\n",
      "Epoch 6/25\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.1543 - accuracy: 0.5031 - val_loss: 0.1745 - val_accuracy: 0.3925\n",
      "Epoch 7/25\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.1494 - accuracy: 0.5306 - val_loss: 0.1760 - val_accuracy: 0.3904\n",
      "Epoch 8/25\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.1442 - accuracy: 0.5559 - val_loss: 0.1777 - val_accuracy: 0.3914\n",
      "Epoch 9/25\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.1387 - accuracy: 0.5838 - val_loss: 0.1799 - val_accuracy: 0.3870\n",
      "Epoch 10/25\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.1331 - accuracy: 0.6068 - val_loss: 0.1820 - val_accuracy: 0.3847\n",
      "Epoch 11/25\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.1272 - accuracy: 0.6349 - val_loss: 0.1846 - val_accuracy: 0.3823\n",
      "Epoch 12/25\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.1212 - accuracy: 0.6599 - val_loss: 0.1873 - val_accuracy: 0.3829\n",
      "Epoch 13/25\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.1151 - accuracy: 0.6849 - val_loss: 0.1900 - val_accuracy: 0.3778\n",
      "Epoch 14/25\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.1092 - accuracy: 0.7084 - val_loss: 0.1931 - val_accuracy: 0.3787\n",
      "Epoch 15/25\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.7297 - val_loss: 0.1960 - val_accuracy: 0.3762\n",
      "Epoch 16/25\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.0978 - accuracy: 0.7507 - val_loss: 0.1985 - val_accuracy: 0.3772\n",
      "Epoch 17/25\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.0924 - accuracy: 0.7704 - val_loss: 0.2008 - val_accuracy: 0.3778\n",
      "Epoch 18/25\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.0876 - accuracy: 0.7868 - val_loss: 0.2035 - val_accuracy: 0.3792\n",
      "Epoch 19/25\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.0835 - accuracy: 0.8008 - val_loss: 0.2066 - val_accuracy: 0.3795\n",
      "Epoch 20/25\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.0817 - accuracy: 0.8025 - val_loss: 0.2083 - val_accuracy: 0.3814\n",
      "Epoch 21/25\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.0840 - accuracy: 0.7879 - val_loss: 0.2233 - val_accuracy: 0.3784\n",
      "Epoch 22/25\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.0849 - accuracy: 0.7772 - val_loss: 0.2110 - val_accuracy: 0.3866\n",
      "Epoch 23/25\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.0788 - accuracy: 0.8044 - val_loss: 0.2155 - val_accuracy: 0.3687\n",
      "Epoch 24/25\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.0751 - accuracy: 0.8153 - val_loss: 0.2203 - val_accuracy: 0.3582\n",
      "Epoch 25/25\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 0.0706 - accuracy: 0.8307 - val_loss: 0.2199 - val_accuracy: 0.3613\n"
     ]
    }
   ],
   "source": [
    "results = reproduce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(results.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results.history['accuracy'])\n",
    "plt.plot(results.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3556428551673889, 0.3968571424484253, 0.425428569316864, 0.4495357275009155, 0.47450000047683716, 0.4957500100135803, 0.5201428532600403, 0.546999990940094, 0.5709642767906189, 0.5970357060432434, 0.6226785778999329, 0.646142840385437, 0.6703214049339294, 0.6924999952316284, 0.7173928618431091, 0.7392500042915344, 0.7594285607337952, 0.7800714373588562, 0.795714259147644, 0.8089285492897034, 0.8153214454650879, 0.791607141494751, 0.7742499709129333, 0.8079285621643066, 0.838535726070404]\n"
     ]
    }
   ],
   "source": [
    "print(results.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37566667795181274, 0.38066667318344116, 0.3843333423137665, 0.38874998688697815, 0.38866665959358215, 0.3916666805744171, 0.39233332872390747, 0.3921666741371155, 0.3916666805744171, 0.3894166648387909, 0.38725000619888306, 0.390749990940094, 0.38741666078567505, 0.3855833411216736, 0.3787499964237213, 0.37691667675971985, 0.3792499899864197, 0.3788333237171173, 0.37841665744781494, 0.3774999976158142, 0.3764166533946991, 0.3790833353996277, 0.3618333339691162, 0.3605000078678131, 0.35766667127609253]\n"
     ]
    }
   ],
   "source": [
    "print(results.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "w53eKengQpA2"
   },
   "outputs": [],
   "source": [
    "def learn(ROUND, SAMPLE_NUM, layer1, layer2, layer3=None, reg=None, learning_rate=0.001, loss=None):\n",
    "    tr_X, tr_t = load_sample(SAMPLE_NUM=SAMPLE_NUM, ROUND_NUM=ROUND)\n",
    "    te_X, te_t = load_test_sample(ROUND_NUM=ROUND)\n",
    "    accuracy = []\n",
    "    for i in range(ITERATION):\n",
    "        model = MLP(layer1, layer2, layer3, reg, learning_rate, loss)\n",
    "        model.fit(tr_X, tr_t, epochs=epoch_size, batch_size=batch_size, validation_split = validation_split, shuffle=True, verbose=0)\n",
    "        accuracy.append(model.evaluate(te_X, te_t, verbose=0)[1])\n",
    "    avg = np.mean(np.array(accuracy))\n",
    "    #print(\"average : %f\" % avg)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\tlsgy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\tlsgy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\tlsgy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\tlsgy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\tlsgy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\tlsgy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\tlsgy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:757 train_step\n        self.trainable_variables)\n    C:\\Users\\tlsgy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2737 _minimize\n        trainable_variables))\n    C:\\Users\\tlsgy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:562 _aggregate_gradients\n        filtered_grads_and_vars = _filter_grads(grads_and_vars)\n    C:\\Users\\tlsgy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:1271 _filter_grads\n        ([v.name for _, v in grads_and_vars],))\n\n    ValueError: No gradients provided for any variable: ['dense_12/kernel:0', 'dense_12/bias:0', 'dense_13/kernel:0', 'dense_13/bias:0', 'dense_14/kernel:0', 'dense_14/bias:0'].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-3f3b916bd6da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreproduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-ecdb0c376d0e>\u001b[0m in \u001b[0;36mreproduce\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mte_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mte_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_test_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mROUND_NUM\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1024\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-f1972130827a>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, t, epochs, batch_size, validation_split, verbose, shuffle, workers)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 697\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3075\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\tlsgy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\tlsgy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\tlsgy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\tlsgy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\tlsgy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\tlsgy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\tlsgy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:757 train_step\n        self.trainable_variables)\n    C:\\Users\\tlsgy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2737 _minimize\n        trainable_variables))\n    C:\\Users\\tlsgy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:562 _aggregate_gradients\n        filtered_grads_and_vars = _filter_grads(grads_and_vars)\n    C:\\Users\\tlsgy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:1271 _filter_grads\n        ([v.name for _, v in grads_and_vars],))\n\n    ValueError: No gradients provided for any variable: ['dense_12/kernel:0', 'dense_12/bias:0', 'dense_13/kernel:0', 'dense_13/bias:0', 'dense_14/kernel:0', 'dense_14/bias:0'].\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_cand = [64, 128, 256]\n",
    "layer2_cand = [512, 1024, 2048]\n",
    "layer3_cand = [None, 1024, 2048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2fQQ7n_Gba8p",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 / 512 / None \t : 0.392875\n",
      "64 / 512 / None \t : 0.394825\n",
      "64 / 512 / None \t : 0.001950\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-5ffbb45b92bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ml1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayer1_cand\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0macc_mse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mROUND\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mROUND\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSAMPLE_NUM\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSAMPLE_NUM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0macc_cce\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mROUND\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mROUND\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSAMPLE_NUM\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSAMPLE_NUM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[1;31m#print(acc)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0macc_mse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_cce\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-1552b55d3194>\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(ROUND, SAMPLE_NUM, layer1, layer2, layer3, reg, learning_rate, loss)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mITERATION\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mte_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mte_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mavg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-f1972130827a>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, t, epochs, batch_size, validation_split, verbose, shuffle, workers)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "layer_state = []\n",
    "\n",
    "for l3 in layer3_cand:\n",
    "    for l2 in layer2_cand:\n",
    "        for l1 in layer1_cand:\n",
    "            acc_mse = learn(ROUND=ROUND, SAMPLE_NUM=SAMPLE_NUM, layer1=l1, layer2=l2, layer3=l3, reg=None, loss='mse')\n",
    "            acc_cce = learn(ROUND=ROUND, SAMPLE_NUM=SAMPLE_NUM, layer1=l1, layer2=l2, layer3=l3, reg=None, loss='categorical_crossentropy')\n",
    "            #print(acc)\n",
    "            accuracy.append([acc_mse, acc_cce])\n",
    "            layer_state.append([l1, l2, l3])\n",
    "            if(l3==None):\n",
    "                print(\"%d / %d / None \\t : %f\" % (l1, l2, acc_mse))\n",
    "                print(\"%d / %d / None \\t : %f\" % (l1, l2, acc_cce))\n",
    "                print(\"%d / %d / None \\t : %f\" % (l1, l2, acc_cce-acc_mse))\n",
    "                print(\"\\n\\n\")\n",
    "            else:\n",
    "                print(\"%d / %d / %d \\t : %f\" % (l1, l2, l3, acc_mse))\n",
    "                print(\"%d / %d / %d \\t : %f\" % (l1, l2, l3, acc_cce))\n",
    "                print(\"%d / %d / %d \\t : %f\" % (l1, l2, l3, acc_cce-acc_mse))\n",
    "                print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = []\n",
    "for acc in accuracy:\n",
    "    for a in acc:\n",
    "        total.append(a)\n",
    "print(max(total))\n",
    "print(total.index(max(total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(accuracy)):\n",
    "    l1, l2, l3 = layer_state[i]:\n",
    "        print(\"%d / %d / %d\" % (l1, l2, l3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HnjsUOFwb2AF"
   },
   "outputs": [],
   "source": [
    "learn(ROUND=5, SAMPLE_NUM=10000, layer1=128, layer2=1024, reg=tf.keras.regularizers.L1(0.001))\n",
    "learn(ROUND=5, SAMPLE_NUM=10000, layer1=128, layer2=1024, reg=tf.keras.regularizers.L2(0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bVPi-uI8cN9a"
   },
   "outputs": [],
   "source": [
    "def learn_l1_reg(ROUND, l1, l2, weight):\n",
    "  tr_X, tr_t = gen(sample_num, ROUND)\n",
    "  te_X, te_t = gen(test_sample_num, ROUND)\n",
    "\n",
    "  #weight = [0.0001, 0.001, 0.01, 0.1]\n",
    "  result = []\n",
    "  for w in weight:\n",
    "    model = MLP(l1, l2, reg=tf.keras.regularizers.L1(w))\n",
    "    model.fit(tr_X, tr_t, epochs=epoch_size, batch_size=batch_size, validation_split = validation_split, verbose=0)\n",
    "    #print(\"\\n\\n\")\n",
    "    result.append(model.evaluate(te_X, te_t))\n",
    "    #print(\"\\n\\n\")\n",
    "    #model.summary()\n",
    "\n",
    "  return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8O6IbxmpuKaq",
    "outputId": "1ac848d2-5174-4695-a127-a407cb46b67b"
   },
   "outputs": [],
   "source": [
    "weight = [0.0001, 0.001, 0.01, 0.1]\n",
    "result = learn_l1_reg(5, 128, 1024, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vpl90qwzuU9H"
   },
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANGE1 = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MVTYS1K6uVn2"
   },
   "outputs": [],
   "source": [
    "weight2 = []\n",
    "for i in range(RANGE1):\n",
    "    weight2.append(i/10000.0)\n",
    "print(weight2)\n",
    "result = learn_l1_reg(5, 128, 1024, weight2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "for i in range(RANGE1):\n",
    "    accuracy.append(result[i][1])\n",
    "maxidx1 = accuracy.index(max(accuracy))\n",
    "print(maxidx1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(RANGE1)], accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight2 = []\n",
    "RANGE2 = 100\n",
    "base = (maxidx1-0.5)/10000.0\n",
    "for i in range(RANGE2):\n",
    "    weight2.append(base+(i/(10000.0*RANGE2)))\n",
    "print(weight2)\n",
    "result = learn_l1_reg(5, 128, 1024, weight2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit = 1/10000.0\n",
    "start = (maxidx1-1)*unit\n",
    "end = (maxidx1+1)*unit\n",
    "step_num = 100\n",
    "step = unit/step_num\n",
    "weight2 = np.arange(start, end, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = learn_l1_reg(5, 128, 1024, weight2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "for i in range(step_num):\n",
    "    accuracy.append(result[i][1])\n",
    "maxidx2 = accuracy.ind|ex(max(accuracy))\n",
    "print(maxidx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(weight2, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
