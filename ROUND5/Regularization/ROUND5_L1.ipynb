{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NXVzTjGSQpAx",
    "outputId": "31cbc208-81e9-4251-95e5-a53c46575581"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 80-bit Key Vectors:\n",
      "Success 0x5579c1387b228445\n",
      "Success 0xe72c46c0f5945049\n",
      "Success 0xa112ffc72f68417b\n",
      "Success 0x3333dcd3213210d2\n",
      "0x5579c1387b228445\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "https://github.com/inmcm/present_cipher/tree/master/python\n",
    "\"\"\"\n",
    "# coding: utf-8\n",
    "from __future__ import print_function\n",
    "\n",
    "s_box = (0xC, 0x5, 0x6, 0xB, 0x9, 0x0, 0xA, 0xD, 0x3, 0xE, 0xF, 0x8, 0x4, 0x7, 0x1, 0x2)\n",
    "\n",
    "inv_s_box = (0x5, 0xE, 0xF, 0x8, 0xC, 0x1, 0x2, 0xD, 0xB, 0x4, 0x6, 0x3, 0x0, 0x7, 0x9, 0xA)\n",
    "\n",
    "p_layer_order = [0, 16, 32, 48, 1, 17, 33, 49, 2, 18, 34, 50, 3, 19, 35, 51, 4, 20, 36, 52, 5, 21, 37, 53, 6, 22, 38,\n",
    "                 54, 7, 23, 39, 55, 8, 24, 40, 56, 9, 25, 41, 57, 10, 26, 42, 58, 11, 27, 43, 59, 12, 28, 44, 60, 13,\n",
    "                 29, 45, 61, 14, 30, 46, 62, 15, 31, 47, 63]\n",
    "\n",
    "block_size = 64\n",
    "\n",
    "ROUND_LIMIT = 32\n",
    "\n",
    "\n",
    "def round_function(state, key):\n",
    "    new_state = state ^ key\n",
    "    state_nibs = []\n",
    "    for x in range(0, block_size, 4):\n",
    "        nib = (new_state >> x) & 0xF\n",
    "        sb_nib = s_box[nib]\n",
    "        state_nibs.append(sb_nib)\n",
    "    # print(state_nibs)\n",
    "\n",
    "    state_bits = []\n",
    "    for y in state_nibs:\n",
    "        nib_bits = [1 if t == '1'else 0 for t in format(y, '04b')[::-1]]\n",
    "        state_bits += nib_bits\n",
    "    # print(state_bits)\n",
    "    # print(len(state_bits))\n",
    "\n",
    "    state_p_layer = [0 for _ in range(64)]\n",
    "    for p_index, std_bits in enumerate(state_bits):\n",
    "        state_p_layer[p_layer_order[p_index]] = std_bits\n",
    "\n",
    "    # print(len(state_p_layer), state_p_layer)\n",
    "\n",
    "    round_output = 0\n",
    "    for index, ind_bit in enumerate(state_p_layer):\n",
    "        round_output += (ind_bit << index)\n",
    "\n",
    "    # print(format(round_output, '#016X'))\n",
    "\n",
    "    # print('')\n",
    "    return round_output\n",
    "\n",
    "\n",
    "def key_function_80(key, round_count):\n",
    "    # print('Start: ', hex(key))\n",
    "    # print('')\n",
    "\n",
    "    r = [1 if t == '1'else 0 for t in format(key, '080b')[::-1]]\n",
    "\n",
    "    # print('k bits:', r)\n",
    "    # print('')\n",
    "\n",
    "    h = r[-61:] + r[:-61]\n",
    "\n",
    "    # print('s bits:', h)\n",
    "    # print('')\n",
    "\n",
    "    round_key_int = 0\n",
    "    # print('init round int:', hex(round_key_int))\n",
    "    for index, ind_bit in enumerate(h):\n",
    "        round_key_int += (ind_bit << index)\n",
    "        # print('round:',index, '-', hex(round_key_int))\n",
    "\n",
    "    # print('round_key_int', hex(round_key_int))\n",
    "    # print('')\n",
    "\n",
    "    upper_nibble = round_key_int >> 76\n",
    "\n",
    "    # print('upper_nibble:', upper_nibble)\n",
    "\n",
    "    upper_nibble = s_box[upper_nibble]\n",
    "\n",
    "    # print('upper_nibble sboxed', hex(upper_nibble))\n",
    "\n",
    "    xor_portion = ((round_key_int >> 15) & 0x1F) ^ round_count\n",
    "    # print('Count:', round_count)\n",
    "    # print('XOR Value:', xor_portion)\n",
    "\n",
    "    # print('Before:', hex(round_key_int))\n",
    "    round_key_int = (round_key_int & 0x0FFFFFFFFFFFFFF07FFF) + (upper_nibble << 76) + (xor_portion << 15)\n",
    "    # print('After: ', hex(round_key_int))\n",
    "\n",
    "    return round_key_int\n",
    "\n",
    "\n",
    "\n",
    "test_vectors_80 = {1:(0x00000000000000000000, 0x0000000000000000, 0x5579C1387B228445),\n",
    "                2:(0xFFFFFFFFFFFFFFFFFFFF, 0x0000000000000000, 0xE72C46C0F5945049),\n",
    "                3:(0x00000000000000000000, 0xFFFFFFFFFFFFFFFF, 0xA112FFC72F68417B),\n",
    "                4:(0xFFFFFFFFFFFFFFFFFFFF, 0xFFFFFFFFFFFFFFFF, 0x3333DCD3213210D2)}\n",
    "\n",
    "print('Testing 80-bit Key Vectors:')\n",
    "\n",
    "\n",
    "\n",
    "for test_case in test_vectors_80:\n",
    "\n",
    "    key_schedule = []\n",
    "    current_round_key = test_vectors_80[test_case][0]\n",
    "    round_state = test_vectors_80[test_case][1]\n",
    "\n",
    "    # Key schedule\n",
    "    for rnd_cnt in range(ROUND_LIMIT):\n",
    "        # print(format(round_key, '020X'))\n",
    "        # print(format(round_key >> 16, '016X'))\n",
    "        key_schedule.append(current_round_key >> 16)\n",
    "        current_round_key = key_function_80(current_round_key, rnd_cnt + 1)\n",
    "\n",
    "    for rnd in range(ROUND_LIMIT - 1):\n",
    "        # print('Round:', rnd)\n",
    "        # print('State:', format(round_state, '016X'))\n",
    "        # print('R_Key:', format(key_schedule[rnd], '016X'))\n",
    "        round_state = round_function(round_state, key_schedule[rnd])\n",
    "\n",
    "    round_state ^= key_schedule[ROUND_LIMIT-1]\n",
    "\n",
    "    if round_state == test_vectors_80[test_case][2]:\n",
    "        print('Success', hex(round_state))\n",
    "    else:\n",
    "        print('Failure', hex(round_state))\n",
    "        \n",
    "def PRESENT(P, K, ROUND):\n",
    "    key_schedule = []\n",
    "    current_round_key = K\n",
    "    round_state = P\n",
    "    \n",
    "    if(ROUND==0):\n",
    "        return P\n",
    "\n",
    "    for rnd_cnt in range(ROUND):\n",
    "        key_schedule.append(current_round_key >> 16)\n",
    "        current_round_key = key_function_80(current_round_key, rnd_cnt + 1)\n",
    "\n",
    "    for rnd in range(ROUND - 1):\n",
    "        round_state = round_function(round_state, key_schedule[rnd])\n",
    "\n",
    "    round_state ^= key_schedule[ROUND-1]\n",
    "    \n",
    "    return round_state\n",
    "\n",
    "C = PRESENT(0x0, 0x0, ROUND=32)\n",
    "print(hex(C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AwZVgDHVQpAz"
   },
   "outputs": [],
   "source": [
    "Wang_diff = [0x7000000000007000, 0x0700000000000700, 0x0070000000000070, 0x0007000000000007]\n",
    "BLOCK_SIZE = 64\n",
    "\n",
    "ROUND_global = 6\n",
    "sample_num = 10000\n",
    "test_sample_num = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xJrNRizYQpA0"
   },
   "outputs": [],
   "source": [
    "def gen(sample_num, ROUND):\n",
    "    P_set = []\n",
    "    K_set = []\n",
    "    for i in range(sample_num):\n",
    "        P_set.append(random.randrange(0,2**64))\n",
    "        #print(\"%x\" % P_set[i])\n",
    "        K_set.append(random.randrange(0,2**80))\n",
    "        #print(\"%x\" % K_set[i])\n",
    "\n",
    "    C_diff_set = []\n",
    "    C_diff_label = []\n",
    "    for i in range(sample_num):\n",
    "        P = P_set[i]\n",
    "        K = K_set[i]\n",
    "        C = PRESENT(P, K, ROUND)\n",
    "        for j in range(4):\n",
    "            Cj = PRESENT(P^Wang_diff[j], K, ROUND)\n",
    "            C_diff = C^Cj\n",
    "            #print(C_diff)\n",
    "            C_diff_set.append(C_diff)\n",
    "            temp = [0, 0, 0, 0]\n",
    "            temp[j] = 1\n",
    "            C_diff_label.append(temp)\n",
    "\n",
    "    tr_X = []\n",
    "    for C_diff in C_diff_set:\n",
    "        A = []\n",
    "        for j in range(BLOCK_SIZE):\n",
    "            A.append((C_diff>>j)&1)\n",
    "        tr_X.append(A)\n",
    "        #print(A)\n",
    "    tr_X = np.array(tr_X)\n",
    "\n",
    "    tr_X = []\n",
    "    for C_diff in C_diff_set:\n",
    "        A = []\n",
    "        for j in range(BLOCK_SIZE):\n",
    "            A.append((C_diff>>j)&1)\n",
    "        tr_X.append(A)\n",
    "        #print(A)\n",
    "    tr_X = np.array(tr_X)\n",
    "    tr_t = np.array(C_diff_label)\n",
    "\n",
    "    ind = np.arange(len(tr_X))\n",
    "    np.random.shuffle(ind)\n",
    "    tr_X = tr_X[ind]\n",
    "    tr_t = tr_t[ind]\n",
    "    \n",
    "    return tr_X, tr_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_gen():\n",
    "    SAMPLE_NUM_RANGE = [10000, 50000, 100000]\n",
    "    ROUND_RANGE = [3, 4, 5, 6, 7, 8]\n",
    "    for sn in SAMPLE_NUM_RANGE:\n",
    "        for rn in ROUND_RANGE:\n",
    "            tr_X, tr_t = gen(sn, rn)\n",
    "            np.save(\"ROUND %d SAMPLE %d Dataset\" % (rn, sn), tr_X)\n",
    "            np.save(\"ROUND %d SAMPLE %d Label\" % (rn, sn), tr_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Wk0Lr4ReQpA1"
   },
   "outputs": [],
   "source": [
    "def test_sample_gen():\n",
    "    TEST_SMAPLE_NUM = 10000\n",
    "    for rn in ROUND_RANGE:\n",
    "        te_X, te_t = gen(TEST_SMAPLE_NUM, rn)\n",
    "        np.save(\"ROUND %d TEST_SAMPLE Dataset\" % (rn), te_X)\n",
    "        np.save(\"ROUND %d TEST_SAMPLE Label\" % (rn), te_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "O9XPTV7FQpA1"
   },
   "outputs": [],
   "source": [
    "def load_sample(SAMPLE_NUM, ROUND_NUM):\n",
    "    tr_X = np.load(\"ROUND %d SAMPLE %d Dataset.npy\" % (ROUND_NUM, SAMPLE_NUM))\n",
    "    tr_t = np.load(\"ROUND %d SAMPLE %d Label.npy\" % (ROUND_NUM, SAMPLE_NUM))\n",
    "    return tr_X, tr_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_sample(ROUND_NUM):\n",
    "    te_X = np.load(\"ROUND %d TEST_SAMPLE Dataset.npy\" % (ROUND_NUM))\n",
    "    te_t = np.load(\"ROUND %d TEST_SAMPLE Label.npy\" % (ROUND_NUM))\n",
    "    return te_X, te_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RfujwI1AQpA1"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, layer1=128, layer2=1028, layer3=None, reg=None, learning_rate=0.001):\n",
    "        self.layers = self._build_layers(layer1, layer2, layer3, reg)\n",
    "        self.model = tf.keras.Sequential(self.layers) \n",
    "        self.model.compile(optimizer=tf.keras.optimizers.Adam(lr=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    def _build_layers(self, layer1, layer2, layer3, reg):\n",
    "        if layer3==None:\n",
    "            layers = [\n",
    "                tf.keras.layers.Flatten(input_shape=(64,)),\n",
    "                tf.keras.layers.Dense(layer1, activation='relu', kernel_regularizer=reg),\n",
    "                tf.keras.layers.Dense(layer2, activation='relu', kernel_regularizer=reg),\n",
    "                #tf.keras.layers.Dense(layer3, activation='relu', kernel_regularizer=reg),\n",
    "                tf.keras.layers.Dense(4, activation='softmax')\n",
    "            ]\n",
    "        else:\n",
    "            layers = [\n",
    "                tf.keras.layers.Flatten(input_shape=(64,)),\n",
    "                tf.keras.layers.Dense(layer1, activation='relu', kernel_regularizer=reg),\n",
    "                tf.keras.layers.Dense(layer2, activation='relu', kernel_regularizer=reg),\n",
    "                tf.keras.layers.Dense(layer3, activation='relu', kernel_regularizer=reg),\n",
    "                tf.keras.layers.Dense(4, activation='softmax')\n",
    "            ]\n",
    "        return layers\n",
    "\n",
    "    #그냥 cross entropy를 그대로 정의함\n",
    "    def _my_loss(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.int32) #float32 => int32로 casting #None, 1\n",
    "        y_true = tf.squeeze(tf.one_hot(y_true, depth=10, dtype=tf.float32), 1) # one_hot encoding #None, 1, 10 #quezze => 1을 없애줌 => None, 10\n",
    "        y_pred = tf.nn.softmax(y_pred, 1) # 한 축에 대해 softmax를 적용해라 #1 => 열을 의미 #즉, 한 행에 있는 값을 다 더하면 1이 되도록 만들어줌\n",
    "\n",
    "        #cross entropy 그대로 적용\n",
    "        #-sum t*log y 한 후에 평균 냄\n",
    "        return -tf.reduce_mean(tf.reduce_sum(\n",
    "                tf.multiply(y_true, tf.math.log(y_pred)), 1))\n",
    "\n",
    "    def _my_accuracy(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.int32)\n",
    "        y_true = tf.squeeze(tf.one_hot(y_true, depth=10, dtype=tf.float32), 1)\n",
    "        #argmax를 그대로 이용\n",
    "        return tf.reduce_mean(\n",
    "            tf.cast(\n",
    "                tf.equal(tf.argmax(y_true, 1), tf.argmax(y_pred, 1)), tf.float32))\n",
    "\n",
    "    def fit(self, x, t, epochs, batch_size=None, validation_split=0.0, verbose=1, shuffle=False, workers=2):\n",
    "        self.model.fit(x, t, epochs=epochs, batch_size=batch_size, validation_split=validation_split, verbose=verbose, shuffle=shuffle, workers=workers)\n",
    "    \n",
    "    def evaluate(self, x=None, y=None, verbose=1):\n",
    "        return self.model.evaluate(x=x, y=y, verbose=verbose)\n",
    "    \n",
    "    def summary(self):\n",
    "        self.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mhQTZ7KwQpA2",
    "outputId": "85b3d255-445f-463d-ba53-122475dfd771"
   },
   "outputs": [],
   "source": [
    "#Config\n",
    "ROUND = 6\n",
    "SAMPLE_NUM = 10000\n",
    "test_sample_num = 10000\n",
    "ITERATION = 5\n",
    "\n",
    "#Fix\n",
    "batch_size = 200\n",
    "epoch_size = 25\n",
    "validation_split = 0.3\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "w53eKengQpA2"
   },
   "outputs": [],
   "source": [
    "def learn(ROUND, SAMPLE_NUM, layer1, layer2, layer3=None, reg=None, learning_rate=0.001):\n",
    "    tr_X, tr_t = load_sample(SAMPLE_NUM=SAMPLE_NUM, ROUND_NUM=ROUND)\n",
    "    te_X, te_t = load_test_sample(ROUND_NUM=ROUND)\n",
    "    accuracy = []\n",
    "    for i in range(ITERATION):\n",
    "        model = MLP(layer1, layer2, layer3, reg, learning_rate)\n",
    "        model.fit(tr_X, tr_t, epochs=epoch_size, batch_size=batch_size, validation_split = validation_split, shuffle=True, verbose=0)\n",
    "        accuracy.append(model.evaluate(te_X, te_t, verbose=0)[1])\n",
    "    avg = np.mean(np.array(accuracy))\n",
    "    #print(\"average : %f\" % avg)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_reg_L1(ROUND=ROUND, l1=128, l2=512, weight=[0.0001]):\n",
    "    tr_X, tr_t = gen(sample_num, ROUND)\n",
    "    te_X, te_t = gen(test_sample_num, ROUND)\n",
    "\n",
    "    result = []\n",
    "    result_weight = []\n",
    "    for w in weight:\n",
    "        accuracy = []\n",
    "        for i in range(ITERATION):\n",
    "            model = MLP(layer1=l1, layer2=l2, reg=tf.keras.regularizers.L1(w))\n",
    "            model.fit(tr_X, tr_t, epochs=epoch_size, batch_size=batch_size, validation_split = validation_split, verbose=0)\n",
    "            accuracy.append(model.evaluate(te_X, te_t)[1])\n",
    "        avg_acc = np.mean(np.array(accuracy))\n",
    "        result.append(avg_acc)\n",
    "        result_weight.append(w)\n",
    "    return result, result_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.2864 - accuracy: 0.4177\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.2848 - accuracy: 0.4212\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.2810 - accuracy: 0.4273\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.2872 - accuracy: 0.4214\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.2842 - accuracy: 0.4230\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2960 - accuracy: 0.3797\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.2845 - accuracy: 0.3839\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2883 - accuracy: 0.3785\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2872 - accuracy: 0.3776\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2779 - accuracy: 0.3875\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.4731 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.4731 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4729 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4719 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.4724 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 2.2836 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 2.2905 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 2.2825 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 2.2859 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 2.2831 - accuracy: 0.2500\n",
      "[0.42213499546051025, 0.38143000602722166, 0.25, 0.25]\n",
      "[0.0001, 0.001, 0.01, 0.1]\n"
     ]
    }
   ],
   "source": [
    "weight0 = [0.0001, 0.001, 0.01, 0.1]\n",
    "accuracy, accuracy_weight = learn_reg_L1(ROUND=5, l1=128, l2=512, weight=weight0)\n",
    "maxidx0 = accuracy.index(max(accuracy))\n",
    "print(accuracy)\n",
    "print(accuracy_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009, 0.001, 0.0011, 0.0012, 0.0013, 0.0014, 0.0015, 0.0016, 0.0017, 0.0018, 0.0019, 0.002, 0.0021, 0.0022, 0.0023, 0.0024, 0.0025, 0.0026, 0.0027, 0.0028, 0.0029, 0.003, 0.0031, 0.0032, 0.0033, 0.0034, 0.0035, 0.0036, 0.0037, 0.0038, 0.0039, 0.004, 0.0041, 0.0042, 0.0043, 0.0044, 0.0045, 0.0046, 0.0047, 0.0048, 0.0049, 0.005, 0.0051, 0.0052, 0.0053, 0.0054, 0.0055, 0.0056, 0.0057, 0.0058, 0.0059, 0.006, 0.0061, 0.0062, 0.0063, 0.0064, 0.0065, 0.0066, 0.0067, 0.0068, 0.0069, 0.007, 0.0071, 0.0072, 0.0073, 0.0074, 0.0075, 0.0076, 0.0077, 0.0078, 0.0079, 0.008, 0.0081, 0.0082, 0.0083, 0.0084, 0.0085, 0.0086, 0.0087, 0.0088, 0.0089, 0.009, 0.0091, 0.0092, 0.0093, 0.0094, 0.0095, 0.0096, 0.0097, 0.0098, 0.0099]\n"
     ]
    }
   ],
   "source": [
    "RANGE1 = 100\n",
    "weight2 = []\n",
    "for i in range(RANGE1):\n",
    "    weight2.append(i/10000.0)\n",
    "print(weight2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "MVTYS1K6uVn2",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.6683 - accuracy: 0.3778\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.6034 - accuracy: 0.3864\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.6196 - accuracy: 0.3801\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.6225 - accuracy: 0.3782\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.6321 - accuracy: 0.3778\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2912 - accuracy: 0.4216\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.2841 - accuracy: 0.4248\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2946 - accuracy: 0.4185\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.3197 - accuracy: 0.4098\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2839 - accuracy: 0.4209\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2241 - accuracy: 0.4248\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2246 - accuracy: 0.4293\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2309 - accuracy: 0.4277\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2286 - accuracy: 0.4236\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2347 - accuracy: 0.4220\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2199 - accuracy: 0.4263\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2320 - accuracy: 0.4184\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.2233 - accuracy: 0.4226\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.2248 - accuracy: 0.4220\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2268 - accuracy: 0.4245\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2434 - accuracy: 0.4089\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.2228 - accuracy: 0.4175\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2348 - accuracy: 0.4171\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.2467 - accuracy: 0.4146\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2263 - accuracy: 0.4220\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2499 - accuracy: 0.4028\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2447 - accuracy: 0.4064\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.2446 - accuracy: 0.4094\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.2324 - accuracy: 0.4106\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.2413 - accuracy: 0.4126\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2554 - accuracy: 0.4029\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2718 - accuracy: 0.3893\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2699 - accuracy: 0.3915\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2423 - accuracy: 0.4110\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2581 - accuracy: 0.3950\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2764 - accuracy: 0.3918\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2782 - accuracy: 0.3868\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2604 - accuracy: 0.4011\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2568 - accuracy: 0.3985\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2606 - accuracy: 0.3969\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2854 - accuracy: 0.3832\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2780 - accuracy: 0.3893\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2773 - accuracy: 0.3874\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2790 - accuracy: 0.3887\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2782 - accuracy: 0.3884\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2793 - accuracy: 0.3890\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.2835 - accuracy: 0.3866\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2813 - accuracy: 0.3880\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2800 - accuracy: 0.3874\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2820 - accuracy: 0.3862\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2817 - accuracy: 0.3905\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2862 - accuracy: 0.3859\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2833 - accuracy: 0.3859\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2865 - accuracy: 0.3846\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.2781 - accuracy: 0.3913\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2905 - accuracy: 0.3842\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 1.2923 - accuracy: 0.3835\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2872 - accuracy: 0.3835\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2878 - accuracy: 0.3862\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2862 - accuracy: 0.3836\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2945 - accuracy: 0.3812\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2883 - accuracy: 0.3856\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.2960 - accuracy: 0.3805\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2985 - accuracy: 0.3823\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2941 - accuracy: 0.3780\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2927 - accuracy: 0.3868\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3000 - accuracy: 0.3799\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.2962 - accuracy: 0.3834\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 1.2956 - accuracy: 0.3812\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2997 - accuracy: 0.3800\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.2956 - accuracy: 0.3820\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2981 - accuracy: 0.3818\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3224 - accuracy: 0.3729\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.2953 - accuracy: 0.3807\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2982 - accuracy: 0.3815\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2965 - accuracy: 0.3803\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3018 - accuracy: 0.3763\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2985 - accuracy: 0.3800\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.3031 - accuracy: 0.3806\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3225 - accuracy: 0.3732\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3250 - accuracy: 0.3728\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3132 - accuracy: 0.3729\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3021 - accuracy: 0.3780\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3018 - accuracy: 0.3794\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3263 - accuracy: 0.3712\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3263 - accuracy: 0.3729\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3215 - accuracy: 0.3671\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3259 - accuracy: 0.3735\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3273 - accuracy: 0.3728\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3021 - accuracy: 0.3803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3067 - accuracy: 0.3771\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3290 - accuracy: 0.3714\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3286 - accuracy: 0.3730\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3225 - accuracy: 0.3676\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3046 - accuracy: 0.3812\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3193 - accuracy: 0.3584\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3220 - accuracy: 0.3494\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3302 - accuracy: 0.3708\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3190 - accuracy: 0.3753\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3153 - accuracy: 0.3592\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3337 - accuracy: 0.3682\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3129 - accuracy: 0.3769\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3338 - accuracy: 0.3447\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3357 - accuracy: 0.3491\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3386 - accuracy: 0.3470\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3372 - accuracy: 0.3680\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3348 - accuracy: 0.3711\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3131 - accuracy: 0.3772\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3362 - accuracy: 0.3687\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3371 - accuracy: 0.3446\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3373 - accuracy: 0.3698\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3167 - accuracy: 0.3762\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3364 - accuracy: 0.3452\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3407 - accuracy: 0.3419\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3426 - accuracy: 0.3449\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3389 - accuracy: 0.3683\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3426 - accuracy: 0.3408\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3403 - accuracy: 0.3663\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3202 - accuracy: 0.3760\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3430 - accuracy: 0.3417\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3435 - accuracy: 0.3473\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3443 - accuracy: 0.3420\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3440 - accuracy: 0.3413\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3479 - accuracy: 0.3512\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3406 - accuracy: 0.3680\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3458 - accuracy: 0.3430\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3455 - accuracy: 0.3431\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3450 - accuracy: 0.3418\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3465 - accuracy: 0.3425\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3442 - accuracy: 0.3450\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3468 - accuracy: 0.3410\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3475 - accuracy: 0.3440\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3470 - accuracy: 0.3411\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3446 - accuracy: 0.3459\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3480 - accuracy: 0.3399\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3481 - accuracy: 0.3413\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3483 - accuracy: 0.3417\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3486 - accuracy: 0.3443\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3475 - accuracy: 0.3412\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.3482 - accuracy: 0.34 - 5s 4ms/step - loss: 1.3482 - accuracy: 0.3442\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4100 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3494 - accuracy: 0.3431\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3485 - accuracy: 0.3412\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3494 - accuracy: 0.3411\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3489 - accuracy: 0.3415\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 1.3502 - accuracy: 0.3407\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3504 - accuracy: 0.3431\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 1.3506 - accuracy: 0.3671\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3507 - accuracy: 0.3422\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3504 - accuracy: 0.3411\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4116 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3485 - accuracy: 0.3704\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4116 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3520 - accuracy: 0.3428\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3515 - accuracy: 0.3429\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3527 - accuracy: 0.3415\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4126 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3519 - accuracy: 0.3422\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 1.3538 - accuracy: 0.3424\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3505 - accuracy: 0.3424\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 1.3543 - accuracy: 0.3427\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3544 - accuracy: 0.3428\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3537 - accuracy: 0.3427\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3543 - accuracy: 0.3413\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4133 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3536 - accuracy: 0.3418\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3556 - accuracy: 0.3414\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4143 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3555 - accuracy: 0.3428\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4142 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4153 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3564 - accuracy: 0.3431\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4152 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4153 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3552 - accuracy: 0.3418\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4161 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3569 - accuracy: 0.3414\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4162 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3571 - accuracy: 0.3432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4158 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3596 - accuracy: 0.3428\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4168 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4167 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3580 - accuracy: 0.3433\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 1.3591 - accuracy: 0.3426\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4176 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4178 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3600 - accuracy: 0.3426\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4177 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3599 - accuracy: 0.3423\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3615 - accuracy: 0.3417\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4185 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3611 - accuracy: 0.3424\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3589 - accuracy: 0.3428\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3615 - accuracy: 0.3431\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4196 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3607 - accuracy: 0.3422\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4196 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4195 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.4195 - accuracy: 0.24 - 5s 4ms/step - loss: 1.4195 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4203 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4204 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4204 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4203 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4203 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4211 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4213 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4209 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4211 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3643 - accuracy: 0.3417\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4222 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4219 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4218 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4219 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 1.4219 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4231 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 1.4230 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4229 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4231 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 1.4231 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 1.4239 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4237 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4236 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4240 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4241 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 1.4244 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4246 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4250 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 1.4246 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4247 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4255 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4254 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4257 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4254 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4256 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4264 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4268 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4265 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4260 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 1.4269 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4277 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4276 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.4274 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.4273 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.4271 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.4283 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.4281 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.4281 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.4284 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.4281 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.4293 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.4293 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.4291 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.4290 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 992us/step - loss: 1.4294 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 855us/step - loss: 1.4299 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 846us/step - loss: 1.4299 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 896us/step - loss: 1.4297 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 883us/step - loss: 1.4300 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 879us/step - loss: 1.4306 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 928us/step - loss: 1.4309 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 936us/step - loss: 1.4311 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 917us/step - loss: 1.4312 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 915us/step - loss: 1.4307 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 922us/step - loss: 1.4311 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 915us/step - loss: 1.4319 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 928us/step - loss: 1.4318 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 914us/step - loss: 1.4320 - accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 1s 904us/step - loss: 1.4320 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 889us/step - loss: 1.4317 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 922us/step - loss: 1.4331 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 906us/step - loss: 1.4326 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 901us/step - loss: 1.4323 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 949us/step - loss: 1.4328 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 890us/step - loss: 1.4326 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 868us/step - loss: 1.4337 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 881us/step - loss: 1.4337 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 824us/step - loss: 1.4335 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 828us/step - loss: 1.4333 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 832us/step - loss: 1.4331 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 798us/step - loss: 1.4345 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 834us/step - loss: 1.4340 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 857us/step - loss: 1.4341 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 853us/step - loss: 1.4347 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 876us/step - loss: 1.4342 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 917us/step - loss: 1.4354 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 919us/step - loss: 1.4351 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 922us/step - loss: 1.4354 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 937us/step - loss: 1.4350 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 898us/step - loss: 1.4353 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 916us/step - loss: 1.4360 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 895us/step - loss: 1.4356 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 926us/step - loss: 1.4365 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 909us/step - loss: 1.4362 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 909us/step - loss: 1.4362 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 918us/step - loss: 1.4370 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 903us/step - loss: 1.4371 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 922us/step - loss: 1.4372 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 933us/step - loss: 1.4366 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 898us/step - loss: 1.4373 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 892us/step - loss: 1.4377 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 922us/step - loss: 1.4380 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 919us/step - loss: 1.4380 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 919us/step - loss: 1.4377 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 935us/step - loss: 1.4379 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 902us/step - loss: 1.4390 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 905us/step - loss: 1.4393 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 945us/step - loss: 1.4392 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 906us/step - loss: 1.4386 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 906us/step - loss: 1.4388 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 910us/step - loss: 1.4401 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 929us/step - loss: 1.4392 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 898us/step - loss: 1.4397 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 896us/step - loss: 1.4394 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 913us/step - loss: 1.4393 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 900us/step - loss: 1.4402 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 890us/step - loss: 1.4401 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 875us/step - loss: 1.4413 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 869us/step - loss: 1.4406 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 864us/step - loss: 1.4408 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 841us/step - loss: 1.4419 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 823us/step - loss: 1.4416 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 818us/step - loss: 1.4415 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 854us/step - loss: 1.4417 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 810us/step - loss: 1.4411 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 813us/step - loss: 1.4429 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 836us/step - loss: 1.4425 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 851us/step - loss: 1.4423 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 843us/step - loss: 1.4428 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 870us/step - loss: 1.4422 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 869us/step - loss: 1.4433 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 900us/step - loss: 1.4428 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 922us/step - loss: 1.4432 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 904us/step - loss: 1.4437 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 911us/step - loss: 1.4431 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 944us/step - loss: 1.4435 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 904us/step - loss: 1.4441 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.4437 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 932us/step - loss: 1.4439 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 927us/step - loss: 1.4443 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 908us/step - loss: 1.4450 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 933us/step - loss: 1.4449 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 902us/step - loss: 1.4446 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 908us/step - loss: 1.4446 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 938us/step - loss: 1.4449 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 903us/step - loss: 1.4462 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 906us/step - loss: 1.4459 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 937us/step - loss: 1.4461 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 924us/step - loss: 1.4450 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 913us/step - loss: 1.4461 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 938us/step - loss: 1.4467 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.4471 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 913us/step - loss: 1.4468 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 923us/step - loss: 1.4465 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 904us/step - loss: 1.4466 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 901us/step - loss: 1.4474 - accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 1s 876us/step - loss: 1.4476 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 879us/step - loss: 1.4473 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 894us/step - loss: 1.4476 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 862us/step - loss: 1.4477 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 846us/step - loss: 1.4487 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 859us/step - loss: 1.4486 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 825us/step - loss: 1.4481 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 820us/step - loss: 1.4485 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 837us/step - loss: 1.4482 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 824us/step - loss: 1.4494 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 838us/step - loss: 1.4490 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 859us/step - loss: 1.4495 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 860us/step - loss: 1.4492 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 831us/step - loss: 1.4496 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 870us/step - loss: 1.4499 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 901us/step - loss: 1.4508 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 905us/step - loss: 1.4501 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 935us/step - loss: 1.4506 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 904us/step - loss: 1.4499 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 905us/step - loss: 1.4507 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 937us/step - loss: 1.4513 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 909us/step - loss: 1.4512 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 905us/step - loss: 1.4513 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 918us/step - loss: 1.4508 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 902us/step - loss: 1.4517 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 898us/step - loss: 1.4523 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 931us/step - loss: 1.4526 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.4523 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 924us/step - loss: 1.4525 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 916us/step - loss: 1.4525 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 907us/step - loss: 1.4523 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 940us/step - loss: 1.4527 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 930us/step - loss: 1.4527 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 908us/step - loss: 1.4531 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 934us/step - loss: 1.4534 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 906us/step - loss: 1.4535 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 945us/step - loss: 1.4538 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 928us/step - loss: 1.4533 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 992us/step - loss: 1.4533 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 934us/step - loss: 1.4549 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.4545 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 937us/step - loss: 1.4548 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 895us/step - loss: 1.4550 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 877us/step - loss: 1.4543 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 890us/step - loss: 1.4551 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 854us/step - loss: 1.4556 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 834us/step - loss: 1.4560 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 848us/step - loss: 1.4561 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 836us/step - loss: 1.4552 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 845us/step - loss: 1.4569 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 835us/step - loss: 1.4561 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 812us/step - loss: 1.4564 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 870us/step - loss: 1.4564 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 886us/step - loss: 1.4560 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 941us/step - loss: 1.4575 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 911us/step - loss: 1.4567 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 920us/step - loss: 1.4568 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 944us/step - loss: 1.4578 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 924us/step - loss: 1.4570 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 943us/step - loss: 1.4578 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 908us/step - loss: 1.4582 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 900us/step - loss: 1.4584 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 939us/step - loss: 1.4583 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 916us/step - loss: 1.4583 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 929us/step - loss: 1.4595 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 909us/step - loss: 1.4589 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 910us/step - loss: 1.4592 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 944us/step - loss: 1.4588 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 909us/step - loss: 1.4587 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 928us/step - loss: 1.4601 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 904us/step - loss: 1.4595 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 910us/step - loss: 1.4601 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 936us/step - loss: 1.4599 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 906us/step - loss: 1.4594 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 906us/step - loss: 1.4606 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 896us/step - loss: 1.4610 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 874us/step - loss: 1.4607 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 874us/step - loss: 1.4604 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 836us/step - loss: 1.4614 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 846us/step - loss: 1.4614 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 835us/step - loss: 1.4618 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 860us/step - loss: 1.4617 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 878us/step - loss: 1.4614 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 897us/step - loss: 1.4621 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 932us/step - loss: 1.4629 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 905us/step - loss: 1.4624 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.4622 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 927us/step - loss: 1.4630 - accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 1s 900us/step - loss: 1.4631 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 932us/step - loss: 1.4633 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 918us/step - loss: 1.4638 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.4644 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 915us/step - loss: 1.4637 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 920us/step - loss: 1.4637 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 937us/step - loss: 1.4651 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 907us/step - loss: 1.4643 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 906us/step - loss: 1.4644 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 925us/step - loss: 1.4644 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 913us/step - loss: 1.4647 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 953us/step - loss: 1.4655 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 922us/step - loss: 1.4655 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 922us/step - loss: 1.4651 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 920us/step - loss: 1.4650 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 916us/step - loss: 1.4652 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.4666 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 908us/step - loss: 1.4660 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 955us/step - loss: 1.4663 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 918us/step - loss: 1.4659 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 909us/step - loss: 1.4663 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 908us/step - loss: 1.4673 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 884us/step - loss: 1.4666 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 919us/step - loss: 1.4667 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 888us/step - loss: 1.4671 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 881us/step - loss: 1.4669 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 902us/step - loss: 1.4676 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 860us/step - loss: 1.4674 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 861us/step - loss: 1.4679 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 840us/step - loss: 1.4682 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 858us/step - loss: 1.4680 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 849us/step - loss: 1.4691 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 867us/step - loss: 1.4691 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 900us/step - loss: 1.4685 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 897us/step - loss: 1.4689 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 949us/step - loss: 1.4687 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 905us/step - loss: 1.4695 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 950us/step - loss: 1.4698 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 914us/step - loss: 1.4697 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 904us/step - loss: 1.4694 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 940us/step - loss: 1.4697 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 917us/step - loss: 1.4703 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 940us/step - loss: 1.4699 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 914us/step - loss: 1.4699 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 922us/step - loss: 1.4704 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 908us/step - loss: 1.4704 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 914us/step - loss: 1.4714 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 920us/step - loss: 1.4724 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.4719 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 936us/step - loss: 1.4719 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 922us/step - loss: 1.4709 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 927us/step - loss: 1.4727 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 904us/step - loss: 1.4724 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 901us/step - loss: 1.4719 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 939us/step - loss: 1.4718 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 1s 919us/step - loss: 1.4723 - accuracy: 0.2500\n"
     ]
    }
   ],
   "source": [
    "accuracy, accuracy_weight = learn_reg_L1(5, 128, 512, weight2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max weight idx : 2\n",
      "max weight : 0.000200\n",
      "max accuracy : 0.425475\n"
     ]
    }
   ],
   "source": [
    "maxidx1 = accuracy.index(max(accuracy))\n",
    "print(\"max weight idx : %d\" % maxidx1)\n",
    "print(\"max weight : %f\" % accuracy_weight[maxidx1])\n",
    "print(\"max accuracy : %f\" % accuracy[maxidx1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x283e8265358>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i for i in range(RANGE1)], accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit = 1/10000.0\n",
    "start = (maxidx1-1)*unit\n",
    "end = (maxidx1+1)*unit\n",
    "step_num = 100\n",
    "step = unit/step_num\n",
    "weight2 = np.arange(start, end, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 1s 916us/step - loss: 1.3008 - accuracy: 0.4127\n",
      "1250/1250 [==============================] - 1s 950us/step - loss: 1.3156 - accuracy: 0.4080\n",
      "1250/1250 [==============================] - 1s 914us/step - loss: 1.3026 - accuracy: 0.4156\n",
      "1250/1250 [==============================] - 1s 949us/step - loss: 1.3063 - accuracy: 0.4170\n",
      "1250/1250 [==============================] - 1s 926us/step - loss: 1.3131 - accuracy: 0.4157\n",
      "1250/1250 [==============================] - 1s 948us/step - loss: 1.2932 - accuracy: 0.4193\n",
      "1250/1250 [==============================] - 1s 921us/step - loss: 1.2947 - accuracy: 0.4162\n",
      "1250/1250 [==============================] - 1s 930us/step - loss: 1.2941 - accuracy: 0.4178\n",
      "1250/1250 [==============================] - 1s 941us/step - loss: 1.2919 - accuracy: 0.4140\n",
      "1250/1250 [==============================] - 1s 918us/step - loss: 1.2998 - accuracy: 0.4195\n",
      "1250/1250 [==============================] - 1s 915us/step - loss: 1.3153 - accuracy: 0.4098\n",
      "1250/1250 [==============================] - 1s 915us/step - loss: 1.2895 - accuracy: 0.4189\n",
      "1250/1250 [==============================] - 1s 935us/step - loss: 1.2904 - accuracy: 0.4142\n",
      "1250/1250 [==============================] - 1s 905us/step - loss: 1.2929 - accuracy: 0.4130\n",
      "1250/1250 [==============================] - 1s 927us/step - loss: 1.3011 - accuracy: 0.4085\n",
      "1250/1250 [==============================] - 1s 909us/step - loss: 1.2991 - accuracy: 0.4150\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.2851 - accuracy: 0.4206\n",
      "1250/1250 [==============================] - 1s 929us/step - loss: 1.3025 - accuracy: 0.4129\n",
      "1250/1250 [==============================] - 1s 896us/step - loss: 1.2982 - accuracy: 0.4189\n",
      "1250/1250 [==============================] - 1s 915us/step - loss: 1.3004 - accuracy: 0.4170\n",
      "1250/1250 [==============================] - 1s 878us/step - loss: 1.3043 - accuracy: 0.4121\n",
      "1250/1250 [==============================] - 1s 880us/step - loss: 1.2985 - accuracy: 0.4141\n",
      "1250/1250 [==============================] - 1s 869us/step - loss: 1.2967 - accuracy: 0.4159\n",
      "1250/1250 [==============================] - 1s 861us/step - loss: 1.3021 - accuracy: 0.4169\n",
      "1250/1250 [==============================] - 1s 850us/step - loss: 1.2992 - accuracy: 0.4146\n",
      "1250/1250 [==============================] - 1s 877us/step - loss: 1.2925 - accuracy: 0.4164\n",
      "1250/1250 [==============================] - 1s 890us/step - loss: 1.2983 - accuracy: 0.4139\n",
      "1250/1250 [==============================] - 1s 945us/step - loss: 1.2699 - accuracy: 0.4212\n",
      "1250/1250 [==============================] - 1s 917us/step - loss: 1.2993 - accuracy: 0.4132\n",
      "1250/1250 [==============================] - 1s 952us/step - loss: 1.2928 - accuracy: 0.4125\n",
      "1250/1250 [==============================] - 1s 933us/step - loss: 1.2931 - accuracy: 0.4149\n",
      "1250/1250 [==============================] - 1s 957us/step - loss: 1.2948 - accuracy: 0.4149\n",
      "1250/1250 [==============================] - 1s 930us/step - loss: 1.2935 - accuracy: 0.4183\n",
      "1250/1250 [==============================] - 1s 941us/step - loss: 1.2904 - accuracy: 0.4141\n",
      "1250/1250 [==============================] - 1s 932us/step - loss: 1.2878 - accuracy: 0.4195\n",
      "1250/1250 [==============================] - 1s 976us/step - loss: 1.2976 - accuracy: 0.4198\n",
      "1250/1250 [==============================] - 1s 803us/step - loss: 1.2980 - accuracy: 0.4088\n",
      "1250/1250 [==============================] - 1s 806us/step - loss: 1.2915 - accuracy: 0.4163\n",
      "1250/1250 [==============================] - 1s 826us/step - loss: 1.2983 - accuracy: 0.4092\n",
      "1250/1250 [==============================] - 1s 914us/step - loss: 1.2884 - accuracy: 0.4166\n",
      "1250/1250 [==============================] - 1s 886us/step - loss: 1.2913 - accuracy: 0.4167\n",
      "1250/1250 [==============================] - 1s 880us/step - loss: 1.2914 - accuracy: 0.4125\n",
      "1250/1250 [==============================] - 1s 936us/step - loss: 1.2873 - accuracy: 0.4183\n",
      "1250/1250 [==============================] - 1s 894us/step - loss: 1.2886 - accuracy: 0.4189\n",
      "1250/1250 [==============================] - 1s 934us/step - loss: 1.2899 - accuracy: 0.4138\n",
      "1250/1250 [==============================] - 1s 889us/step - loss: 1.2962 - accuracy: 0.4172\n",
      "1250/1250 [==============================] - 1s 940us/step - loss: 1.2867 - accuracy: 0.4187\n",
      "1250/1250 [==============================] - 1s 915us/step - loss: 1.2872 - accuracy: 0.4166\n",
      "1250/1250 [==============================] - 1s 915us/step - loss: 1.2839 - accuracy: 0.4194\n",
      "1250/1250 [==============================] - 1s 925us/step - loss: 1.2875 - accuracy: 0.4178\n",
      "1250/1250 [==============================] - 1s 922us/step - loss: 1.2842 - accuracy: 0.4178\n",
      "1250/1250 [==============================] - 1s 967us/step - loss: 1.2939 - accuracy: 0.4145\n",
      "1250/1250 [==============================] - 1s 920us/step - loss: 1.2856 - accuracy: 0.4160\n",
      "1250/1250 [==============================] - 1s 944us/step - loss: 1.2941 - accuracy: 0.4161\n",
      "1250/1250 [==============================] - 1s 918us/step - loss: 1.2884 - accuracy: 0.4199\n",
      "1250/1250 [==============================] - 1s 948us/step - loss: 1.2881 - accuracy: 0.4218\n",
      "1250/1250 [==============================] - 1s 919us/step - loss: 1.2890 - accuracy: 0.4194\n",
      "1250/1250 [==============================] - 1s 926us/step - loss: 1.2842 - accuracy: 0.4188\n",
      "1250/1250 [==============================] - 1s 923us/step - loss: 1.2778 - accuracy: 0.4225\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.2867 - accuracy: 0.4178\n",
      "1250/1250 [==============================] - 1s 928us/step - loss: 1.2902 - accuracy: 0.4157\n",
      "1250/1250 [==============================] - 1s 946us/step - loss: 1.2934 - accuracy: 0.4124\n",
      "1250/1250 [==============================] - 1s 932us/step - loss: 1.2799 - accuracy: 0.4173\n",
      "1250/1250 [==============================] - 1s 940us/step - loss: 1.2889 - accuracy: 0.4150\n",
      "1250/1250 [==============================] - 1s 919us/step - loss: 1.2866 - accuracy: 0.4151\n",
      "1250/1250 [==============================] - 1s 940us/step - loss: 1.2821 - accuracy: 0.4216\n",
      "1250/1250 [==============================] - 1s 943us/step - loss: 1.2886 - accuracy: 0.4178\n",
      "1250/1250 [==============================] - 1s 938us/step - loss: 1.2924 - accuracy: 0.4188\n",
      "1250/1250 [==============================] - 1s 920us/step - loss: 1.2872 - accuracy: 0.4207\n",
      "1250/1250 [==============================] - 1s 920us/step - loss: 1.2786 - accuracy: 0.4199\n",
      "1250/1250 [==============================] - 1s 926us/step - loss: 1.2772 - accuracy: 0.4189\n",
      "1250/1250 [==============================] - 1s 934us/step - loss: 1.2850 - accuracy: 0.4191\n",
      "1250/1250 [==============================] - 1s 930us/step - loss: 1.2870 - accuracy: 0.4146\n",
      "1250/1250 [==============================] - 1s 930us/step - loss: 1.2790 - accuracy: 0.4165\n",
      "1250/1250 [==============================] - 1s 934us/step - loss: 1.2906 - accuracy: 0.4128\n",
      "1250/1250 [==============================] - 1s 903us/step - loss: 1.2862 - accuracy: 0.4160\n",
      "1250/1250 [==============================] - 1s 949us/step - loss: 1.2797 - accuracy: 0.4194\n",
      "1250/1250 [==============================] - 1s 905us/step - loss: 1.2770 - accuracy: 0.4232\n",
      "1250/1250 [==============================] - 1s 886us/step - loss: 1.2641 - accuracy: 0.4266\n",
      "1250/1250 [==============================] - 1s 854us/step - loss: 1.2817 - accuracy: 0.4171\n",
      "1250/1250 [==============================] - 1s 852us/step - loss: 1.2830 - accuracy: 0.4220\n",
      "1250/1250 [==============================] - 1s 860us/step - loss: 1.2932 - accuracy: 0.4100\n",
      "1250/1250 [==============================] - 1s 841us/step - loss: 1.2929 - accuracy: 0.4146\n",
      "1250/1250 [==============================] - 1s 864us/step - loss: 1.2967 - accuracy: 0.4143\n",
      "1250/1250 [==============================] - 1s 864us/step - loss: 1.2792 - accuracy: 0.4171\n",
      "1250/1250 [==============================] - 1s 884us/step - loss: 1.2737 - accuracy: 0.4202\n",
      "1250/1250 [==============================] - 1s 848us/step - loss: 1.2808 - accuracy: 0.4214\n",
      "1250/1250 [==============================] - 1s 871us/step - loss: 1.2809 - accuracy: 0.4165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 1s 874us/step - loss: 1.2701 - accuracy: 0.4231\n",
      "1250/1250 [==============================] - 1s 861us/step - loss: 1.2883 - accuracy: 0.4223\n",
      "1250/1250 [==============================] - 1s 886us/step - loss: 1.2763 - accuracy: 0.4166\n",
      "1250/1250 [==============================] - 1s 928us/step - loss: 1.2689 - accuracy: 0.4200\n",
      "1250/1250 [==============================] - 1s 921us/step - loss: 1.2822 - accuracy: 0.4152\n",
      "1250/1250 [==============================] - 1s 939us/step - loss: 1.2805 - accuracy: 0.4200\n",
      "1250/1250 [==============================] - 1s 926us/step - loss: 1.2844 - accuracy: 0.4152\n",
      "1250/1250 [==============================] - 1s 916us/step - loss: 1.2587 - accuracy: 0.4236\n",
      "1250/1250 [==============================] - 1s 916us/step - loss: 1.2934 - accuracy: 0.4116\n",
      "1250/1250 [==============================] - 1s 899us/step - loss: 1.2676 - accuracy: 0.4218\n",
      "1250/1250 [==============================] - 1s 862us/step - loss: 1.2770 - accuracy: 0.4174\n",
      "1250/1250 [==============================] - 1s 830us/step - loss: 1.2696 - accuracy: 0.4169\n",
      "1250/1250 [==============================] - 1s 847us/step - loss: 1.2777 - accuracy: 0.4198\n",
      "1250/1250 [==============================] - 1s 862us/step - loss: 1.2771 - accuracy: 0.4198\n",
      "1250/1250 [==============================] - 1s 913us/step - loss: 1.2813 - accuracy: 0.4146\n",
      "1250/1250 [==============================] - 1s 921us/step - loss: 1.2709 - accuracy: 0.4198\n",
      "1250/1250 [==============================] - 1s 907us/step - loss: 1.2895 - accuracy: 0.4139\n",
      "1250/1250 [==============================] - 1s 884us/step - loss: 1.2731 - accuracy: 0.4209\n",
      "1250/1250 [==============================] - 1s 931us/step - loss: 1.2745 - accuracy: 0.4202\n",
      "1250/1250 [==============================] - 1s 902us/step - loss: 1.2862 - accuracy: 0.4195\n",
      "1250/1250 [==============================] - 1s 898us/step - loss: 1.2820 - accuracy: 0.4205\n",
      "1250/1250 [==============================] - 1s 917us/step - loss: 1.2758 - accuracy: 0.4216\n",
      "1250/1250 [==============================] - 1s 913us/step - loss: 1.2748 - accuracy: 0.4177\n",
      "1250/1250 [==============================] - 1s 930us/step - loss: 1.2773 - accuracy: 0.4177\n",
      "1250/1250 [==============================] - 1s 898us/step - loss: 1.2675 - accuracy: 0.4201\n",
      "1250/1250 [==============================] - 1s 929us/step - loss: 1.2667 - accuracy: 0.4241\n",
      "1250/1250 [==============================] - 1s 883us/step - loss: 1.2584 - accuracy: 0.4243\n",
      "1250/1250 [==============================] - 1s 911us/step - loss: 1.2659 - accuracy: 0.4227\n",
      "1250/1250 [==============================] - 1s 856us/step - loss: 1.2702 - accuracy: 0.4223\n",
      "1250/1250 [==============================] - 1s 862us/step - loss: 1.2757 - accuracy: 0.4194\n",
      "1250/1250 [==============================] - 1s 839us/step - loss: 1.2750 - accuracy: 0.4239\n",
      "1250/1250 [==============================] - 1s 856us/step - loss: 1.2776 - accuracy: 0.4124\n",
      "1250/1250 [==============================] - 1s 887us/step - loss: 1.2705 - accuracy: 0.4188\n",
      "1250/1250 [==============================] - 1s 946us/step - loss: 1.2884 - accuracy: 0.4172\n",
      "1250/1250 [==============================] - 1s 908us/step - loss: 1.2767 - accuracy: 0.4202\n",
      "1250/1250 [==============================] - 1s 932us/step - loss: 1.2811 - accuracy: 0.4203\n",
      "1250/1250 [==============================] - 1s 914us/step - loss: 1.2693 - accuracy: 0.4203\n",
      "1250/1250 [==============================] - 1s 952us/step - loss: 1.2738 - accuracy: 0.4187\n",
      "1250/1250 [==============================] - 1s 914us/step - loss: 1.2694 - accuracy: 0.4208\n",
      "1250/1250 [==============================] - 1s 930us/step - loss: 1.2729 - accuracy: 0.4196\n",
      "1250/1250 [==============================] - 1s 905us/step - loss: 1.2766 - accuracy: 0.4172\n",
      "1250/1250 [==============================] - 1s 923us/step - loss: 1.2733 - accuracy: 0.4207\n",
      "1250/1250 [==============================] - 1s 906us/step - loss: 1.2727 - accuracy: 0.4201\n",
      "1250/1250 [==============================] - 1s 932us/step - loss: 1.2665 - accuracy: 0.4218\n",
      "1250/1250 [==============================] - 1s 911us/step - loss: 1.2743 - accuracy: 0.4173\n",
      "1250/1250 [==============================] - 1s 900us/step - loss: 1.2831 - accuracy: 0.4141\n",
      "1250/1250 [==============================] - 1s 882us/step - loss: 1.2863 - accuracy: 0.4141\n",
      "1250/1250 [==============================] - 1s 847us/step - loss: 1.2779 - accuracy: 0.4261\n",
      "1250/1250 [==============================] - 1s 846us/step - loss: 1.2781 - accuracy: 0.4197\n",
      "1250/1250 [==============================] - 1s 840us/step - loss: 1.2629 - accuracy: 0.4256\n",
      "1250/1250 [==============================] - 1s 848us/step - loss: 1.2729 - accuracy: 0.4209\n",
      "1250/1250 [==============================] - 1s 867us/step - loss: 1.2794 - accuracy: 0.4193\n",
      "1250/1250 [==============================] - 1s 884us/step - loss: 1.2677 - accuracy: 0.4192\n",
      "1250/1250 [==============================] - 1s 910us/step - loss: 1.2713 - accuracy: 0.4140\n",
      "1250/1250 [==============================] - 1s 906us/step - loss: 1.2756 - accuracy: 0.4214\n",
      "1250/1250 [==============================] - 1s 930us/step - loss: 1.2714 - accuracy: 0.4233\n",
      "1250/1250 [==============================] - 1s 919us/step - loss: 1.2710 - accuracy: 0.4192\n",
      "1250/1250 [==============================] - 1s 931us/step - loss: 1.2748 - accuracy: 0.4173\n",
      "1250/1250 [==============================] - 1s 903us/step - loss: 1.2703 - accuracy: 0.4177\n",
      "1250/1250 [==============================] - 1s 936us/step - loss: 1.2762 - accuracy: 0.4170\n",
      "1250/1250 [==============================] - 1s 915us/step - loss: 1.2620 - accuracy: 0.4252\n",
      "1250/1250 [==============================] - 1s 913us/step - loss: 1.2695 - accuracy: 0.4181\n",
      "1250/1250 [==============================] - 1s 884us/step - loss: 1.2738 - accuracy: 0.4198\n",
      "1250/1250 [==============================] - 1s 923us/step - loss: 1.2575 - accuracy: 0.4250\n",
      "1250/1250 [==============================] - 1s 893us/step - loss: 1.2649 - accuracy: 0.4218\n",
      "1250/1250 [==============================] - 1s 941us/step - loss: 1.2719 - accuracy: 0.4189\n",
      "1250/1250 [==============================] - 1s 914us/step - loss: 1.2691 - accuracy: 0.4166\n",
      "1250/1250 [==============================] - 1s 945us/step - loss: 1.2663 - accuracy: 0.4189\n",
      "1250/1250 [==============================] - 1s 910us/step - loss: 1.2679 - accuracy: 0.4242\n",
      "1250/1250 [==============================] - 1s 926us/step - loss: 1.2578 - accuracy: 0.4267\n",
      "1250/1250 [==============================] - 1s 859us/step - loss: 1.2622 - accuracy: 0.4262\n",
      "1250/1250 [==============================] - 1s 876us/step - loss: 1.2627 - accuracy: 0.4234\n",
      "1250/1250 [==============================] - 1s 841us/step - loss: 1.2540 - accuracy: 0.4228\n",
      "1250/1250 [==============================] - 1s 873us/step - loss: 1.2660 - accuracy: 0.4261\n",
      "1250/1250 [==============================] - 1s 866us/step - loss: 1.2611 - accuracy: 0.4234\n",
      "1250/1250 [==============================] - 1s 922us/step - loss: 1.2714 - accuracy: 0.4218\n",
      "1250/1250 [==============================] - 1s 898us/step - loss: 1.2725 - accuracy: 0.4168\n",
      "1250/1250 [==============================] - 1s 902us/step - loss: 1.2623 - accuracy: 0.4243\n",
      "1250/1250 [==============================] - 1s 911us/step - loss: 1.2575 - accuracy: 0.4233\n",
      "1250/1250 [==============================] - 1s 927us/step - loss: 1.2743 - accuracy: 0.4191\n",
      "1250/1250 [==============================] - 1s 898us/step - loss: 1.2675 - accuracy: 0.4263\n",
      "1250/1250 [==============================] - 1s 904us/step - loss: 1.2682 - accuracy: 0.4199\n",
      "1250/1250 [==============================] - 1s 938us/step - loss: 1.2583 - accuracy: 0.4238\n",
      "1250/1250 [==============================] - 1s 911us/step - loss: 1.2750 - accuracy: 0.4168\n",
      "1250/1250 [==============================] - 1s 948us/step - loss: 1.2682 - accuracy: 0.4241\n",
      "1250/1250 [==============================] - 1s 934us/step - loss: 1.2667 - accuracy: 0.4248\n",
      "1250/1250 [==============================] - 1s 939us/step - loss: 1.2611 - accuracy: 0.4199\n",
      "1250/1250 [==============================] - 1s 916us/step - loss: 1.2658 - accuracy: 0.4215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 1s 941us/step - loss: 1.2638 - accuracy: 0.4235\n",
      "1250/1250 [==============================] - 1s 914us/step - loss: 1.2643 - accuracy: 0.4232\n",
      "1250/1250 [==============================] - 1s 943us/step - loss: 1.2613 - accuracy: 0.4234\n",
      "1250/1250 [==============================] - 1s 910us/step - loss: 1.2668 - accuracy: 0.4192\n",
      "1250/1250 [==============================] - 1s 898us/step - loss: 1.2706 - accuracy: 0.4189\n",
      "1250/1250 [==============================] - 1s 858us/step - loss: 1.2608 - accuracy: 0.4234\n",
      "1250/1250 [==============================] - 1s 858us/step - loss: 1.2569 - accuracy: 0.4230\n",
      "1250/1250 [==============================] - 1s 848us/step - loss: 1.2574 - accuracy: 0.4229\n",
      "1250/1250 [==============================] - 1s 856us/step - loss: 1.2591 - accuracy: 0.4219\n",
      "1250/1250 [==============================] - 1s 891us/step - loss: 1.2621 - accuracy: 0.4221\n",
      "1250/1250 [==============================] - 1s 900us/step - loss: 1.2722 - accuracy: 0.4143\n",
      "1250/1250 [==============================] - 1s 939us/step - loss: 1.2752 - accuracy: 0.4147\n",
      "1250/1250 [==============================] - 1s 914us/step - loss: 1.2715 - accuracy: 0.4175\n",
      "1250/1250 [==============================] - 1s 944us/step - loss: 1.2674 - accuracy: 0.4229\n",
      "1250/1250 [==============================] - 1s 927us/step - loss: 1.2723 - accuracy: 0.4183\n",
      "1250/1250 [==============================] - 1s 922us/step - loss: 1.2574 - accuracy: 0.4214\n",
      "1250/1250 [==============================] - 1s 916us/step - loss: 1.2655 - accuracy: 0.4205\n",
      "1250/1250 [==============================] - 1s 918us/step - loss: 1.2676 - accuracy: 0.4160\n",
      "1250/1250 [==============================] - 1s 931us/step - loss: 1.2682 - accuracy: 0.4177\n",
      "1250/1250 [==============================] - 1s 918us/step - loss: 1.2602 - accuracy: 0.4243\n",
      "1250/1250 [==============================] - 1s 934us/step - loss: 1.2589 - accuracy: 0.4193\n",
      "1250/1250 [==============================] - 1s 911us/step - loss: 1.2534 - accuracy: 0.4258\n",
      "1250/1250 [==============================] - 1s 930us/step - loss: 1.2737 - accuracy: 0.4199\n",
      "1250/1250 [==============================] - 1s 924us/step - loss: 1.2679 - accuracy: 0.4176\n",
      "1250/1250 [==============================] - 1s 937us/step - loss: 1.2601 - accuracy: 0.4239\n",
      "1250/1250 [==============================] - 1s 900us/step - loss: 1.2544 - accuracy: 0.4227\n",
      "1250/1250 [==============================] - 1s 859us/step - loss: 1.2615 - accuracy: 0.4198\n",
      "1250/1250 [==============================] - 1s 854us/step - loss: 1.2607 - accuracy: 0.4215\n",
      "1250/1250 [==============================] - 1s 848us/step - loss: 1.2464 - accuracy: 0.4257\n",
      "1250/1250 [==============================] - 1s 891us/step - loss: 1.2572 - accuracy: 0.4227\n",
      "1250/1250 [==============================] - 1s 903us/step - loss: 1.2549 - accuracy: 0.4279\n",
      "1250/1250 [==============================] - 1s 944us/step - loss: 1.2523 - accuracy: 0.4228\n",
      "1250/1250 [==============================] - 1s 921us/step - loss: 1.2479 - accuracy: 0.4272\n",
      "1250/1250 [==============================] - 1s 944us/step - loss: 1.2649 - accuracy: 0.4225\n",
      "1250/1250 [==============================] - 1s 905us/step - loss: 1.2659 - accuracy: 0.4257\n",
      "1250/1250 [==============================] - 1s 949us/step - loss: 1.2524 - accuracy: 0.4241\n",
      "1250/1250 [==============================] - 1s 926us/step - loss: 1.2563 - accuracy: 0.4232\n",
      "1250/1250 [==============================] - 1s 934us/step - loss: 1.2602 - accuracy: 0.4250\n",
      "1250/1250 [==============================] - 1s 902us/step - loss: 1.2666 - accuracy: 0.4185\n",
      "1250/1250 [==============================] - 1s 916us/step - loss: 1.2593 - accuracy: 0.4200\n",
      "1250/1250 [==============================] - 1s 910us/step - loss: 1.2506 - accuracy: 0.4227\n",
      "1250/1250 [==============================] - 1s 932us/step - loss: 1.2608 - accuracy: 0.4224\n",
      "1250/1250 [==============================] - 1s 885us/step - loss: 1.2500 - accuracy: 0.4220\n",
      "1250/1250 [==============================] - 1s 852us/step - loss: 1.2475 - accuracy: 0.4237\n",
      "1250/1250 [==============================] - 1s 868us/step - loss: 1.2467 - accuracy: 0.4267\n",
      "1250/1250 [==============================] - 1s 857us/step - loss: 1.2590 - accuracy: 0.4216\n",
      "1250/1250 [==============================] - 1s 885us/step - loss: 1.2563 - accuracy: 0.4220\n",
      "1250/1250 [==============================] - 1s 860us/step - loss: 1.2584 - accuracy: 0.4215\n",
      "1250/1250 [==============================] - 1s 936us/step - loss: 1.2542 - accuracy: 0.4246\n",
      "1250/1250 [==============================] - 1s 917us/step - loss: 1.2544 - accuracy: 0.4207\n",
      "1250/1250 [==============================] - 1s 944us/step - loss: 1.2556 - accuracy: 0.4265\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.2655 - accuracy: 0.4164\n",
      "1250/1250 [==============================] - 1s 949us/step - loss: 1.2663 - accuracy: 0.4167\n",
      "1250/1250 [==============================] - 1s 905us/step - loss: 1.2567 - accuracy: 0.4216\n",
      "1250/1250 [==============================] - 1s 915us/step - loss: 1.2675 - accuracy: 0.4204\n",
      "1250/1250 [==============================] - 1s 910us/step - loss: 1.2655 - accuracy: 0.4179\n",
      "1250/1250 [==============================] - 1s 903us/step - loss: 1.2676 - accuracy: 0.4188\n",
      "1250/1250 [==============================] - 1s 924us/step - loss: 1.2554 - accuracy: 0.4246\n",
      "1250/1250 [==============================] - 1s 910us/step - loss: 1.2648 - accuracy: 0.4223\n",
      "1250/1250 [==============================] - 1s 911us/step - loss: 1.2585 - accuracy: 0.4218\n",
      "1250/1250 [==============================] - 1s 865us/step - loss: 1.2506 - accuracy: 0.4251\n",
      "1250/1250 [==============================] - 1s 898us/step - loss: 1.2633 - accuracy: 0.4184\n",
      "1250/1250 [==============================] - 1s 867us/step - loss: 1.2524 - accuracy: 0.4227\n",
      "1250/1250 [==============================] - 1s 858us/step - loss: 1.2516 - accuracy: 0.4299\n",
      "1250/1250 [==============================] - 1s 864us/step - loss: 1.2605 - accuracy: 0.4203\n",
      "1250/1250 [==============================] - 1s 896us/step - loss: 1.2645 - accuracy: 0.4227\n",
      "1250/1250 [==============================] - 1s 938us/step - loss: 1.2563 - accuracy: 0.4225\n",
      "1250/1250 [==============================] - 1s 928us/step - loss: 1.2655 - accuracy: 0.4147\n",
      "1250/1250 [==============================] - 1s 944us/step - loss: 1.2576 - accuracy: 0.4207\n",
      "1250/1250 [==============================] - 1s 906us/step - loss: 1.2620 - accuracy: 0.4221\n",
      "1250/1250 [==============================] - 1s 916us/step - loss: 1.2524 - accuracy: 0.4279\n",
      "1250/1250 [==============================] - 1s 932us/step - loss: 1.2557 - accuracy: 0.4251\n",
      "1250/1250 [==============================] - 1s 908us/step - loss: 1.2484 - accuracy: 0.4212\n",
      "1250/1250 [==============================] - 1s 934us/step - loss: 1.2557 - accuracy: 0.4196\n",
      "1250/1250 [==============================] - 1s 909us/step - loss: 1.2637 - accuracy: 0.4204\n",
      "1250/1250 [==============================] - 1s 932us/step - loss: 1.2600 - accuracy: 0.4225\n",
      "1250/1250 [==============================] - 1s 903us/step - loss: 1.2487 - accuracy: 0.4270\n",
      "1250/1250 [==============================] - 1s 883us/step - loss: 1.2584 - accuracy: 0.4201\n",
      "1250/1250 [==============================] - 1s 943us/step - loss: 1.2580 - accuracy: 0.4237\n",
      "1250/1250 [==============================] - 1s 897us/step - loss: 1.2506 - accuracy: 0.4252\n",
      "1250/1250 [==============================] - 1s 887us/step - loss: 1.2608 - accuracy: 0.4203\n",
      "1250/1250 [==============================] - 1s 850us/step - loss: 1.2550 - accuracy: 0.4196\n",
      "1250/1250 [==============================] - 1s 860us/step - loss: 1.2399 - accuracy: 0.4254\n",
      "1250/1250 [==============================] - 1s 889us/step - loss: 1.2571 - accuracy: 0.4244\n",
      "1250/1250 [==============================] - 1s 908us/step - loss: 1.2421 - accuracy: 0.4286\n",
      "1250/1250 [==============================] - 1s 956us/step - loss: 1.2592 - accuracy: 0.4229\n",
      "1250/1250 [==============================] - 1s 922us/step - loss: 1.2447 - accuracy: 0.4205\n",
      "1250/1250 [==============================] - 1s 941us/step - loss: 1.2592 - accuracy: 0.4231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 1s 940us/step - loss: 1.2451 - accuracy: 0.4246\n",
      "1250/1250 [==============================] - 1s 915us/step - loss: 1.2542 - accuracy: 0.4244\n",
      "1250/1250 [==============================] - 1s 941us/step - loss: 1.2615 - accuracy: 0.4194\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.2432 - accuracy: 0.4263\n",
      "1250/1250 [==============================] - 1s 905us/step - loss: 1.2531 - accuracy: 0.4248\n",
      "1250/1250 [==============================] - 1s 923us/step - loss: 1.2491 - accuracy: 0.4267\n",
      "1250/1250 [==============================] - 1s 899us/step - loss: 1.2511 - accuracy: 0.4238\n",
      "1250/1250 [==============================] - 1s 925us/step - loss: 1.2442 - accuracy: 0.4243\n",
      "1250/1250 [==============================] - 1s 919us/step - loss: 1.2495 - accuracy: 0.4266\n",
      "1250/1250 [==============================] - 1s 927us/step - loss: 1.2508 - accuracy: 0.4254\n",
      "1250/1250 [==============================] - 1s 954us/step - loss: 1.2517 - accuracy: 0.4236\n",
      "1250/1250 [==============================] - 1s 931us/step - loss: 1.2425 - accuracy: 0.4285\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.2599 - accuracy: 0.4227\n",
      "1250/1250 [==============================] - 1s 868us/step - loss: 1.2566 - accuracy: 0.4230\n",
      "1250/1250 [==============================] - 1s 858us/step - loss: 1.2549 - accuracy: 0.4234\n",
      "1250/1250 [==============================] - 1s 878us/step - loss: 1.2521 - accuracy: 0.4234\n",
      "1250/1250 [==============================] - 1s 884us/step - loss: 1.2443 - accuracy: 0.4263\n",
      "1250/1250 [==============================] - 1s 878us/step - loss: 1.2496 - accuracy: 0.4259\n",
      "1250/1250 [==============================] - 1s 943us/step - loss: 1.2432 - accuracy: 0.4260\n",
      "1250/1250 [==============================] - 1s 908us/step - loss: 1.2481 - accuracy: 0.4264\n",
      "1250/1250 [==============================] - 1s 938us/step - loss: 1.2500 - accuracy: 0.4250\n",
      "1250/1250 [==============================] - 1s 909us/step - loss: 1.2432 - accuracy: 0.4269\n",
      "1250/1250 [==============================] - 1s 893us/step - loss: 1.2500 - accuracy: 0.4203\n",
      "1250/1250 [==============================] - 1s 914us/step - loss: 1.2596 - accuracy: 0.4223\n",
      "1250/1250 [==============================] - 1s 907us/step - loss: 1.2482 - accuracy: 0.4296\n",
      "1250/1250 [==============================] - 1s 927us/step - loss: 1.2553 - accuracy: 0.4218\n",
      "1250/1250 [==============================] - 1s 923us/step - loss: 1.2334 - accuracy: 0.4317\n",
      "1250/1250 [==============================] - 1s 923us/step - loss: 1.2431 - accuracy: 0.4279\n",
      "1250/1250 [==============================] - 1s 948us/step - loss: 1.2458 - accuracy: 0.4254\n",
      "1250/1250 [==============================] - 1s 925us/step - loss: 1.2380 - accuracy: 0.4227\n",
      "1250/1250 [==============================] - 1s 935us/step - loss: 1.2494 - accuracy: 0.4242\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2483 - accuracy: 0.4267\n",
      "1250/1250 [==============================] - 1s 920us/step - loss: 1.2581 - accuracy: 0.4246\n",
      "1250/1250 [==============================] - 1s 894us/step - loss: 1.2491 - accuracy: 0.4240\n",
      "1250/1250 [==============================] - 1s 893us/step - loss: 1.2463 - accuracy: 0.4256\n",
      "1250/1250 [==============================] - 1s 887us/step - loss: 1.2569 - accuracy: 0.4242\n",
      "1250/1250 [==============================] - 1s 916us/step - loss: 1.2473 - accuracy: 0.4232\n",
      "1250/1250 [==============================] - 1s 921us/step - loss: 1.2579 - accuracy: 0.4229\n",
      "1250/1250 [==============================] - 1s 905us/step - loss: 1.2508 - accuracy: 0.4238\n",
      "1250/1250 [==============================] - 1s 938us/step - loss: 1.2507 - accuracy: 0.4261\n",
      "1250/1250 [==============================] - 1s 902us/step - loss: 1.2521 - accuracy: 0.4189\n",
      "1250/1250 [==============================] - 1s 897us/step - loss: 1.2481 - accuracy: 0.4241\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.2441 - accuracy: 0.4223\n",
      "1250/1250 [==============================] - 1s 940us/step - loss: 1.2474 - accuracy: 0.4202\n",
      "1250/1250 [==============================] - 1s 922us/step - loss: 1.2512 - accuracy: 0.4240\n",
      "1250/1250 [==============================] - 1s 934us/step - loss: 1.2533 - accuracy: 0.4234\n",
      "1250/1250 [==============================] - 1s 913us/step - loss: 1.2465 - accuracy: 0.4253\n",
      "1250/1250 [==============================] - 1s 934us/step - loss: 1.2438 - accuracy: 0.4279\n",
      "1250/1250 [==============================] - 1s 898us/step - loss: 1.2466 - accuracy: 0.4248\n",
      "1250/1250 [==============================] - 1s 876us/step - loss: 1.2480 - accuracy: 0.4246\n",
      "1250/1250 [==============================] - 1s 876us/step - loss: 1.2519 - accuracy: 0.4208\n",
      "1250/1250 [==============================] - 1s 872us/step - loss: 1.2597 - accuracy: 0.4261\n",
      "1250/1250 [==============================] - 1s 887us/step - loss: 1.2425 - accuracy: 0.4266\n",
      "1250/1250 [==============================] - 1s 946us/step - loss: 1.2439 - accuracy: 0.4291\n",
      "1250/1250 [==============================] - 1s 920us/step - loss: 1.2381 - accuracy: 0.4287\n",
      "1250/1250 [==============================] - 1s 938us/step - loss: 1.2492 - accuracy: 0.4179\n",
      "1250/1250 [==============================] - 1s 950us/step - loss: 1.2389 - accuracy: 0.4242\n",
      "1250/1250 [==============================] - 1s 925us/step - loss: 1.2494 - accuracy: 0.4235\n",
      "1250/1250 [==============================] - 1s 925us/step - loss: 1.2419 - accuracy: 0.4286\n",
      "1250/1250 [==============================] - 1s 932us/step - loss: 1.2498 - accuracy: 0.4195\n",
      "1250/1250 [==============================] - 1s 898us/step - loss: 1.2520 - accuracy: 0.4206\n",
      "1250/1250 [==============================] - 1s 918us/step - loss: 1.2416 - accuracy: 0.4291\n",
      "1250/1250 [==============================] - 1s 947us/step - loss: 1.2361 - accuracy: 0.4293\n",
      "1250/1250 [==============================] - 1s 914us/step - loss: 1.2446 - accuracy: 0.4248\n",
      "1250/1250 [==============================] - 1s 928us/step - loss: 1.2446 - accuracy: 0.4217\n",
      "1250/1250 [==============================] - 1s 947us/step - loss: 1.2410 - accuracy: 0.4263\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.2451 - accuracy: 0.4236\n",
      "1250/1250 [==============================] - 1s 918us/step - loss: 1.2516 - accuracy: 0.4231\n",
      "1250/1250 [==============================] - 1s 918us/step - loss: 1.2497 - accuracy: 0.4264\n",
      "1250/1250 [==============================] - 1s 872us/step - loss: 1.2492 - accuracy: 0.4205\n",
      "1250/1250 [==============================] - 1s 868us/step - loss: 1.2393 - accuracy: 0.4243\n",
      "1250/1250 [==============================] - 1s 884us/step - loss: 1.2463 - accuracy: 0.4255\n",
      "1250/1250 [==============================] - 1s 910us/step - loss: 1.2462 - accuracy: 0.4208\n",
      "1250/1250 [==============================] - 1s 944us/step - loss: 1.2463 - accuracy: 0.4248\n",
      "1250/1250 [==============================] - 1s 908us/step - loss: 1.2506 - accuracy: 0.4209\n",
      "1250/1250 [==============================] - 1s 889us/step - loss: 1.2353 - accuracy: 0.4259\n",
      "1250/1250 [==============================] - 1s 938us/step - loss: 1.2445 - accuracy: 0.4237\n",
      "1250/1250 [==============================] - 1s 909us/step - loss: 1.2412 - accuracy: 0.4258\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.2506 - accuracy: 0.4218\n",
      "1250/1250 [==============================] - 1s 924us/step - loss: 1.2432 - accuracy: 0.4283\n",
      "1250/1250 [==============================] - 1s 932us/step - loss: 1.2476 - accuracy: 0.4207\n",
      "1250/1250 [==============================] - 1s 943us/step - loss: 1.2417 - accuracy: 0.4241\n",
      "1250/1250 [==============================] - 1s 956us/step - loss: 1.2498 - accuracy: 0.4214\n",
      "1250/1250 [==============================] - 1s 946us/step - loss: 1.2490 - accuracy: 0.4256\n",
      "1250/1250 [==============================] - 1s 934us/step - loss: 1.2423 - accuracy: 0.4220\n",
      "1250/1250 [==============================] - 1s 919us/step - loss: 1.2540 - accuracy: 0.4226\n",
      "1250/1250 [==============================] - 1s 930us/step - loss: 1.2452 - accuracy: 0.4254\n",
      "1250/1250 [==============================] - 1s 891us/step - loss: 1.2491 - accuracy: 0.4232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 1s 871us/step - loss: 1.2458 - accuracy: 0.4236\n",
      "1250/1250 [==============================] - 1s 885us/step - loss: 1.2421 - accuracy: 0.4227\n",
      "1250/1250 [==============================] - 1s 876us/step - loss: 1.2355 - accuracy: 0.4295\n",
      "1250/1250 [==============================] - 1s 926us/step - loss: 1.2496 - accuracy: 0.4216\n",
      "1250/1250 [==============================] - 1s 943us/step - loss: 1.2448 - accuracy: 0.4270\n",
      "1250/1250 [==============================] - 1s 921us/step - loss: 1.2552 - accuracy: 0.4207\n",
      "1250/1250 [==============================] - 1s 935us/step - loss: 1.2407 - accuracy: 0.4286\n",
      "1250/1250 [==============================] - 1s 948us/step - loss: 1.2451 - accuracy: 0.4265\n",
      "1250/1250 [==============================] - 1s 921us/step - loss: 1.2417 - accuracy: 0.4270\n",
      "1250/1250 [==============================] - 1s 924us/step - loss: 1.2545 - accuracy: 0.4238\n",
      "1250/1250 [==============================] - 1s 928us/step - loss: 1.2576 - accuracy: 0.4220\n",
      "1250/1250 [==============================] - 1s 919us/step - loss: 1.2390 - accuracy: 0.4306\n",
      "1250/1250 [==============================] - 1s 915us/step - loss: 1.2381 - accuracy: 0.4271\n",
      "1250/1250 [==============================] - 1s 910us/step - loss: 1.2489 - accuracy: 0.4218\n",
      "1250/1250 [==============================] - 1s 950us/step - loss: 1.2429 - accuracy: 0.4198\n",
      "1250/1250 [==============================] - 1s 913us/step - loss: 1.2453 - accuracy: 0.4236\n",
      "1250/1250 [==============================] - 1s 900us/step - loss: 1.2410 - accuracy: 0.4205\n",
      "1250/1250 [==============================] - 1s 910us/step - loss: 1.2411 - accuracy: 0.4282\n",
      "1250/1250 [==============================] - 1s 867us/step - loss: 1.2340 - accuracy: 0.4292\n",
      "1250/1250 [==============================] - 1s 885us/step - loss: 1.2348 - accuracy: 0.4266\n",
      "1250/1250 [==============================] - 1s 897us/step - loss: 1.2371 - accuracy: 0.4294\n",
      "1250/1250 [==============================] - 1s 918us/step - loss: 1.2490 - accuracy: 0.4216\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.2362 - accuracy: 0.4227\n",
      "1250/1250 [==============================] - 1s 923us/step - loss: 1.2448 - accuracy: 0.4276\n",
      "1250/1250 [==============================] - 1s 942us/step - loss: 1.2521 - accuracy: 0.4207\n",
      "1250/1250 [==============================] - 1s 914us/step - loss: 1.2429 - accuracy: 0.4266\n",
      "1250/1250 [==============================] - 1s 929us/step - loss: 1.2420 - accuracy: 0.4227\n",
      "1250/1250 [==============================] - 1s 932us/step - loss: 1.2387 - accuracy: 0.4217\n",
      "1250/1250 [==============================] - 1s 918us/step - loss: 1.2415 - accuracy: 0.4273\n",
      "1250/1250 [==============================] - 1s 932us/step - loss: 1.2402 - accuracy: 0.4239\n",
      "1250/1250 [==============================] - 1s 911us/step - loss: 1.2401 - accuracy: 0.4294\n",
      "1250/1250 [==============================] - 1s 927us/step - loss: 1.2387 - accuracy: 0.4252\n",
      "1250/1250 [==============================] - 1s 900us/step - loss: 1.2412 - accuracy: 0.4260\n",
      "1250/1250 [==============================] - 1s 865us/step - loss: 1.2362 - accuracy: 0.4259\n",
      "1250/1250 [==============================] - 1s 880us/step - loss: 1.2438 - accuracy: 0.4238\n",
      "1250/1250 [==============================] - 1s 916us/step - loss: 1.2345 - accuracy: 0.4248\n",
      "1250/1250 [==============================] - 1s 923us/step - loss: 1.2456 - accuracy: 0.4277\n",
      "1250/1250 [==============================] - 1s 928us/step - loss: 1.2433 - accuracy: 0.4273\n",
      "1250/1250 [==============================] - 1s 950us/step - loss: 1.2508 - accuracy: 0.4246\n",
      "1250/1250 [==============================] - 1s 918us/step - loss: 1.2419 - accuracy: 0.4224\n",
      "1250/1250 [==============================] - 1s 913us/step - loss: 1.2382 - accuracy: 0.4266\n",
      "1250/1250 [==============================] - 1s 953us/step - loss: 1.2427 - accuracy: 0.4260\n",
      "1250/1250 [==============================] - 1s 908us/step - loss: 1.2424 - accuracy: 0.4302\n",
      "1250/1250 [==============================] - 1s 920us/step - loss: 1.2514 - accuracy: 0.4230\n",
      "1250/1250 [==============================] - 1s 898us/step - loss: 1.2357 - accuracy: 0.4263\n",
      "1250/1250 [==============================] - 1s 854us/step - loss: 1.2369 - accuracy: 0.4238\n",
      "1250/1250 [==============================] - 1s 882us/step - loss: 1.2401 - accuracy: 0.4190\n",
      "1250/1250 [==============================] - 1s 936us/step - loss: 1.2446 - accuracy: 0.4266\n",
      "1250/1250 [==============================] - 1s 893us/step - loss: 1.2413 - accuracy: 0.4272\n",
      "1250/1250 [==============================] - 1s 950us/step - loss: 1.2456 - accuracy: 0.4206\n",
      "1250/1250 [==============================] - 1s 960us/step - loss: 1.2327 - accuracy: 0.4254\n",
      "1250/1250 [==============================] - 1s 932us/step - loss: 1.2424 - accuracy: 0.4208\n",
      "1250/1250 [==============================] - 1s 922us/step - loss: 1.2404 - accuracy: 0.4263\n",
      "1250/1250 [==============================] - 1s 960us/step - loss: 1.2348 - accuracy: 0.4257\n",
      "1250/1250 [==============================] - 1s 917us/step - loss: 1.2535 - accuracy: 0.4204\n",
      "1250/1250 [==============================] - 1s 919us/step - loss: 1.2447 - accuracy: 0.4205\n",
      "1250/1250 [==============================] - 1s 940us/step - loss: 1.2422 - accuracy: 0.4276\n",
      "1250/1250 [==============================] - 1s 906us/step - loss: 1.2388 - accuracy: 0.4269\n",
      "1250/1250 [==============================] - 1s 879us/step - loss: 1.2401 - accuracy: 0.4216\n",
      "1250/1250 [==============================] - 1s 896us/step - loss: 1.2325 - accuracy: 0.4275\n",
      "1250/1250 [==============================] - 1s 909us/step - loss: 1.2265 - accuracy: 0.4337\n",
      "1250/1250 [==============================] - 1s 910us/step - loss: 1.2398 - accuracy: 0.4287\n",
      "1250/1250 [==============================] - 1s 920us/step - loss: 1.2401 - accuracy: 0.4256\n",
      "1250/1250 [==============================] - 1s 938us/step - loss: 1.2304 - accuracy: 0.4269\n",
      "1250/1250 [==============================] - 1s 914us/step - loss: 1.2346 - accuracy: 0.4241\n",
      "1250/1250 [==============================] - 1s 924us/step - loss: 1.2399 - accuracy: 0.4219\n",
      "1250/1250 [==============================] - 1s 927us/step - loss: 1.2408 - accuracy: 0.4258\n",
      "1250/1250 [==============================] - 1s 910us/step - loss: 1.2377 - accuracy: 0.4233\n",
      "1250/1250 [==============================] - 1s 876us/step - loss: 1.2322 - accuracy: 0.4271\n",
      "1250/1250 [==============================] - 1s 870us/step - loss: 1.2394 - accuracy: 0.4261\n",
      "1250/1250 [==============================] - 1s 868us/step - loss: 1.2429 - accuracy: 0.4229\n",
      "1250/1250 [==============================] - 1s 883us/step - loss: 1.2501 - accuracy: 0.4216\n",
      "1250/1250 [==============================] - 1s 910us/step - loss: 1.2398 - accuracy: 0.4252\n",
      "1250/1250 [==============================] - 1s 960us/step - loss: 1.2399 - accuracy: 0.4248\n",
      "1250/1250 [==============================] - 1s 933us/step - loss: 1.2459 - accuracy: 0.4211\n",
      "1250/1250 [==============================] - 1s 932us/step - loss: 1.2434 - accuracy: 0.4250\n",
      "1250/1250 [==============================] - 1s 960us/step - loss: 1.2309 - accuracy: 0.4264\n",
      "1250/1250 [==============================] - 1s 933us/step - loss: 1.2350 - accuracy: 0.4215\n",
      "1250/1250 [==============================] - 1s 936us/step - loss: 1.2347 - accuracy: 0.4274\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2412 - accuracy: 0.4222\n",
      "1250/1250 [==============================] - 1s 967us/step - loss: 1.2309 - accuracy: 0.4245\n",
      "1250/1250 [==============================] - 1s 922us/step - loss: 1.2415 - accuracy: 0.4257\n",
      "1250/1250 [==============================] - 1s 898us/step - loss: 1.2324 - accuracy: 0.4301\n",
      "1250/1250 [==============================] - 1s 880us/step - loss: 1.2376 - accuracy: 0.4287\n",
      "1250/1250 [==============================] - 1s 890us/step - loss: 1.2322 - accuracy: 0.4243\n",
      "1250/1250 [==============================] - 1s 926us/step - loss: 1.2395 - accuracy: 0.4198\n",
      "1250/1250 [==============================] - 1s 908us/step - loss: 1.2465 - accuracy: 0.4258\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.2416 - accuracy: 0.4269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 1s 943us/step - loss: 1.2356 - accuracy: 0.4266\n",
      "1250/1250 [==============================] - 1s 941us/step - loss: 1.2292 - accuracy: 0.4308\n",
      "1250/1250 [==============================] - 1s 935us/step - loss: 1.2310 - accuracy: 0.4252\n",
      "1250/1250 [==============================] - 1s 921us/step - loss: 1.2333 - accuracy: 0.4225\n",
      "1250/1250 [==============================] - 1s 922us/step - loss: 1.2386 - accuracy: 0.4286\n",
      "1250/1250 [==============================] - 1s 954us/step - loss: 1.2318 - accuracy: 0.4241\n",
      "1250/1250 [==============================] - 1s 913us/step - loss: 1.2353 - accuracy: 0.4288\n",
      "1250/1250 [==============================] - 1s 891us/step - loss: 1.2334 - accuracy: 0.4247\n",
      "1250/1250 [==============================] - 1s 887us/step - loss: 1.2388 - accuracy: 0.4261\n",
      "1250/1250 [==============================] - 1s 906us/step - loss: 1.2391 - accuracy: 0.4254\n",
      "1250/1250 [==============================] - 1s 900us/step - loss: 1.2343 - accuracy: 0.4250\n",
      "1250/1250 [==============================] - 1s 941us/step - loss: 1.2358 - accuracy: 0.4232\n",
      "1250/1250 [==============================] - 1s 950us/step - loss: 1.2358 - accuracy: 0.4243\n",
      "1250/1250 [==============================] - 1s 968us/step - loss: 1.2400 - accuracy: 0.4234\n",
      "1250/1250 [==============================] - 1s 929us/step - loss: 1.2352 - accuracy: 0.4277\n",
      "1250/1250 [==============================] - 1s 914us/step - loss: 1.2372 - accuracy: 0.4286\n",
      "1250/1250 [==============================] - 1s 952us/step - loss: 1.2338 - accuracy: 0.4281\n",
      "1250/1250 [==============================] - 1s 926us/step - loss: 1.2370 - accuracy: 0.4246\n",
      "1250/1250 [==============================] - 1s 918us/step - loss: 1.2361 - accuracy: 0.4258\n",
      "1250/1250 [==============================] - 1s 921us/step - loss: 1.2321 - accuracy: 0.4284\n",
      "1250/1250 [==============================] - 1s 876us/step - loss: 1.2353 - accuracy: 0.4302\n",
      "1250/1250 [==============================] - 1s 895us/step - loss: 1.2372 - accuracy: 0.4254\n",
      "1250/1250 [==============================] - 1s 900us/step - loss: 1.2352 - accuracy: 0.4213\n",
      "1250/1250 [==============================] - 1s 919us/step - loss: 1.2336 - accuracy: 0.4237\n",
      "1250/1250 [==============================] - 1s 950us/step - loss: 1.2332 - accuracy: 0.4275\n",
      "1250/1250 [==============================] - 1s 926us/step - loss: 1.2324 - accuracy: 0.4238\n",
      "1250/1250 [==============================] - 1s 933us/step - loss: 1.2345 - accuracy: 0.4263\n",
      "1250/1250 [==============================] - 1s 938us/step - loss: 1.2408 - accuracy: 0.4195\n",
      "1250/1250 [==============================] - 1s 956us/step - loss: 1.2307 - accuracy: 0.4290\n",
      "1250/1250 [==============================] - 1s 928us/step - loss: 1.2371 - accuracy: 0.4259\n",
      "1250/1250 [==============================] - 1s 919us/step - loss: 1.2314 - accuracy: 0.4290\n",
      "1250/1250 [==============================] - 1s 933us/step - loss: 1.2377 - accuracy: 0.4274\n",
      "1250/1250 [==============================] - 1s 954us/step - loss: 1.2399 - accuracy: 0.4275\n",
      "1250/1250 [==============================] - 1s 898us/step - loss: 1.2416 - accuracy: 0.4205\n",
      "1250/1250 [==============================] - 1s 902us/step - loss: 1.2334 - accuracy: 0.4264\n",
      "1250/1250 [==============================] - 1s 920us/step - loss: 1.2431 - accuracy: 0.4243\n",
      "1250/1250 [==============================] - 1s 937us/step - loss: 1.2308 - accuracy: 0.4263\n",
      "1250/1250 [==============================] - 1s 925us/step - loss: 1.2347 - accuracy: 0.4273\n",
      "1250/1250 [==============================] - 1s 918us/step - loss: 1.2371 - accuracy: 0.4258\n",
      "1250/1250 [==============================] - 1s 943us/step - loss: 1.2316 - accuracy: 0.4329\n",
      "1250/1250 [==============================] - 1s 893us/step - loss: 1.2215 - accuracy: 0.4306\n",
      "1250/1250 [==============================] - 1s 914us/step - loss: 1.2325 - accuracy: 0.4273\n",
      "1250/1250 [==============================] - 1s 924us/step - loss: 1.2442 - accuracy: 0.4193\n",
      "1250/1250 [==============================] - 1s 944us/step - loss: 1.2330 - accuracy: 0.4232\n",
      "1250/1250 [==============================] - 1s 896us/step - loss: 1.2361 - accuracy: 0.4238\n",
      "1250/1250 [==============================] - 1s 885us/step - loss: 1.2330 - accuracy: 0.4275\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.2374 - accuracy: 0.4211\n",
      "1250/1250 [==============================] - 1s 950us/step - loss: 1.2314 - accuracy: 0.4270\n",
      "1250/1250 [==============================] - 1s 940us/step - loss: 1.2296 - accuracy: 0.4314\n",
      "1250/1250 [==============================] - 1s 920us/step - loss: 1.2400 - accuracy: 0.4257\n",
      "1250/1250 [==============================] - 1s 916us/step - loss: 1.2299 - accuracy: 0.4291\n",
      "1250/1250 [==============================] - 1s 941us/step - loss: 1.2260 - accuracy: 0.4256\n",
      "1250/1250 [==============================] - 1s 938us/step - loss: 1.2327 - accuracy: 0.4224\n",
      "1250/1250 [==============================] - 1s 933us/step - loss: 1.2328 - accuracy: 0.4223\n",
      "1250/1250 [==============================] - 1s 962us/step - loss: 1.2315 - accuracy: 0.4254\n",
      "1250/1250 [==============================] - 1s 902us/step - loss: 1.2251 - accuracy: 0.4277\n",
      "1250/1250 [==============================] - 1s 877us/step - loss: 1.2257 - accuracy: 0.4256\n",
      "1250/1250 [==============================] - 1s 920us/step - loss: 1.2349 - accuracy: 0.4251\n",
      "1250/1250 [==============================] - 1s 950us/step - loss: 1.2255 - accuracy: 0.4291\n",
      "1250/1250 [==============================] - 1s 916us/step - loss: 1.2376 - accuracy: 0.4237\n",
      "1250/1250 [==============================] - 1s 935us/step - loss: 1.2327 - accuracy: 0.4254\n",
      "1250/1250 [==============================] - 1s 922us/step - loss: 1.2274 - accuracy: 0.4299\n",
      "1250/1250 [==============================] - 1s 932us/step - loss: 1.2402 - accuracy: 0.4263\n",
      "1250/1250 [==============================] - 1s 915us/step - loss: 1.2388 - accuracy: 0.4248\n",
      "1250/1250 [==============================] - 1s 930us/step - loss: 1.2312 - accuracy: 0.4252\n",
      "1250/1250 [==============================] - 1s 932us/step - loss: 1.2260 - accuracy: 0.4312\n",
      "1250/1250 [==============================] - 1s 928us/step - loss: 1.2260 - accuracy: 0.4266\n",
      "1250/1250 [==============================] - 1s 958us/step - loss: 1.2456 - accuracy: 0.4245\n",
      "1250/1250 [==============================] - 1s 903us/step - loss: 1.2348 - accuracy: 0.4236\n",
      "1250/1250 [==============================] - 1s 882us/step - loss: 1.2341 - accuracy: 0.4268\n",
      "1250/1250 [==============================] - 1s 894us/step - loss: 1.2243 - accuracy: 0.4297\n",
      "1250/1250 [==============================] - 1s 913us/step - loss: 1.2328 - accuracy: 0.4240\n",
      "1250/1250 [==============================] - 1s 954us/step - loss: 1.2305 - accuracy: 0.4227\n",
      "1250/1250 [==============================] - 1s 926us/step - loss: 1.2385 - accuracy: 0.4250\n",
      "1250/1250 [==============================] - 1s 925us/step - loss: 1.2416 - accuracy: 0.4237\n",
      "1250/1250 [==============================] - 1s 924us/step - loss: 1.2325 - accuracy: 0.4218\n",
      "1250/1250 [==============================] - 1s 941us/step - loss: 1.2331 - accuracy: 0.4283\n",
      "1250/1250 [==============================] - 1s 916us/step - loss: 1.2318 - accuracy: 0.4276\n",
      "1250/1250 [==============================] - 1s 928us/step - loss: 1.2335 - accuracy: 0.4236\n",
      "1250/1250 [==============================] - 1s 949us/step - loss: 1.2293 - accuracy: 0.4301\n",
      "1250/1250 [==============================] - 1s 930us/step - loss: 1.2392 - accuracy: 0.4256\n",
      "1250/1250 [==============================] - 1s 872us/step - loss: 1.2219 - accuracy: 0.4315\n",
      "1250/1250 [==============================] - 1s 903us/step - loss: 1.2294 - accuracy: 0.4312\n",
      "1250/1250 [==============================] - 1s 948us/step - loss: 1.2387 - accuracy: 0.4266\n",
      "1250/1250 [==============================] - 1s 930us/step - loss: 1.2343 - accuracy: 0.4284\n",
      "1250/1250 [==============================] - 1s 897us/step - loss: 1.2310 - accuracy: 0.4300\n",
      "1250/1250 [==============================] - 1s 931us/step - loss: 1.2421 - accuracy: 0.4191\n",
      "1250/1250 [==============================] - 1s 931us/step - loss: 1.2327 - accuracy: 0.4240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 1s 956us/step - loss: 1.2341 - accuracy: 0.4207\n",
      "1250/1250 [==============================] - 1s 956us/step - loss: 1.2279 - accuracy: 0.4267\n",
      "1250/1250 [==============================] - 1s 928us/step - loss: 1.2389 - accuracy: 0.4256\n",
      "1250/1250 [==============================] - 1s 910us/step - loss: 1.2342 - accuracy: 0.4252\n",
      "1250/1250 [==============================] - 1s 883us/step - loss: 1.2278 - accuracy: 0.4228\n",
      "1250/1250 [==============================] - 1s 909us/step - loss: 1.2284 - accuracy: 0.4282\n",
      "1250/1250 [==============================] - 1s 917us/step - loss: 1.2386 - accuracy: 0.4250\n",
      "1250/1250 [==============================] - 1s 922us/step - loss: 1.2245 - accuracy: 0.4267\n",
      "1250/1250 [==============================] - 1s 934us/step - loss: 1.2359 - accuracy: 0.4241\n",
      "1250/1250 [==============================] - 1s 956us/step - loss: 1.2335 - accuracy: 0.4216\n",
      "1250/1250 [==============================] - 1s 951us/step - loss: 1.2366 - accuracy: 0.4259\n",
      "1250/1250 [==============================] - 1s 916us/step - loss: 1.2460 - accuracy: 0.4151\n",
      "1250/1250 [==============================] - 1s 930us/step - loss: 1.2300 - accuracy: 0.4281\n",
      "1250/1250 [==============================] - 1s 932us/step - loss: 1.2301 - accuracy: 0.4281\n",
      "1250/1250 [==============================] - 1s 936us/step - loss: 1.2297 - accuracy: 0.4265\n",
      "1250/1250 [==============================] - 1s 863us/step - loss: 1.2294 - accuracy: 0.4245\n",
      "1250/1250 [==============================] - 1s 905us/step - loss: 1.2257 - accuracy: 0.4275\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2289 - accuracy: 0.4240\n",
      "1250/1250 [==============================] - 1s 948us/step - loss: 1.2294 - accuracy: 0.4270\n",
      "1250/1250 [==============================] - 1s 967us/step - loss: 1.2235 - accuracy: 0.4257\n",
      "1250/1250 [==============================] - 1s 945us/step - loss: 1.2304 - accuracy: 0.4282\n",
      "1250/1250 [==============================] - 1s 934us/step - loss: 1.2294 - accuracy: 0.4257\n",
      "1250/1250 [==============================] - 1s 940us/step - loss: 1.2246 - accuracy: 0.4328\n",
      "1250/1250 [==============================] - 1s 954us/step - loss: 1.2258 - accuracy: 0.4260\n",
      "1250/1250 [==============================] - 1s 938us/step - loss: 1.2260 - accuracy: 0.4278\n",
      "1250/1250 [==============================] - 1s 923us/step - loss: 1.2304 - accuracy: 0.4268\n",
      "1250/1250 [==============================] - 1s 886us/step - loss: 1.2304 - accuracy: 0.4225\n",
      "1250/1250 [==============================] - 1s 899us/step - loss: 1.2346 - accuracy: 0.4251\n",
      "1250/1250 [==============================] - 1s 928us/step - loss: 1.2343 - accuracy: 0.4223\n",
      "1250/1250 [==============================] - 1s 945us/step - loss: 1.2326 - accuracy: 0.4307\n",
      "1250/1250 [==============================] - 1s 936us/step - loss: 1.2304 - accuracy: 0.4240\n",
      "1250/1250 [==============================] - 1s 943us/step - loss: 1.2288 - accuracy: 0.4261\n",
      "1250/1250 [==============================] - 1s 934us/step - loss: 1.2194 - accuracy: 0.4296\n",
      "1250/1250 [==============================] - 1s 937us/step - loss: 1.2380 - accuracy: 0.4251\n",
      "1250/1250 [==============================] - 1s 947us/step - loss: 1.2288 - accuracy: 0.4278\n",
      "1250/1250 [==============================] - 1s 935us/step - loss: 1.2266 - accuracy: 0.4265\n",
      "1250/1250 [==============================] - 1s 930us/step - loss: 1.2283 - accuracy: 0.4288\n",
      "1250/1250 [==============================] - 1s 924us/step - loss: 1.2273 - accuracy: 0.4277\n",
      "1250/1250 [==============================] - 1s 906us/step - loss: 1.2199 - accuracy: 0.4313\n",
      "1250/1250 [==============================] - 1s 906us/step - loss: 1.2299 - accuracy: 0.4243\n",
      "1250/1250 [==============================] - 1s 877us/step - loss: 1.2249 - accuracy: 0.4290\n",
      "1250/1250 [==============================] - 1s 918us/step - loss: 1.2332 - accuracy: 0.4245\n",
      "1250/1250 [==============================] - 1s 931us/step - loss: 1.2173 - accuracy: 0.4325\n",
      "1250/1250 [==============================] - 1s 934us/step - loss: 1.2351 - accuracy: 0.4206\n",
      "1250/1250 [==============================] - 1s 932us/step - loss: 1.2240 - accuracy: 0.4268\n",
      "1250/1250 [==============================] - 1s 961us/step - loss: 1.2232 - accuracy: 0.4317\n",
      "1250/1250 [==============================] - 1s 944us/step - loss: 1.2275 - accuracy: 0.4221\n",
      "1250/1250 [==============================] - 1s 941us/step - loss: 1.2290 - accuracy: 0.4261\n",
      "1250/1250 [==============================] - 1s 927us/step - loss: 1.2258 - accuracy: 0.4277\n",
      "1250/1250 [==============================] - 1s 943us/step - loss: 1.2287 - accuracy: 0.4281\n",
      "1250/1250 [==============================] - 1s 887us/step - loss: 1.2292 - accuracy: 0.4278\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.2218 - accuracy: 0.4270\n",
      "1250/1250 [==============================] - 1s 927us/step - loss: 1.2254 - accuracy: 0.4275\n",
      "1250/1250 [==============================] - 1s 933us/step - loss: 1.2324 - accuracy: 0.4238\n",
      "1250/1250 [==============================] - 1s 929us/step - loss: 1.2230 - accuracy: 0.4267\n",
      "1250/1250 [==============================] - 1s 936us/step - loss: 1.2325 - accuracy: 0.4241\n",
      "1250/1250 [==============================] - 1s 900us/step - loss: 1.2358 - accuracy: 0.4261\n",
      "1250/1250 [==============================] - 1s 954us/step - loss: 1.2299 - accuracy: 0.4265\n",
      "1250/1250 [==============================] - 1s 948us/step - loss: 1.2228 - accuracy: 0.4288\n",
      "1250/1250 [==============================] - 1s 941us/step - loss: 1.2285 - accuracy: 0.4252\n",
      "1250/1250 [==============================] - 1s 933us/step - loss: 1.2358 - accuracy: 0.4232\n",
      "1250/1250 [==============================] - 1s 918us/step - loss: 1.2292 - accuracy: 0.4264\n",
      "1250/1250 [==============================] - 1s 895us/step - loss: 1.2355 - accuracy: 0.4227\n",
      "1250/1250 [==============================] - 1s 900us/step - loss: 1.2265 - accuracy: 0.4248\n",
      "1250/1250 [==============================] - 1s 930us/step - loss: 1.2271 - accuracy: 0.4268\n",
      "1250/1250 [==============================] - 1s 946us/step - loss: 1.2311 - accuracy: 0.4277\n",
      "1250/1250 [==============================] - 1s 951us/step - loss: 1.2282 - accuracy: 0.4275\n",
      "1250/1250 [==============================] - 1s 936us/step - loss: 1.2298 - accuracy: 0.4249\n",
      "1250/1250 [==============================] - 1s 934us/step - loss: 1.2280 - accuracy: 0.4259\n",
      "1250/1250 [==============================] - 1s 929us/step - loss: 1.2310 - accuracy: 0.4258\n",
      "1250/1250 [==============================] - 1s 942us/step - loss: 1.2319 - accuracy: 0.4256\n",
      "1250/1250 [==============================] - 1s 973us/step - loss: 1.2267 - accuracy: 0.4252\n",
      "1250/1250 [==============================] - 1s 996us/step - loss: 1.2302 - accuracy: 0.4247\n",
      "1250/1250 [==============================] - 1s 964us/step - loss: 1.2284 - accuracy: 0.4292\n",
      "1250/1250 [==============================] - 1s 910us/step - loss: 1.2341 - accuracy: 0.4218\n",
      "1250/1250 [==============================] - 1s 899us/step - loss: 1.2222 - accuracy: 0.4277\n",
      "1250/1250 [==============================] - 1s 920us/step - loss: 1.2358 - accuracy: 0.4272\n",
      "1250/1250 [==============================] - 1s 951us/step - loss: 1.2293 - accuracy: 0.4280\n",
      "1250/1250 [==============================] - 1s 974us/step - loss: 1.2326 - accuracy: 0.4245\n",
      "1250/1250 [==============================] - 1s 974us/step - loss: 1.2341 - accuracy: 0.4246\n",
      "1250/1250 [==============================] - 1s 947us/step - loss: 1.2329 - accuracy: 0.4227\n",
      "1250/1250 [==============================] - 1s 956us/step - loss: 1.2239 - accuracy: 0.4311\n",
      "1250/1250 [==============================] - 1s 967us/step - loss: 1.2241 - accuracy: 0.4221\n",
      "1250/1250 [==============================] - 1s 933us/step - loss: 1.2295 - accuracy: 0.4250\n",
      "1250/1250 [==============================] - 1s 961us/step - loss: 1.2316 - accuracy: 0.4268\n",
      "1250/1250 [==============================] - 1s 924us/step - loss: 1.2310 - accuracy: 0.4249\n",
      "1250/1250 [==============================] - 1s 988us/step - loss: 1.2278 - accuracy: 0.4285\n",
      "1250/1250 [==============================] - 1s 907us/step - loss: 1.2289 - accuracy: 0.4237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 1s 913us/step - loss: 1.2239 - accuracy: 0.4295\n",
      "1250/1250 [==============================] - 1s 923us/step - loss: 1.2278 - accuracy: 0.4211\n",
      "1250/1250 [==============================] - 1s 937us/step - loss: 1.2302 - accuracy: 0.4200\n",
      "1250/1250 [==============================] - 1s 949us/step - loss: 1.2211 - accuracy: 0.4246\n",
      "1250/1250 [==============================] - 1s 966us/step - loss: 1.2312 - accuracy: 0.4236\n",
      "1250/1250 [==============================] - 1s 953us/step - loss: 1.2368 - accuracy: 0.4164\n",
      "1250/1250 [==============================] - 1s 938us/step - loss: 1.2331 - accuracy: 0.4231\n",
      "1250/1250 [==============================] - 1s 943us/step - loss: 1.2181 - accuracy: 0.4278\n",
      "1250/1250 [==============================] - 1s 962us/step - loss: 1.2270 - accuracy: 0.4260\n",
      "1250/1250 [==============================] - 1s 943us/step - loss: 1.2267 - accuracy: 0.4245\n",
      "1250/1250 [==============================] - 1s 906us/step - loss: 1.2308 - accuracy: 0.4283\n",
      "1250/1250 [==============================] - 1s 910us/step - loss: 1.2260 - accuracy: 0.4254\n",
      "1250/1250 [==============================] - 1s 936us/step - loss: 1.2278 - accuracy: 0.4270\n",
      "1250/1250 [==============================] - 1s 956us/step - loss: 1.2375 - accuracy: 0.4258\n",
      "1250/1250 [==============================] - 1s 988us/step - loss: 1.2238 - accuracy: 0.4275\n",
      "1250/1250 [==============================] - 1s 974us/step - loss: 1.2292 - accuracy: 0.4260\n",
      "1250/1250 [==============================] - 1s 964us/step - loss: 1.2217 - accuracy: 0.4306\n",
      "1250/1250 [==============================] - 1s 956us/step - loss: 1.2338 - accuracy: 0.4243\n",
      "1250/1250 [==============================] - 1s 936us/step - loss: 1.2269 - accuracy: 0.4223\n",
      "1250/1250 [==============================] - 1s 938us/step - loss: 1.2299 - accuracy: 0.4271\n",
      "1250/1250 [==============================] - 1s 971us/step - loss: 1.2295 - accuracy: 0.4240\n",
      "1250/1250 [==============================] - 1s 978us/step - loss: 1.2300 - accuracy: 0.4245\n",
      "1250/1250 [==============================] - 1s 988us/step - loss: 1.2274 - accuracy: 0.4255\n",
      "1250/1250 [==============================] - 1s 974us/step - loss: 1.2273 - accuracy: 0.4273\n",
      "1250/1250 [==============================] - 1s 922us/step - loss: 1.2316 - accuracy: 0.4243\n",
      "1250/1250 [==============================] - 1s 909us/step - loss: 1.2310 - accuracy: 0.4243\n",
      "1250/1250 [==============================] - 1s 920us/step - loss: 1.2391 - accuracy: 0.4189\n",
      "1250/1250 [==============================] - 1s 944us/step - loss: 1.2318 - accuracy: 0.4221\n",
      "1250/1250 [==============================] - 1s 936us/step - loss: 1.2315 - accuracy: 0.4222\n",
      "1250/1250 [==============================] - 1s 956us/step - loss: 1.2323 - accuracy: 0.4233\n",
      "1250/1250 [==============================] - 1s 952us/step - loss: 1.2208 - accuracy: 0.4270\n",
      "1250/1250 [==============================] - 1s 960us/step - loss: 1.2214 - accuracy: 0.4282\n",
      "1250/1250 [==============================] - 1s 969us/step - loss: 1.2276 - accuracy: 0.4216\n",
      "1250/1250 [==============================] - 1s 974us/step - loss: 1.2346 - accuracy: 0.4219\n",
      "1250/1250 [==============================] - 1s 957us/step - loss: 1.2209 - accuracy: 0.4257\n",
      "1250/1250 [==============================] - 1s 951us/step - loss: 1.2235 - accuracy: 0.4274\n",
      "1250/1250 [==============================] - 1s 936us/step - loss: 1.2208 - accuracy: 0.4296\n",
      "1250/1250 [==============================] - 1s 940us/step - loss: 1.2194 - accuracy: 0.4286\n",
      "1250/1250 [==============================] - 1s 942us/step - loss: 1.2356 - accuracy: 0.4238\n",
      "1250/1250 [==============================] - 1s 902us/step - loss: 1.2291 - accuracy: 0.4284\n",
      "1250/1250 [==============================] - 1s 893us/step - loss: 1.2251 - accuracy: 0.4244\n",
      "1250/1250 [==============================] - 1s 910us/step - loss: 1.2294 - accuracy: 0.4238\n",
      "1250/1250 [==============================] - 1s 937us/step - loss: 1.2271 - accuracy: 0.4263\n",
      "1250/1250 [==============================] - 1s 938us/step - loss: 1.2274 - accuracy: 0.4265\n",
      "1250/1250 [==============================] - 1s 980us/step - loss: 1.2257 - accuracy: 0.4313\n",
      "1250/1250 [==============================] - 1s 958us/step - loss: 1.2327 - accuracy: 0.4215\n",
      "1250/1250 [==============================] - 1s 994us/step - loss: 1.2266 - accuracy: 0.4252\n",
      "1250/1250 [==============================] - 1s 962us/step - loss: 1.2346 - accuracy: 0.4263\n",
      "1250/1250 [==============================] - 1s 944us/step - loss: 1.2383 - accuracy: 0.4205\n",
      "1250/1250 [==============================] - 1s 931us/step - loss: 1.2299 - accuracy: 0.4247\n",
      "1250/1250 [==============================] - 1s 944us/step - loss: 1.2300 - accuracy: 0.4288\n",
      "1250/1250 [==============================] - 1s 939us/step - loss: 1.2326 - accuracy: 0.4225\n",
      "1250/1250 [==============================] - 1s 962us/step - loss: 1.2401 - accuracy: 0.4235\n",
      "1250/1250 [==============================] - 1s 946us/step - loss: 1.2205 - accuracy: 0.4283\n",
      "1250/1250 [==============================] - 1s 938us/step - loss: 1.2257 - accuracy: 0.4293\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.2195 - accuracy: 0.4290\n",
      "1250/1250 [==============================] - 1s 937us/step - loss: 1.2207 - accuracy: 0.4278\n",
      "1250/1250 [==============================] - 1s 961us/step - loss: 1.2290 - accuracy: 0.4283\n",
      "1250/1250 [==============================] - 1s 974us/step - loss: 1.2223 - accuracy: 0.4281\n",
      "1250/1250 [==============================] - 1s 956us/step - loss: 1.2290 - accuracy: 0.4253\n",
      "1250/1250 [==============================] - 1s 973us/step - loss: 1.2206 - accuracy: 0.4291\n",
      "1250/1250 [==============================] - 1s 949us/step - loss: 1.2233 - accuracy: 0.4261\n",
      "1250/1250 [==============================] - 1s 959us/step - loss: 1.2293 - accuracy: 0.4282\n",
      "1250/1250 [==============================] - 1s 956us/step - loss: 1.2188 - accuracy: 0.4278\n",
      "1250/1250 [==============================] - 1s 941us/step - loss: 1.2217 - accuracy: 0.4243\n",
      "1250/1250 [==============================] - 1s 945us/step - loss: 1.2369 - accuracy: 0.4191\n",
      "1250/1250 [==============================] - 1s 931us/step - loss: 1.2318 - accuracy: 0.4248\n",
      "1250/1250 [==============================] - 1s 940us/step - loss: 1.2251 - accuracy: 0.4263\n",
      "1250/1250 [==============================] - 1s 961us/step - loss: 1.2263 - accuracy: 0.4250\n",
      "1250/1250 [==============================] - 1s 958us/step - loss: 1.2249 - accuracy: 0.4261\n",
      "1250/1250 [==============================] - 1s 944us/step - loss: 1.2237 - accuracy: 0.4251\n",
      "1250/1250 [==============================] - 1s 901us/step - loss: 1.2246 - accuracy: 0.4310\n",
      "1250/1250 [==============================] - 1s 905us/step - loss: 1.2428 - accuracy: 0.4205\n",
      "1250/1250 [==============================] - 1s 922us/step - loss: 1.2260 - accuracy: 0.4276\n",
      "1250/1250 [==============================] - 1s 962us/step - loss: 1.2258 - accuracy: 0.4251\n",
      "1250/1250 [==============================] - 1s 979us/step - loss: 1.2344 - accuracy: 0.4274\n",
      "1250/1250 [==============================] - 1s 972us/step - loss: 1.2265 - accuracy: 0.4263\n",
      "1250/1250 [==============================] - 1s 972us/step - loss: 1.2298 - accuracy: 0.4237\n",
      "1250/1250 [==============================] - 1s 953us/step - loss: 1.2201 - accuracy: 0.4321\n",
      "1250/1250 [==============================] - 1s 938us/step - loss: 1.2288 - accuracy: 0.4251\n",
      "1250/1250 [==============================] - 1s 939us/step - loss: 1.2265 - accuracy: 0.4266\n",
      "1250/1250 [==============================] - 1s 944us/step - loss: 1.2207 - accuracy: 0.4281\n",
      "1250/1250 [==============================] - 1s 934us/step - loss: 1.2237 - accuracy: 0.4223\n",
      "1250/1250 [==============================] - 1s 917us/step - loss: 1.2244 - accuracy: 0.4255\n",
      "1250/1250 [==============================] - 1s 913us/step - loss: 1.2291 - accuracy: 0.4259\n",
      "1250/1250 [==============================] - 1s 929us/step - loss: 1.2206 - accuracy: 0.4282\n",
      "1250/1250 [==============================] - 1s 944us/step - loss: 1.2254 - accuracy: 0.4255\n",
      "1250/1250 [==============================] - 1s 951us/step - loss: 1.2268 - accuracy: 0.4251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 1s 964us/step - loss: 1.2223 - accuracy: 0.4284\n",
      "1250/1250 [==============================] - 1s 976us/step - loss: 1.2184 - accuracy: 0.4232\n",
      "1250/1250 [==============================] - 1s 933us/step - loss: 1.2334 - accuracy: 0.4231\n",
      "1250/1250 [==============================] - 1s 974us/step - loss: 1.2286 - accuracy: 0.4246\n",
      "1250/1250 [==============================] - 1s 971us/step - loss: 1.2217 - accuracy: 0.4277\n",
      "1250/1250 [==============================] - 1s 973us/step - loss: 1.2191 - accuracy: 0.4393\n",
      "1250/1250 [==============================] - 1s 969us/step - loss: 1.2205 - accuracy: 0.4315\n",
      "1250/1250 [==============================] - 1s 966us/step - loss: 1.2377 - accuracy: 0.4210\n",
      "1250/1250 [==============================] - 1s 958us/step - loss: 1.2243 - accuracy: 0.4262\n",
      "1250/1250 [==============================] - 1s 948us/step - loss: 1.2231 - accuracy: 0.4262\n",
      "1250/1250 [==============================] - 1s 954us/step - loss: 1.2245 - accuracy: 0.4272\n",
      "1250/1250 [==============================] - 1s 941us/step - loss: 1.2271 - accuracy: 0.4249\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.2340 - accuracy: 0.4230\n",
      "1250/1250 [==============================] - 1s 904us/step - loss: 1.2264 - accuracy: 0.4235\n",
      "1250/1250 [==============================] - 1s 922us/step - loss: 1.2158 - accuracy: 0.4277\n",
      "1250/1250 [==============================] - 1s 954us/step - loss: 1.2366 - accuracy: 0.4247\n",
      "1250/1250 [==============================] - 1s 935us/step - loss: 1.2223 - accuracy: 0.4265\n",
      "1250/1250 [==============================] - 1s 944us/step - loss: 1.2195 - accuracy: 0.4278\n",
      "1250/1250 [==============================] - 1s 949us/step - loss: 1.2382 - accuracy: 0.4164\n",
      "1250/1250 [==============================] - 1s 949us/step - loss: 1.2299 - accuracy: 0.4238\n",
      "1250/1250 [==============================] - 1s 943us/step - loss: 1.2313 - accuracy: 0.4240\n",
      "1250/1250 [==============================] - 1s 942us/step - loss: 1.2265 - accuracy: 0.4257\n",
      "1250/1250 [==============================] - 1s 950us/step - loss: 1.2223 - accuracy: 0.4234\n",
      "1250/1250 [==============================] - 1s 954us/step - loss: 1.2255 - accuracy: 0.4216\n",
      "1250/1250 [==============================] - 1s 928us/step - loss: 1.2253 - accuracy: 0.4257\n",
      "1250/1250 [==============================] - 1s 928us/step - loss: 1.2286 - accuracy: 0.4266\n",
      "1250/1250 [==============================] - 1s 920us/step - loss: 1.2298 - accuracy: 0.4224\n",
      "1250/1250 [==============================] - 1s 956us/step - loss: 1.2290 - accuracy: 0.4254\n",
      "1250/1250 [==============================] - 1s 930us/step - loss: 1.2243 - accuracy: 0.4263\n",
      "1250/1250 [==============================] - 1s 906us/step - loss: 1.2295 - accuracy: 0.4231\n",
      "1250/1250 [==============================] - 1s 910us/step - loss: 1.2266 - accuracy: 0.4231\n",
      "1250/1250 [==============================] - 1s 939us/step - loss: 1.2258 - accuracy: 0.4252\n",
      "1250/1250 [==============================] - 1s 960us/step - loss: 1.2266 - accuracy: 0.4251\n",
      "1250/1250 [==============================] - 1s 954us/step - loss: 1.2347 - accuracy: 0.4230\n",
      "1250/1250 [==============================] - 1s 954us/step - loss: 1.2213 - accuracy: 0.4301\n",
      "1250/1250 [==============================] - 1s 951us/step - loss: 1.2307 - accuracy: 0.4252\n",
      "1250/1250 [==============================] - 1s 946us/step - loss: 1.2355 - accuracy: 0.4250\n",
      "1250/1250 [==============================] - 1s 952us/step - loss: 1.2338 - accuracy: 0.4249\n",
      "1250/1250 [==============================] - 1s 953us/step - loss: 1.2278 - accuracy: 0.4234\n",
      "1250/1250 [==============================] - 1s 960us/step - loss: 1.2230 - accuracy: 0.4272\n",
      "1250/1250 [==============================] - 1s 962us/step - loss: 1.2228 - accuracy: 0.4288\n",
      "1250/1250 [==============================] - 1s 963us/step - loss: 1.2233 - accuracy: 0.4300\n",
      "1250/1250 [==============================] - 1s 914us/step - loss: 1.2262 - accuracy: 0.4238\n",
      "1250/1250 [==============================] - 1s 900us/step - loss: 1.2255 - accuracy: 0.4271\n",
      "1250/1250 [==============================] - 1s 927us/step - loss: 1.2313 - accuracy: 0.4208\n",
      "1250/1250 [==============================] - 1s 933us/step - loss: 1.2244 - accuracy: 0.4238\n",
      "1250/1250 [==============================] - 1s 950us/step - loss: 1.2289 - accuracy: 0.4272\n",
      "1250/1250 [==============================] - 1s 964us/step - loss: 1.2311 - accuracy: 0.4226\n",
      "1250/1250 [==============================] - 1s 943us/step - loss: 1.2257 - accuracy: 0.4214\n",
      "1250/1250 [==============================] - 1s 953us/step - loss: 1.2335 - accuracy: 0.4205\n",
      "1250/1250 [==============================] - 1s 946us/step - loss: 1.2236 - accuracy: 0.4250\n",
      "1250/1250 [==============================] - 1s 980us/step - loss: 1.2206 - accuracy: 0.4297\n",
      "1250/1250 [==============================] - 1s 962us/step - loss: 1.2255 - accuracy: 0.4235\n",
      "1250/1250 [==============================] - 1s 951us/step - loss: 1.2267 - accuracy: 0.4237\n",
      "1250/1250 [==============================] - 1s 955us/step - loss: 1.2321 - accuracy: 0.4265\n",
      "1250/1250 [==============================] - 1s 945us/step - loss: 1.2329 - accuracy: 0.4218\n",
      "1250/1250 [==============================] - 1s 948us/step - loss: 1.2267 - accuracy: 0.4275\n",
      "1250/1250 [==============================] - 1s 945us/step - loss: 1.2384 - accuracy: 0.4215\n",
      "1250/1250 [==============================] - 1s 943us/step - loss: 1.2248 - accuracy: 0.4261\n",
      "1250/1250 [==============================] - 1s 918us/step - loss: 1.2319 - accuracy: 0.4227\n",
      "1250/1250 [==============================] - 1s 919us/step - loss: 1.2219 - accuracy: 0.4294\n",
      "1250/1250 [==============================] - 1s 963us/step - loss: 1.2247 - accuracy: 0.4275\n",
      "1250/1250 [==============================] - 1s 958us/step - loss: 1.2207 - accuracy: 0.4247\n",
      "1250/1250 [==============================] - 1s 953us/step - loss: 1.2236 - accuracy: 0.4286\n",
      "1250/1250 [==============================] - 1s 960us/step - loss: 1.2184 - accuracy: 0.4316\n",
      "1250/1250 [==============================] - 1s 947us/step - loss: 1.2257 - accuracy: 0.4260\n",
      "1250/1250 [==============================] - 1s 970us/step - loss: 1.2227 - accuracy: 0.4290\n",
      "1250/1250 [==============================] - 1s 975us/step - loss: 1.2278 - accuracy: 0.4238\n",
      "1250/1250 [==============================] - 1s 962us/step - loss: 1.2307 - accuracy: 0.4214\n",
      "1250/1250 [==============================] - 1s 981us/step - loss: 1.2341 - accuracy: 0.4236\n",
      "1250/1250 [==============================] - 1s 958us/step - loss: 1.2211 - accuracy: 0.4270\n",
      "1250/1250 [==============================] - 1s 905us/step - loss: 1.2240 - accuracy: 0.4240\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.2284 - accuracy: 0.4281\n",
      "1250/1250 [==============================] - 1s 926us/step - loss: 1.2244 - accuracy: 0.4234\n",
      "1250/1250 [==============================] - 1s 936us/step - loss: 1.2250 - accuracy: 0.4236\n",
      "1250/1250 [==============================] - 1s 938us/step - loss: 1.2227 - accuracy: 0.4274\n",
      "1250/1250 [==============================] - 1s 969us/step - loss: 1.2221 - accuracy: 0.4288\n",
      "1250/1250 [==============================] - 1s 961us/step - loss: 1.2234 - accuracy: 0.4233\n",
      "1250/1250 [==============================] - 1s 954us/step - loss: 1.2205 - accuracy: 0.4269\n",
      "1250/1250 [==============================] - 1s 947us/step - loss: 1.2215 - accuracy: 0.4311\n",
      "1250/1250 [==============================] - 1s 953us/step - loss: 1.2230 - accuracy: 0.4280\n",
      "1250/1250 [==============================] - 1s 964us/step - loss: 1.2253 - accuracy: 0.4252\n",
      "1250/1250 [==============================] - 1s 948us/step - loss: 1.2243 - accuracy: 0.4253\n",
      "1250/1250 [==============================] - 1s 954us/step - loss: 1.2246 - accuracy: 0.4211\n",
      "1250/1250 [==============================] - 1s 952us/step - loss: 1.2299 - accuracy: 0.4259\n",
      "1250/1250 [==============================] - 1s 938us/step - loss: 1.2210 - accuracy: 0.4275\n",
      "1250/1250 [==============================] - 1s 918us/step - loss: 1.2239 - accuracy: 0.4225\n",
      "1250/1250 [==============================] - 1s 919us/step - loss: 1.2293 - accuracy: 0.4279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 1s 950us/step - loss: 1.2265 - accuracy: 0.4238\n",
      "1250/1250 [==============================] - 1s 996us/step - loss: 1.2191 - accuracy: 0.4315\n",
      "1250/1250 [==============================] - 1s 977us/step - loss: 1.2353 - accuracy: 0.4229\n",
      "1250/1250 [==============================] - 1s 969us/step - loss: 1.2278 - accuracy: 0.4272\n",
      "1250/1250 [==============================] - 1s 988us/step - loss: 1.2223 - accuracy: 0.4263\n",
      "1250/1250 [==============================] - 1s 954us/step - loss: 1.2238 - accuracy: 0.4220\n",
      "1250/1250 [==============================] - 1s 955us/step - loss: 1.2292 - accuracy: 0.4222\n",
      "1250/1250 [==============================] - 1s 945us/step - loss: 1.2311 - accuracy: 0.4248\n",
      "1250/1250 [==============================] - 1s 973us/step - loss: 1.2271 - accuracy: 0.4232\n",
      "1250/1250 [==============================] - 1s 959us/step - loss: 1.2247 - accuracy: 0.4219\n",
      "1250/1250 [==============================] - 1s 952us/step - loss: 1.2239 - accuracy: 0.4283\n",
      "1250/1250 [==============================] - 1s 951us/step - loss: 1.2284 - accuracy: 0.4266\n",
      "1250/1250 [==============================] - 1s 923us/step - loss: 1.2265 - accuracy: 0.4258\n",
      "1250/1250 [==============================] - 1s 914us/step - loss: 1.2253 - accuracy: 0.4272\n",
      "1250/1250 [==============================] - 1s 936us/step - loss: 1.2219 - accuracy: 0.4270\n",
      "1250/1250 [==============================] - 1s 946us/step - loss: 1.2212 - accuracy: 0.4277\n",
      "1250/1250 [==============================] - 1s 936us/step - loss: 1.2365 - accuracy: 0.4207\n",
      "1250/1250 [==============================] - 1s 953us/step - loss: 1.2249 - accuracy: 0.4288\n",
      "1250/1250 [==============================] - 1s 968us/step - loss: 1.2234 - accuracy: 0.4258\n",
      "1250/1250 [==============================] - 1s 972us/step - loss: 1.2248 - accuracy: 0.4244\n",
      "1250/1250 [==============================] - 1s 981us/step - loss: 1.2204 - accuracy: 0.4270\n",
      "1250/1250 [==============================] - 1s 954us/step - loss: 1.2317 - accuracy: 0.4240\n",
      "1250/1250 [==============================] - 1s 956us/step - loss: 1.2217 - accuracy: 0.4299\n",
      "1250/1250 [==============================] - 1s 959us/step - loss: 1.2288 - accuracy: 0.4229\n",
      "1250/1250 [==============================] - 1s 962us/step - loss: 1.2231 - accuracy: 0.4248\n",
      "1250/1250 [==============================] - 1s 954us/step - loss: 1.2420 - accuracy: 0.4171\n",
      "1250/1250 [==============================] - 1s 934us/step - loss: 1.2197 - accuracy: 0.4242\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.2235 - accuracy: 0.4266\n",
      "1250/1250 [==============================] - 1s 930us/step - loss: 1.2256 - accuracy: 0.4259\n",
      "1250/1250 [==============================] - 1s 963us/step - loss: 1.2213 - accuracy: 0.4293\n",
      "1250/1250 [==============================] - 1s 978us/step - loss: 1.2366 - accuracy: 0.4130\n",
      "1250/1250 [==============================] - 1s 971us/step - loss: 1.2250 - accuracy: 0.4220\n",
      "1250/1250 [==============================] - 1s 976us/step - loss: 1.2196 - accuracy: 0.4256\n",
      "1250/1250 [==============================] - 1s 943us/step - loss: 1.2197 - accuracy: 0.4279\n",
      "1250/1250 [==============================] - 1s 974us/step - loss: 1.2249 - accuracy: 0.4240\n",
      "1250/1250 [==============================] - 1s 962us/step - loss: 1.2184 - accuracy: 0.4342\n",
      "1250/1250 [==============================] - 1s 985us/step - loss: 1.2183 - accuracy: 0.4274\n",
      "1250/1250 [==============================] - 1s 938us/step - loss: 1.2304 - accuracy: 0.4259\n",
      "1250/1250 [==============================] - 1s 964us/step - loss: 1.2196 - accuracy: 0.4250\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2244 - accuracy: 0.4245\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2291 - accuracy: 0.4209\n",
      "1250/1250 [==============================] - 1s 944us/step - loss: 1.2230 - accuracy: 0.4275\n",
      "1250/1250 [==============================] - 1s 946us/step - loss: 1.2237 - accuracy: 0.4236\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2273 - accuracy: 0.4224\n",
      "1250/1250 [==============================] - 1s 988us/step - loss: 1.2257 - accuracy: 0.4261\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2240 - accuracy: 0.4220\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2247 - accuracy: 0.4297\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2325 - accuracy: 0.4189\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2224 - accuracy: 0.4234\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2214 - accuracy: 0.4270\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2206 - accuracy: 0.4286\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2238 - accuracy: 0.4255\n",
      "1250/1250 [==============================] - 1s 988us/step - loss: 1.2257 - accuracy: 0.4230\n",
      "1250/1250 [==============================] - 1s 935us/step - loss: 1.2255 - accuracy: 0.4245\n",
      "1250/1250 [==============================] - 1s 970us/step - loss: 1.2247 - accuracy: 0.4304\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2194 - accuracy: 0.4232\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2314 - accuracy: 0.4203\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2210 - accuracy: 0.4270\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2244 - accuracy: 0.4206\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2215 - accuracy: 0.4275\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2286 - accuracy: 0.4233\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2234 - accuracy: 0.4257\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2213 - accuracy: 0.4214\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2234 - accuracy: 0.4240\n",
      "1250/1250 [==============================] - 1s 980us/step - loss: 1.2167 - accuracy: 0.4259\n",
      "1250/1250 [==============================] - 1s 911us/step - loss: 1.2215 - accuracy: 0.4244\n",
      "1250/1250 [==============================] - 1s 983us/step - loss: 1.2238 - accuracy: 0.4228\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2207 - accuracy: 0.4279\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2193 - accuracy: 0.4252\n",
      "1250/1250 [==============================] - 1s 999us/step - loss: 1.2231 - accuracy: 0.4282\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2285 - accuracy: 0.4197\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2254 - accuracy: 0.4233\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2338 - accuracy: 0.4222\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2287 - accuracy: 0.4237\n",
      "1250/1250 [==============================] - 1s 991us/step - loss: 1.2241 - accuracy: 0.4251\n",
      "1250/1250 [==============================] - 1s 961us/step - loss: 1.2284 - accuracy: 0.4191\n",
      "1250/1250 [==============================] - 1s 1000us/step - loss: 1.2322 - accuracy: 0.4189\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2323 - accuracy: 0.4188\n",
      "1250/1250 [==============================] - 1s 986us/step - loss: 1.2175 - accuracy: 0.4268\n",
      "1250/1250 [==============================] - 1s 977us/step - loss: 1.2269 - accuracy: 0.4234\n",
      "1250/1250 [==============================] - 1s 937us/step - loss: 1.2203 - accuracy: 0.4295\n",
      "1250/1250 [==============================] - 1s 972us/step - loss: 1.2216 - accuracy: 0.4257\n",
      "1250/1250 [==============================] - 1s 994us/step - loss: 1.2279 - accuracy: 0.4254\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2278 - accuracy: 0.4229\n",
      "1250/1250 [==============================] - 1s 982us/step - loss: 1.2169 - accuracy: 0.4260\n",
      "1250/1250 [==============================] - 1s 985us/step - loss: 1.2146 - accuracy: 0.4286\n",
      "1250/1250 [==============================] - 1s 980us/step - loss: 1.2277 - accuracy: 0.4238\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2173 - accuracy: 0.4299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2165 - accuracy: 0.4261\n",
      "1250/1250 [==============================] - 1s 928us/step - loss: 1.2230 - accuracy: 0.4234\n",
      "1250/1250 [==============================] - 1s 913us/step - loss: 1.2220 - accuracy: 0.4249\n",
      "1250/1250 [==============================] - 1s 942us/step - loss: 1.2269 - accuracy: 0.4243\n",
      "1250/1250 [==============================] - 1s 952us/step - loss: 1.2203 - accuracy: 0.4246\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2229 - accuracy: 0.4236\n",
      "1250/1250 [==============================] - 1s 985us/step - loss: 1.2277 - accuracy: 0.4226\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2282 - accuracy: 0.4245\n",
      "1250/1250 [==============================] - 1s 996us/step - loss: 1.2250 - accuracy: 0.4260\n",
      "1250/1250 [==============================] - 1s 996us/step - loss: 1.2308 - accuracy: 0.4245\n",
      "1250/1250 [==============================] - 1s 990us/step - loss: 1.2209 - accuracy: 0.4266\n",
      "1250/1250 [==============================] - 1s 997us/step - loss: 1.2277 - accuracy: 0.4223\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2371 - accuracy: 0.4202\n",
      "1250/1250 [==============================] - 1s 981us/step - loss: 1.2318 - accuracy: 0.4242\n",
      "1250/1250 [==============================] - 1s 968us/step - loss: 1.2237 - accuracy: 0.4248\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2219 - accuracy: 0.4231\n",
      "1250/1250 [==============================] - 1s 1ms/step - loss: 1.2205 - accuracy: 0.4257\n",
      "1250/1250 [==============================] - 1s 998us/step - loss: 1.2234 - accuracy: 0.4261\n",
      "1250/1250 [==============================] - 1s 984us/step - loss: 1.2241 - accuracy: 0.4224\n",
      "1250/1250 [==============================] - 1s 981us/step - loss: 1.2269 - accuracy: 0.4214\n",
      "1250/1250 [==============================] - 1s 979us/step - loss: 1.2223 - accuracy: 0.4261\n",
      "1250/1250 [==============================] - 1s 960us/step - loss: 1.2165 - accuracy: 0.4325\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.2225 - accuracy: 0.4265\n",
      "1250/1250 [==============================] - 1s 935us/step - loss: 1.2210 - accuracy: 0.4288\n",
      "1250/1250 [==============================] - 1s 892us/step - loss: 1.2209 - accuracy: 0.4264\n",
      "1250/1250 [==============================] - 1s 921us/step - loss: 1.2283 - accuracy: 0.4270\n",
      "1250/1250 [==============================] - 1s 897us/step - loss: 1.2236 - accuracy: 0.4248\n",
      "1250/1250 [==============================] - 1s 891us/step - loss: 1.2233 - accuracy: 0.4273\n",
      "1250/1250 [==============================] - 1s 875us/step - loss: 1.2197 - accuracy: 0.4264\n",
      "1250/1250 [==============================] - 1s 891us/step - loss: 1.2257 - accuracy: 0.4242\n",
      "1250/1250 [==============================] - 1s 888us/step - loss: 1.2219 - accuracy: 0.4253\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.2278 - accuracy: 0.4229\n",
      "1250/1250 [==============================] - 1s 929us/step - loss: 1.2215 - accuracy: 0.4246\n",
      "1250/1250 [==============================] - 1s 901us/step - loss: 1.2228 - accuracy: 0.4276\n",
      "1250/1250 [==============================] - 1s 903us/step - loss: 1.2264 - accuracy: 0.4237\n",
      "1250/1250 [==============================] - 1s 900us/step - loss: 1.2237 - accuracy: 0.4262\n",
      "1250/1250 [==============================] - 1s 902us/step - loss: 1.2201 - accuracy: 0.4244\n",
      "1250/1250 [==============================] - 1s 901us/step - loss: 1.2272 - accuracy: 0.4236\n",
      "1250/1250 [==============================] - 1s 910us/step - loss: 1.2353 - accuracy: 0.4184\n",
      "1250/1250 [==============================] - 1s 930us/step - loss: 1.2376 - accuracy: 0.4198\n",
      "1250/1250 [==============================] - 1s 918us/step - loss: 1.2197 - accuracy: 0.4252\n",
      "1250/1250 [==============================] - 1s 905us/step - loss: 1.2254 - accuracy: 0.4249\n",
      "1250/1250 [==============================] - 1s 896us/step - loss: 1.2332 - accuracy: 0.4216\n",
      "1250/1250 [==============================] - 1s 886us/step - loss: 1.2238 - accuracy: 0.4248\n",
      "1250/1250 [==============================] - 1s 896us/step - loss: 1.2273 - accuracy: 0.4235\n",
      "1250/1250 [==============================] - 1s 900us/step - loss: 1.2239 - accuracy: 0.4297\n",
      "1250/1250 [==============================] - 1s 914us/step - loss: 1.2223 - accuracy: 0.4225\n",
      "1250/1250 [==============================] - 1s 910us/step - loss: 1.2146 - accuracy: 0.4318\n",
      "1250/1250 [==============================] - 1s 907us/step - loss: 1.2361 - accuracy: 0.4193\n",
      "1250/1250 [==============================] - 1s 921us/step - loss: 1.2298 - accuracy: 0.4186\n",
      "1250/1250 [==============================] - 1s 906us/step - loss: 1.2259 - accuracy: 0.4242\n",
      "1250/1250 [==============================] - 1s 899us/step - loss: 1.2282 - accuracy: 0.4246\n",
      "1250/1250 [==============================] - 1s 888us/step - loss: 1.2172 - accuracy: 0.4290\n",
      "1250/1250 [==============================] - 1s 898us/step - loss: 1.2190 - accuracy: 0.4256\n",
      "1250/1250 [==============================] - 1s 886us/step - loss: 1.2379 - accuracy: 0.4217\n",
      "1250/1250 [==============================] - 1s 889us/step - loss: 1.2206 - accuracy: 0.4273\n",
      "1250/1250 [==============================] - 1s 888us/step - loss: 1.2253 - accuracy: 0.4226\n",
      "1250/1250 [==============================] - 1s 903us/step - loss: 1.2361 - accuracy: 0.4209\n",
      "1250/1250 [==============================] - 1s 933us/step - loss: 1.2283 - accuracy: 0.4220\n",
      "1250/1250 [==============================] - 1s 915us/step - loss: 1.2244 - accuracy: 0.4252\n",
      "1250/1250 [==============================] - 1s 897us/step - loss: 1.2235 - accuracy: 0.4235\n",
      "1250/1250 [==============================] - 1s 893us/step - loss: 1.2195 - accuracy: 0.4262\n",
      "1250/1250 [==============================] - 1s 906us/step - loss: 1.2204 - accuracy: 0.4259\n",
      "1250/1250 [==============================] - 1s 899us/step - loss: 1.2221 - accuracy: 0.4241\n",
      "1250/1250 [==============================] - 1s 903us/step - loss: 1.2219 - accuracy: 0.4245\n",
      "1250/1250 [==============================] - 1s 897us/step - loss: 1.2291 - accuracy: 0.4234\n",
      "1250/1250 [==============================] - 1s 896us/step - loss: 1.2357 - accuracy: 0.4224\n",
      "1250/1250 [==============================] - 1s 904us/step - loss: 1.2216 - accuracy: 0.4302\n",
      "1250/1250 [==============================] - 1s 908us/step - loss: 1.2382 - accuracy: 0.4160\n",
      "1250/1250 [==============================] - 1s 904us/step - loss: 1.2272 - accuracy: 0.4219\n",
      "1250/1250 [==============================] - 1s 903us/step - loss: 1.2234 - accuracy: 0.4236\n",
      "1250/1250 [==============================] - 1s 902us/step - loss: 1.2310 - accuracy: 0.4256\n",
      "1250/1250 [==============================] - 1s 904us/step - loss: 1.2192 - accuracy: 0.4257\n",
      "1250/1250 [==============================] - 1s 902us/step - loss: 1.2199 - accuracy: 0.4273\n",
      "1250/1250 [==============================] - 1s 895us/step - loss: 1.2228 - accuracy: 0.4254\n",
      "1250/1250 [==============================] - 1s 908us/step - loss: 1.2277 - accuracy: 0.4219\n",
      "1250/1250 [==============================] - 1s 895us/step - loss: 1.2310 - accuracy: 0.4208\n",
      "1250/1250 [==============================] - 1s 899us/step - loss: 1.2168 - accuracy: 0.4260\n",
      "1250/1250 [==============================] - 1s 902us/step - loss: 1.2256 - accuracy: 0.4223\n",
      "1250/1250 [==============================] - 1s 910us/step - loss: 1.2202 - accuracy: 0.4248\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.2281 - accuracy: 0.4203\n",
      "1250/1250 [==============================] - 1s 906us/step - loss: 1.2359 - accuracy: 0.4168\n",
      "1250/1250 [==============================] - 1s 898us/step - loss: 1.2221 - accuracy: 0.4218\n",
      "1250/1250 [==============================] - 1s 906us/step - loss: 1.2248 - accuracy: 0.4261\n",
      "1250/1250 [==============================] - 1s 879us/step - loss: 1.2282 - accuracy: 0.4187\n",
      "1250/1250 [==============================] - 1s 904us/step - loss: 1.2286 - accuracy: 0.4234\n",
      "1250/1250 [==============================] - 1s 909us/step - loss: 1.2194 - accuracy: 0.4257\n",
      "1250/1250 [==============================] - 1s 916us/step - loss: 1.2234 - accuracy: 0.4274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 1s 913us/step - loss: 1.2223 - accuracy: 0.4271\n",
      "1250/1250 [==============================] - 1s 914us/step - loss: 1.2191 - accuracy: 0.4291\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.2276 - accuracy: 0.4237\n",
      "1250/1250 [==============================] - 1s 911us/step - loss: 1.2241 - accuracy: 0.4272\n",
      "1250/1250 [==============================] - 1s 905us/step - loss: 1.2247 - accuracy: 0.4243\n",
      "1250/1250 [==============================] - 1s 902us/step - loss: 1.2194 - accuracy: 0.4275\n",
      "1250/1250 [==============================] - 1s 890us/step - loss: 1.2204 - accuracy: 0.4256\n",
      "1250/1250 [==============================] - 1s 902us/step - loss: 1.2221 - accuracy: 0.4273\n",
      "1250/1250 [==============================] - 1s 890us/step - loss: 1.2303 - accuracy: 0.4216\n",
      "1250/1250 [==============================] - 1s 900us/step - loss: 1.2281 - accuracy: 0.4228\n",
      "1250/1250 [==============================] - 1s 894us/step - loss: 1.2392 - accuracy: 0.4175\n",
      "1250/1250 [==============================] - 1s 894us/step - loss: 1.2299 - accuracy: 0.4228\n",
      "1250/1250 [==============================] - 1s 896us/step - loss: 1.2189 - accuracy: 0.4285\n",
      "1250/1250 [==============================] - 1s 898us/step - loss: 1.2321 - accuracy: 0.4242\n",
      "1250/1250 [==============================] - 1s 900us/step - loss: 1.2194 - accuracy: 0.4250\n",
      "1250/1250 [==============================] - 1s 914us/step - loss: 1.2254 - accuracy: 0.4229\n",
      "1250/1250 [==============================] - 1s 916us/step - loss: 1.2219 - accuracy: 0.4245\n",
      "1250/1250 [==============================] - 1s 914us/step - loss: 1.2209 - accuracy: 0.4230\n",
      "1250/1250 [==============================] - 1s 904us/step - loss: 1.2263 - accuracy: 0.4243\n",
      "1250/1250 [==============================] - 1s 902us/step - loss: 1.2210 - accuracy: 0.4262\n",
      "1250/1250 [==============================] - 1s 905us/step - loss: 1.2186 - accuracy: 0.4253\n",
      "1250/1250 [==============================] - 1s 901us/step - loss: 1.2202 - accuracy: 0.4229\n",
      "1250/1250 [==============================] - 1s 898us/step - loss: 1.2235 - accuracy: 0.4268\n",
      "1250/1250 [==============================] - 1s 870us/step - loss: 1.2193 - accuracy: 0.4264\n",
      "1250/1250 [==============================] - 1s 898us/step - loss: 1.2196 - accuracy: 0.4281\n",
      "1250/1250 [==============================] - 1s 910us/step - loss: 1.2244 - accuracy: 0.4264\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.2226 - accuracy: 0.4236\n",
      "1250/1250 [==============================] - 1s 912us/step - loss: 1.2185 - accuracy: 0.4308\n",
      "1250/1250 [==============================] - 1s 917us/step - loss: 1.2258 - accuracy: 0.4265\n",
      "1250/1250 [==============================] - 1s 911us/step - loss: 1.2304 - accuracy: 0.4232\n",
      "1250/1250 [==============================] - 1s 902us/step - loss: 1.2244 - accuracy: 0.4247\n",
      "1250/1250 [==============================] - 1s 907us/step - loss: 1.2222 - accuracy: 0.4222\n",
      "1250/1250 [==============================] - 1s 917us/step - loss: 1.2175 - accuracy: 0.4301\n",
      "1250/1250 [==============================] - 1s 906us/step - loss: 1.2199 - accuracy: 0.4238\n",
      "1250/1250 [==============================] - 1s 940us/step - loss: 1.2230 - accuracy: 0.4249\n",
      "1250/1250 [==============================] - 1s 902us/step - loss: 1.2203 - accuracy: 0.4230\n",
      "1250/1250 [==============================] - 1s 902us/step - loss: 1.2231 - accuracy: 0.4235\n"
     ]
    }
   ],
   "source": [
    "accuracy, accuracy_weight = learn_reg_L1(5, 128, 512, weight2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max weight idx : 104\n",
      "max weight : 0.000204\n",
      "max accuracy : 0.428670\n"
     ]
    }
   ],
   "source": [
    "maxidx1 = accuracy.index(max(accuracy))\n",
    "print(\"max weight idx : %d\" % maxidx1)\n",
    "print(\"max weight : %f\" % accuracy_weight[maxidx1])\n",
    "print(\"max accuracy : %f\" % accuracy[maxidx1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28416bd4c18>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i for i in range(step_num*2+1)], accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0001, 0.000101, 0.000102, 0.000103, 0.000104, 0.00010499999999999999, 0.00010599999999999999, 0.00010699999999999999, 0.00010799999999999998, 0.00010899999999999998, 0.00010999999999999998, 0.00011099999999999997, 0.00011199999999999997, 0.00011299999999999997, 0.00011399999999999997, 0.00011499999999999996, 0.00011599999999999996, 0.00011699999999999996, 0.00011799999999999995, 0.00011899999999999995, 0.00011999999999999995, 0.00012099999999999995, 0.00012199999999999994, 0.00012299999999999995, 0.00012399999999999992, 0.00012499999999999995, 0.00012599999999999992, 0.00012699999999999994, 0.0001279999999999999, 0.00012899999999999994, 0.0001299999999999999, 0.00013099999999999993, 0.0001319999999999999, 0.00013299999999999993, 0.0001339999999999999, 0.00013499999999999992, 0.0001359999999999999, 0.00013699999999999991, 0.00013799999999999988, 0.0001389999999999999, 0.00013999999999999988, 0.0001409999999999999, 0.00014199999999999987, 0.0001429999999999999, 0.00014399999999999987, 0.0001449999999999999, 0.00014599999999999986, 0.0001469999999999999, 0.00014799999999999986, 0.00014899999999999988, 0.00014999999999999985, 0.00015099999999999988, 0.00015199999999999985, 0.00015299999999999987, 0.00015399999999999984, 0.00015499999999999986, 0.00015599999999999983, 0.00015699999999999986, 0.00015799999999999983, 0.00015899999999999985, 0.00015999999999999982, 0.00016099999999999985, 0.00016199999999999982, 0.00016299999999999984, 0.0001639999999999998, 0.00016499999999999984, 0.0001659999999999998, 0.00016699999999999983, 0.0001679999999999998, 0.00016899999999999983, 0.0001699999999999998, 0.00017099999999999982, 0.0001719999999999998, 0.00017299999999999981, 0.00017399999999999978, 0.0001749999999999998, 0.00017599999999999978, 0.0001769999999999998, 0.00017799999999999977, 0.0001789999999999998, 0.00017999999999999977, 0.0001809999999999998, 0.00018199999999999976, 0.00018299999999999979, 0.00018399999999999976, 0.00018499999999999978, 0.00018599999999999975, 0.00018699999999999977, 0.00018799999999999975, 0.00018899999999999977, 0.00018999999999999974, 0.00019099999999999976, 0.00019199999999999973, 0.00019299999999999976, 0.00019399999999999973, 0.00019499999999999975, 0.00019599999999999972, 0.00019699999999999975, 0.00019799999999999972, 0.00019899999999999974, 0.0001999999999999997, 0.00020099999999999974, 0.0002019999999999997, 0.00020299999999999973, 0.0002039999999999997, 0.00020499999999999972, 0.0002059999999999997, 0.00020699999999999972, 0.0002079999999999997, 0.0002089999999999997, 0.00020999999999999968, 0.0002109999999999997, 0.00021199999999999968, 0.0002129999999999997, 0.00021399999999999967, 0.0002149999999999997, 0.00021599999999999967, 0.0002169999999999997, 0.00021799999999999966, 0.00021899999999999969, 0.00021999999999999966, 0.00022099999999999968, 0.00022199999999999965, 0.00022299999999999967, 0.00022399999999999964, 0.00022499999999999967, 0.00022599999999999964, 0.00022699999999999966, 0.00022799999999999963, 0.00022899999999999966, 0.00022999999999999963, 0.00023099999999999965, 0.00023199999999999962, 0.00023299999999999965, 0.00023399999999999962, 0.00023499999999999964, 0.0002359999999999996, 0.00023699999999999964, 0.0002379999999999996, 0.00023899999999999963, 0.0002399999999999996, 0.00024099999999999962, 0.0002419999999999996, 0.00024299999999999962, 0.0002439999999999996, 0.0002449999999999996, 0.0002459999999999996, 0.0002469999999999996, 0.0002479999999999996, 0.0002489999999999996, 0.00024999999999999957, 0.0002509999999999996, 0.00025199999999999957, 0.0002529999999999996, 0.00025399999999999956, 0.0002549999999999996, 0.00025599999999999955, 0.0002569999999999996, 0.00025799999999999955, 0.0002589999999999996, 0.00025999999999999954, 0.00026099999999999957, 0.00026199999999999954, 0.00026299999999999956, 0.00026399999999999953, 0.00026499999999999956, 0.0002659999999999995, 0.00026699999999999955, 0.0002679999999999995, 0.00026899999999999955, 0.0002699999999999995, 0.00027099999999999954, 0.0002719999999999995, 0.00027299999999999953, 0.0002739999999999995, 0.00027499999999999953, 0.0002759999999999995, 0.0002769999999999995, 0.0002779999999999995, 0.0002789999999999995, 0.0002799999999999995, 0.0002809999999999995, 0.0002819999999999995, 0.0002829999999999995, 0.0002839999999999995, 0.0002849999999999995, 0.00028599999999999947, 0.0002869999999999995, 0.00028799999999999947, 0.0002889999999999995, 0.00028999999999999946, 0.0002909999999999995, 0.00029199999999999945, 0.0002929999999999995, 0.00029399999999999945, 0.00029499999999999947, 0.00029599999999999944, 0.00029699999999999947, 0.00029799999999999944, 0.00029899999999999946, 0.00029999999999999943]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
