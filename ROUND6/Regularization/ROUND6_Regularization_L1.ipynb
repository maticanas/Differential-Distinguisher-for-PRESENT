{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NXVzTjGSQpAx",
    "outputId": "31cbc208-81e9-4251-95e5-a53c46575581"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 80-bit Key Vectors:\n",
      "Success 0x5579c1387b228445\n",
      "Success 0xe72c46c0f5945049\n",
      "Success 0xa112ffc72f68417b\n",
      "Success 0x3333dcd3213210d2\n",
      "0x5579c1387b228445\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "https://github.com/inmcm/present_cipher/tree/master/python\n",
    "\"\"\"\n",
    "# coding: utf-8\n",
    "from __future__ import print_function\n",
    "\n",
    "s_box = (0xC, 0x5, 0x6, 0xB, 0x9, 0x0, 0xA, 0xD, 0x3, 0xE, 0xF, 0x8, 0x4, 0x7, 0x1, 0x2)\n",
    "\n",
    "inv_s_box = (0x5, 0xE, 0xF, 0x8, 0xC, 0x1, 0x2, 0xD, 0xB, 0x4, 0x6, 0x3, 0x0, 0x7, 0x9, 0xA)\n",
    "\n",
    "p_layer_order = [0, 16, 32, 48, 1, 17, 33, 49, 2, 18, 34, 50, 3, 19, 35, 51, 4, 20, 36, 52, 5, 21, 37, 53, 6, 22, 38,\n",
    "                 54, 7, 23, 39, 55, 8, 24, 40, 56, 9, 25, 41, 57, 10, 26, 42, 58, 11, 27, 43, 59, 12, 28, 44, 60, 13,\n",
    "                 29, 45, 61, 14, 30, 46, 62, 15, 31, 47, 63]\n",
    "\n",
    "block_size = 64\n",
    "\n",
    "ROUND_LIMIT = 32\n",
    "\n",
    "\n",
    "def round_function(state, key):\n",
    "    new_state = state ^ key\n",
    "    state_nibs = []\n",
    "    for x in range(0, block_size, 4):\n",
    "        nib = (new_state >> x) & 0xF\n",
    "        sb_nib = s_box[nib]\n",
    "        state_nibs.append(sb_nib)\n",
    "    # print(state_nibs)\n",
    "\n",
    "    state_bits = []\n",
    "    for y in state_nibs:\n",
    "        nib_bits = [1 if t == '1'else 0 for t in format(y, '04b')[::-1]]\n",
    "        state_bits += nib_bits\n",
    "    # print(state_bits)\n",
    "    # print(len(state_bits))\n",
    "\n",
    "    state_p_layer = [0 for _ in range(64)]\n",
    "    for p_index, std_bits in enumerate(state_bits):\n",
    "        state_p_layer[p_layer_order[p_index]] = std_bits\n",
    "\n",
    "    # print(len(state_p_layer), state_p_layer)\n",
    "\n",
    "    round_output = 0\n",
    "    for index, ind_bit in enumerate(state_p_layer):\n",
    "        round_output += (ind_bit << index)\n",
    "\n",
    "    # print(format(round_output, '#016X'))\n",
    "\n",
    "    # print('')\n",
    "    return round_output\n",
    "\n",
    "\n",
    "def key_function_80(key, round_count):\n",
    "    # print('Start: ', hex(key))\n",
    "    # print('')\n",
    "\n",
    "    r = [1 if t == '1'else 0 for t in format(key, '080b')[::-1]]\n",
    "\n",
    "    # print('k bits:', r)\n",
    "    # print('')\n",
    "\n",
    "    h = r[-61:] + r[:-61]\n",
    "\n",
    "    # print('s bits:', h)\n",
    "    # print('')\n",
    "\n",
    "    round_key_int = 0\n",
    "    # print('init round int:', hex(round_key_int))\n",
    "    for index, ind_bit in enumerate(h):\n",
    "        round_key_int += (ind_bit << index)\n",
    "        # print('round:',index, '-', hex(round_key_int))\n",
    "\n",
    "    # print('round_key_int', hex(round_key_int))\n",
    "    # print('')\n",
    "\n",
    "    upper_nibble = round_key_int >> 76\n",
    "\n",
    "    # print('upper_nibble:', upper_nibble)\n",
    "\n",
    "    upper_nibble = s_box[upper_nibble]\n",
    "\n",
    "    # print('upper_nibble sboxed', hex(upper_nibble))\n",
    "\n",
    "    xor_portion = ((round_key_int >> 15) & 0x1F) ^ round_count\n",
    "    # print('Count:', round_count)\n",
    "    # print('XOR Value:', xor_portion)\n",
    "\n",
    "    # print('Before:', hex(round_key_int))\n",
    "    round_key_int = (round_key_int & 0x0FFFFFFFFFFFFFF07FFF) + (upper_nibble << 76) + (xor_portion << 15)\n",
    "    # print('After: ', hex(round_key_int))\n",
    "\n",
    "    return round_key_int\n",
    "\n",
    "\n",
    "\n",
    "test_vectors_80 = {1:(0x00000000000000000000, 0x0000000000000000, 0x5579C1387B228445),\n",
    "                2:(0xFFFFFFFFFFFFFFFFFFFF, 0x0000000000000000, 0xE72C46C0F5945049),\n",
    "                3:(0x00000000000000000000, 0xFFFFFFFFFFFFFFFF, 0xA112FFC72F68417B),\n",
    "                4:(0xFFFFFFFFFFFFFFFFFFFF, 0xFFFFFFFFFFFFFFFF, 0x3333DCD3213210D2)}\n",
    "\n",
    "print('Testing 80-bit Key Vectors:')\n",
    "\n",
    "\n",
    "\n",
    "for test_case in test_vectors_80:\n",
    "\n",
    "    key_schedule = []\n",
    "    current_round_key = test_vectors_80[test_case][0]\n",
    "    round_state = test_vectors_80[test_case][1]\n",
    "\n",
    "    # Key schedule\n",
    "    for rnd_cnt in range(ROUND_LIMIT):\n",
    "        # print(format(round_key, '020X'))\n",
    "        # print(format(round_key >> 16, '016X'))\n",
    "        key_schedule.append(current_round_key >> 16)\n",
    "        current_round_key = key_function_80(current_round_key, rnd_cnt + 1)\n",
    "\n",
    "    for rnd in range(ROUND_LIMIT - 1):\n",
    "        # print('Round:', rnd)\n",
    "        # print('State:', format(round_state, '016X'))\n",
    "        # print('R_Key:', format(key_schedule[rnd], '016X'))\n",
    "        round_state = round_function(round_state, key_schedule[rnd])\n",
    "\n",
    "    round_state ^= key_schedule[ROUND_LIMIT-1]\n",
    "\n",
    "    if round_state == test_vectors_80[test_case][2]:\n",
    "        print('Success', hex(round_state))\n",
    "    else:\n",
    "        print('Failure', hex(round_state))\n",
    "        \n",
    "def PRESENT(P, K, ROUND):\n",
    "    key_schedule = []\n",
    "    current_round_key = K\n",
    "    round_state = P\n",
    "    \n",
    "    if(ROUND==0):\n",
    "        return P\n",
    "\n",
    "    for rnd_cnt in range(ROUND):\n",
    "        key_schedule.append(current_round_key >> 16)\n",
    "        current_round_key = key_function_80(current_round_key, rnd_cnt + 1)\n",
    "\n",
    "    for rnd in range(ROUND - 1):\n",
    "        round_state = round_function(round_state, key_schedule[rnd])\n",
    "\n",
    "    round_state ^= key_schedule[ROUND-1]\n",
    "    \n",
    "    return round_state\n",
    "\n",
    "C = PRESENT(0x0, 0x0, ROUND=32)\n",
    "print(hex(C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AwZVgDHVQpAz"
   },
   "outputs": [],
   "source": [
    "Wang_diff = [0x7000000000007000, 0x0700000000000700, 0x0070000000000070, 0x0007000000000007]\n",
    "BLOCK_SIZE = 64\n",
    "\n",
    "ROUND_global = 6\n",
    "sample_num = 10000\n",
    "test_sample_num = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xJrNRizYQpA0"
   },
   "outputs": [],
   "source": [
    "def gen(sample_num, ROUND):\n",
    "    P_set = []\n",
    "    K_set = []\n",
    "    for i in range(sample_num):\n",
    "        P_set.append(random.randrange(0,2**64))\n",
    "        #print(\"%x\" % P_set[i])\n",
    "        K_set.append(random.randrange(0,2**80))\n",
    "        #print(\"%x\" % K_set[i])\n",
    "\n",
    "    C_diff_set = []\n",
    "    C_diff_label = []\n",
    "    for i in range(sample_num):\n",
    "        P = P_set[i]\n",
    "        K = K_set[i]\n",
    "        C = PRESENT(P, K, ROUND)\n",
    "        for j in range(4):\n",
    "            Cj = PRESENT(P^Wang_diff[j], K, ROUND)\n",
    "            C_diff = C^Cj\n",
    "            #print(C_diff)\n",
    "            C_diff_set.append(C_diff)\n",
    "            temp = [0, 0, 0, 0]\n",
    "            temp[j] = 1\n",
    "            C_diff_label.append(temp)\n",
    "\n",
    "    tr_X = []\n",
    "    for C_diff in C_diff_set:\n",
    "        A = []\n",
    "        for j in range(BLOCK_SIZE):\n",
    "            A.append((C_diff>>j)&1)\n",
    "        tr_X.append(A)\n",
    "        #print(A)\n",
    "    tr_X = np.array(tr_X)\n",
    "\n",
    "    tr_X = []\n",
    "    for C_diff in C_diff_set:\n",
    "        A = []\n",
    "        for j in range(BLOCK_SIZE):\n",
    "            A.append((C_diff>>j)&1)\n",
    "        tr_X.append(A)\n",
    "        #print(A)\n",
    "    tr_X = np.array(tr_X)\n",
    "    tr_t = np.array(C_diff_label)\n",
    "\n",
    "    ind = np.arange(len(tr_X))\n",
    "    np.random.shuffle(ind)\n",
    "    tr_X = tr_X[ind]\n",
    "    tr_t = tr_t[ind]\n",
    "    \n",
    "    return tr_X, tr_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_gen():\n",
    "    SAMPLE_NUM_RANGE = [10000, 50000, 100000]\n",
    "    ROUND_RANGE = [3, 4, 5, 6, 7, 8]\n",
    "    for sn in SAMPLE_NUM_RANGE:\n",
    "        for rn in ROUND_RANGE:\n",
    "            tr_X, tr_t = gen(sn, rn)\n",
    "            np.save(\"ROUND %d SAMPLE %d Dataset\" % (rn, sn), tr_X)\n",
    "            np.save(\"ROUND %d SAMPLE %d Label\" % (rn, sn), tr_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Wk0Lr4ReQpA1"
   },
   "outputs": [],
   "source": [
    "def test_sample_gen():\n",
    "    TEST_SMAPLE_NUM = 10000\n",
    "    for rn in ROUND_RANGE:\n",
    "        te_X, te_t = gen(TEST_SMAPLE_NUM, rn)\n",
    "        np.save(\"ROUND %d TEST_SAMPLE Dataset\" % (rn), te_X)\n",
    "        np.save(\"ROUND %d TEST_SAMPLE Label\" % (rn), te_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "O9XPTV7FQpA1"
   },
   "outputs": [],
   "source": [
    "def load_sample(SAMPLE_NUM, ROUND_NUM):\n",
    "    tr_X = np.load(\"ROUND %d SAMPLE %d Dataset.npy\" % (ROUND_NUM, SAMPLE_NUM))\n",
    "    tr_t = np.load(\"ROUND %d SAMPLE %d Label.npy\" % (ROUND_NUM, SAMPLE_NUM))\n",
    "    return tr_X, tr_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_sample(ROUND_NUM):\n",
    "    te_X = np.load(\"ROUND %d TEST_SAMPLE Dataset.npy\" % (ROUND_NUM))\n",
    "    te_t = np.load(\"ROUND %d TEST_SAMPLE Label.npy\" % (ROUND_NUM))\n",
    "    return te_X, te_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RfujwI1AQpA1"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, layer1=128, layer2=1024, layer3=None, reg=None, learning_rate=0.001):\n",
    "        self.layers = self._build_layers(layer1, layer2, layer3, reg)\n",
    "        self.model = tf.keras.Sequential(self.layers) \n",
    "        self.model.compile(optimizer=tf.keras.optimizers.Adam(lr=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    def _build_layers(self, layer1, layer2, layer3, reg):\n",
    "        if layer3==None:\n",
    "            layers = [\n",
    "                tf.keras.layers.Flatten(input_shape=(64,)),\n",
    "                tf.keras.layers.Dense(layer1, activation='relu', kernel_regularizer=reg),\n",
    "                tf.keras.layers.Dense(layer2, activation='relu', kernel_regularizer=reg),\n",
    "                #tf.keras.layers.Dense(layer3, activation='relu', kernel_regularizer=reg),\n",
    "                tf.keras.layers.Dense(4, activation='softmax')\n",
    "            ]\n",
    "        else:\n",
    "            layers = [\n",
    "                tf.keras.layers.Flatten(input_shape=(64,)),\n",
    "                tf.keras.layers.Dense(layer1, activation='relu', kernel_regularizer=reg),\n",
    "                tf.keras.layers.Dense(layer2, activation='relu', kernel_regularizer=reg),\n",
    "                tf.keras.layers.Dense(layer3, activation='relu', kernel_regularizer=reg),\n",
    "                tf.keras.layers.Dense(4, activation='softmax')\n",
    "            ]\n",
    "        return layers\n",
    "\n",
    "    #그냥 cross entropy를 그대로 정의함\n",
    "    def _my_loss(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.int32) #float32 => int32로 casting #None, 1\n",
    "        y_true = tf.squeeze(tf.one_hot(y_true, depth=10, dtype=tf.float32), 1) # one_hot encoding #None, 1, 10 #quezze => 1을 없애줌 => None, 10\n",
    "        y_pred = tf.nn.softmax(y_pred, 1) # 한 축에 대해 softmax를 적용해라 #1 => 열을 의미 #즉, 한 행에 있는 값을 다 더하면 1이 되도록 만들어줌\n",
    "\n",
    "        #cross entropy 그대로 적용\n",
    "        #-sum t*log y 한 후에 평균 냄\n",
    "        return -tf.reduce_mean(tf.reduce_sum(\n",
    "                tf.multiply(y_true, tf.math.log(y_pred)), 1))\n",
    "\n",
    "    def _my_accuracy(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.int32)\n",
    "        y_true = tf.squeeze(tf.one_hot(y_true, depth=10, dtype=tf.float32), 1)\n",
    "        #argmax를 그대로 이용\n",
    "        return tf.reduce_mean(\n",
    "            tf.cast(\n",
    "                tf.equal(tf.argmax(y_true, 1), tf.argmax(y_pred, 1)), tf.float32))\n",
    "\n",
    "    def fit(self, x, t, epochs, batch_size=None, validation_split=0.0, verbose=1, shuffle=False, workers=2):\n",
    "        self.model.fit(x, t, epochs=epochs, batch_size=batch_size, validation_split=validation_split, verbose=verbose, shuffle=shuffle, workers=workers)\n",
    "    \n",
    "    def evaluate(self, x=None, y=None, verbose=1):\n",
    "        return self.model.evaluate(x=x, y=y, verbose=verbose)\n",
    "    \n",
    "    def summary(self):\n",
    "        self.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mhQTZ7KwQpA2",
    "outputId": "85b3d255-445f-463d-ba53-122475dfd771"
   },
   "outputs": [],
   "source": [
    "#Config\n",
    "ROUND = 6\n",
    "SAMPLE_NUM = 10000\n",
    "test_sample_num = 10000\n",
    "ITERATION = 5\n",
    "\n",
    "#Fix\n",
    "batch_size = 200\n",
    "epoch_size = 25\n",
    "validation_split = 0.3\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "w53eKengQpA2"
   },
   "outputs": [],
   "source": [
    "def learn(ROUND, SAMPLE_NUM, layer1, layer2, layer3=None, reg=None, learning_rate=0.001):\n",
    "    tr_X, tr_t = load_sample(SAMPLE_NUM=SAMPLE_NUM, ROUND_NUM=ROUND)\n",
    "    te_X, te_t = load_test_sample(ROUND_NUM=ROUND)\n",
    "    accuracy = []\n",
    "    for i in range(ITERATION):\n",
    "        model = MLP(layer1, layer2, layer3, reg, learning_rate)\n",
    "        model.fit(tr_X, tr_t, epochs=epoch_size, batch_size=batch_size, validation_split = validation_split, shuffle=True, verbose=0)\n",
    "        accuracy.append(model.evaluate(te_X, te_t, verbose=0)[1])\n",
    "    avg = np.mean(np.array(accuracy))\n",
    "    #print(\"average : %f\" % avg)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_reg_L1(ROUND=ROUND, l1=256, l2=2048, weight=[0.0001]):\n",
    "    tr_X, tr_t = gen(sample_num, ROUND)\n",
    "    te_X, te_t = gen(test_sample_num, ROUND)\n",
    "\n",
    "    result = []\n",
    "    result_weight = []\n",
    "    for w in weight:\n",
    "        accuracy = []\n",
    "        for i in range(ITERATION):\n",
    "            model = MLP(layer1=l1, layer2=l2, reg=tf.keras.regularizers.L1(w))\n",
    "            model.fit(tr_X, tr_t, epochs=epoch_size, batch_size=batch_size, validation_split = validation_split, verbose=0)\n",
    "            accuracy.append(model.evaluate(te_X, te_t)[1])\n",
    "        avg_acc = np.mean(np.array(accuracy))\n",
    "        result.append(avg_acc)\n",
    "        result_weight.append(w)\n",
    "    return result, result_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.3958 - accuracy: 0.2553\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.3963 - accuracy: 0.2575\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4000 - accuracy: 0.2584\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.3982 - accuracy: 0.2571\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.3978 - accuracy: 0.2565\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4514 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4517 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4516 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4516 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.4516 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.0399 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.0387 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.0395 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.0379 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 2.0406 - accuracy: 0.25 - 6s 5ms/step - loss: 2.0406 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 8.0116 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 8.0034 - accuracy: 0.2500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-530e0aef8a21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mweight0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearn_reg_L1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweight0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmaxidx0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-b795901cfb1c>\u001b[0m in \u001b[0;36mlearn_reg_L1\u001b[1;34m(ROUND, l1, l2, weight)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mITERATION\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mte_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mte_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mavg_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-2d2c0ce4851f>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, t, epochs, batch_size, validation_split, verbose, shuffle, workers)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "weight0 = [0.0001, 0.001, 0.01, 0.1]\n",
    "accuracy, accuracy_weight = learn_reg_L1(weight=weight0)\n",
    "maxidx0 = accuracy.index(max(accuracy))\n",
    "print(accuracy)\n",
    "print(accuracy_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009]\n"
     ]
    }
   ],
   "source": [
    "RANGE1 = 10\n",
    "weight2 = []\n",
    "for i in range(RANGE1):\n",
    "    weight2.append(i/10000.0)\n",
    "print(weight2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "MVTYS1K6uVn2",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.9795 - accuracy: 0.2559\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 3.1358 - accuracy: 0.2547\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 2.8868 - accuracy: 0.2546\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 3.2593 - accuracy: 0.2564\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.9703 - accuracy: 0.2607\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.4001 - accuracy: 0.2618\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.3993 - accuracy: 0.2607\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.3983 - accuracy: 0.2580\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.3990 - accuracy: 0.2575\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.4033 - accuracy: 0.2584\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.3989 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.3990 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.3997 - accuracy: 0.2583\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.3996 - accuracy: 0.2579\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.3990 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4054 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.4055 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.4055 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.4055 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 1.4054 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.4121 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.4119 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.4121 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.4120 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.4121 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.4188 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.4186 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.4184 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.4187 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.4187 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.4252 - accuracy: 0.2500: 0s - loss: 1.4252 - ac\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.4250 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.4250 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.4252 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.4250 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.4318 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.4316 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 1.4317 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.4318 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.4316 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.4381 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.4381 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.4382 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 1.4380 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.4381 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.4448 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.4447 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 1.4447 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.4447 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 1.4447 - accuracy: 0.2500\n"
     ]
    }
   ],
   "source": [
    "accuracy, accuracy_weight = learn_reg_L1(weight=weight2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max weight idx : 1\n",
      "max weight : 0.000100\n",
      "max accuracy : 0.259260\n"
     ]
    }
   ],
   "source": [
    "maxidx1 = accuracy.index(max(accuracy))\n",
    "print(\"max weight idx : %d\" % maxidx1)\n",
    "print(\"max weight : %f\" % accuracy_weight[maxidx1])\n",
    "print(\"max accuracy : %f\" % accuracy[maxidx1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2675227b048>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i for i in range(RANGE1)], accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit = 1/10000.0\n",
    "start = (maxidx1-1)*unit\n",
    "end = (maxidx1+1)*unit\n",
    "step_num = 10\n",
    "step = unit/step_num\n",
    "weight2 = np.arange(start, end, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.9148 - accuracy: 0.2552\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 3.1907 - accuracy: 0.2567\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.9227 - accuracy: 0.2566\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 3.0527 - accuracy: 0.2567\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.9822 - accuracy: 0.2548\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.6240 - accuracy: 0.2546\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 2.7879 - accuracy: 0.2530\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 2.5117 - accuracy: 0.2522\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 2.5879 - accuracy: 0.2582\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.6811 - accuracy: 0.2545\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 1.9387 - accuracy: 0.2580\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.9724 - accuracy: 0.2552\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 1.9615 - accuracy: 0.2598\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 2.0497 - accuracy: 0.2571\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 1.9307 - accuracy: 0.2542\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 1.6601 - accuracy: 0.2580\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.6612 - accuracy: 0.2558\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.6443 - accuracy: 0.2572\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.6579 - accuracy: 0.2607\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.6332 - accuracy: 0.2573\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5249 - accuracy: 0.2569\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5330 - accuracy: 0.2566\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.5341 - accuracy: 0.2586\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.5304 - accuracy: 0.2555\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5544 - accuracy: 0.2602\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4824 - accuracy: 0.2564\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4914 - accuracy: 0.2556\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4749 - accuracy: 0.2571\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4781 - accuracy: 0.2576\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4712 - accuracy: 0.2555\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4420 - accuracy: 0.2578\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4323 - accuracy: 0.2621\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4395 - accuracy: 0.2572\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4435 - accuracy: 0.2592\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.4399 - accuracy: 0.2594\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.4200 - accuracy: 0.2564\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.4167 - accuracy: 0.2569\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4242 - accuracy: 0.2574\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4197 - accuracy: 0.2545\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4195 - accuracy: 0.2594\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4040 - accuracy: 0.2567\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4107 - accuracy: 0.2593\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4108 - accuracy: 0.2579\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4034 - accuracy: 0.2567\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4038 - accuracy: 0.2562\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4063 - accuracy: 0.2576\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4062 - accuracy: 0.2585\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4027 - accuracy: 0.2584\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3987 - accuracy: 0.2613\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.4017 - accuracy: 0.2595\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.3971 - accuracy: 0.2564\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3978 - accuracy: 0.2582\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3991 - accuracy: 0.2584\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3995 - accuracy: 0.2574\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3985 - accuracy: 0.2592\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3950 - accuracy: 0.2608\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3977 - accuracy: 0.2588\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3975 - accuracy: 0.2585\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3963 - accuracy: 0.2607\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3987 - accuracy: 0.2553\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3967 - accuracy: 0.2616\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.3981 - accuracy: 0.2585\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.3974 - accuracy: 0.2615\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.3958 - accuracy: 0.2601\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3955 - accuracy: 0.2598\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3968 - accuracy: 0.2605\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3955 - accuracy: 0.2612\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3972 - accuracy: 0.2608\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3972 - accuracy: 0.2579\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3965 - accuracy: 0.2611\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3974 - accuracy: 0.2601\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3974 - accuracy: 0.2599\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3969 - accuracy: 0.2609\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3967 - accuracy: 0.2596\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 1.3972 - accuracy: 0.2603\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.3975 - accuracy: 0.2605\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.3984 - accuracy: 0.2563\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.3981 - accuracy: 0.2576\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.3967 - accuracy: 0.2572\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.3965 - accuracy: 0.2586\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.3964 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.3983 - accuracy: 0.2618\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.3963 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.3972 - accuracy: 0.2587\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.3974 - accuracy: 0.2582\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.3977 - accuracy: 0.2597\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.3978 - accuracy: 0.2585\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.3980 - accuracy: 0.2581\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.3994 - accuracy: 0.2607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.3970 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.3976 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.3985 - accuracy: 0.2592\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.3988 - accuracy: 0.2577\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.3984 - accuracy: 0.2589\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.3985 - accuracy: 0.2573\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.3983 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.3991 - accuracy: 0.2591\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.3984 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.3982 - accuracy: 0.2500\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 1.3984 - accuracy: 0.2500\n"
     ]
    }
   ],
   "source": [
    "accuracy, accuracy_weight = learn_reg_L1(weight=weight2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max weight idx : 12\n",
      "max weight : 0.000120\n",
      "max accuracy : 0.260315\n"
     ]
    }
   ],
   "source": [
    "maxidx1 = accuracy.index(max(accuracy))\n",
    "print(\"max weight idx : %d\" % maxidx1)\n",
    "print(\"max weight : %f\" % accuracy_weight[maxidx1])\n",
    "print(\"max accuracy : %f\" % accuracy[maxidx1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x267bcc526a0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i for i in range(step_num*2)], accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
